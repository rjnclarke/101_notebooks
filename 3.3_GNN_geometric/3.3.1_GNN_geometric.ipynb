{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","toc_visible":true,"collapsed_sections":["NIT-f4xaaHAN","5h6V_IS4aUHE","7gHf4pRRec33","DzuIfUdD1mgl","DzclltjJ2pAD"],"authorship_tag":"ABX9TyM5lzm12+z+CtR4bnjG1Q29"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Text Classification - Training a GNN with PyTorch Geometric\n"],"metadata":{"id":"dUIPrkd5ZhSk"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","* Admin\n","* Data\n","* Model\n","* Sampling\n","* Train - Validate\n"],"metadata":{"id":"B8XfyA9PZvEw"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","We now train a GNN in PyTorch Geometric. We will keep the network quite close to the previous version. But it may lead to commutational efficiency and potentiall easier iteration.\n","\n","Note there are now version issues with SparseTensor, we require a stable versioning setup between torch-sparse, torch, and torch-geometric."],"metadata":{"id":"vret55TUZ02j"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"NIT-f4xaaHAN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wcuqh_quIMyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742304787769,"user_tz":-60,"elapsed":1736,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"4543ebdd-5243-4eb0-800d-5cbf1b7398e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"id":"DzhX1zvqaNvl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742304788999,"user_tz":-60,"elapsed":1228,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"e37c00ee-97a5-4f41-c8ef-08f7de6764b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import torch\n","!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n","!pip install --no-index torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install --no-index torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install --no-index torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install git+https://github.com/pyg-team/pytorch_geometric.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndE1nWhnWJNw","executionInfo":{"status":"ok","timestamp":1742304062191,"user_tz":-60,"elapsed":14033,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f7695d93-e681-4901-dc56-8ad6e170b74e","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-scatter (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch-scatter\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-sparse (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch-sparse\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-cluster (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch-cluster\u001b[0m\u001b[31m\n","\u001b[0mCollecting git+https://github.com/pyg-team/pytorch_geometric.git\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-481aooot\n","  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-481aooot\n","  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit d2bb939a1bfba3b7a6f7d7b102a2771471657319\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.11.13)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\n","Collecting xxhash (from torch-geometric==2.7.0)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2025.1.31)\n","Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1185293 sha256=4589b2a226e971cabcff89909acfc6a0eaa636fabf706f6dcb6e826330698bcb\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-io4imvqn/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\n","Successfully built torch-geometric\n","Installing collected packages: xxhash, torch-geometric\n","Successfully installed torch-geometric-2.7.0 xxhash-3.5.0\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data\n","* Load adjacency matrices\n","* Instantiate PyTorch Geometric Data objects"],"metadata":{"id":"5h6V_IS4aUHE"}},{"cell_type":"code","source":["path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train')\n","df_dev = pd.read_pickle(path + 'df_dev')\n","df_test = pd.read_pickle(path + 'df_test')"],"metadata":{"id":"ODsXJcTmaSS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = 'class/tensors/adj_{}.pt'\n","\n","# train\n","train_people = torch.load(path.format('train_people'), weights_only=True)\n","train_locations = torch.load(path.format('train_locations'), weights_only=True)\n","train_entities = torch.load(path.format('train_entities'), weights_only=True)\n","\n","# dev\n","dev_people = torch.load(path.format('dev_people'), weights_only=True)\n","dev_locations = torch.load(path.format('dev_locations'), weights_only=True)\n","dev_entities = torch.load(path.format('dev_entities'), weights_only=True)\n","\n","# val (contains the adjacency matrix for both the training and the development set)\n","val_people = torch.load(path.format('val_people.1'), weights_only=True)\n","val_locations = torch.load(path.format('val_locations.1'), weights_only=True)\n","val_entities = torch.load(path.format('val_entities.1'), weights_only=True)"],"metadata":{"id":"Gq2r3eC3aYsu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = df_train[['index', 'chapter_idx', 'vanilla_embedding.1']]\n","df2 = df_dev[['index', 'chapter_idx', 'vanilla_embedding.1']]\n","df_val = pd.concat([df2,df1])"],"metadata":{"id":"O_nJwwBo6tuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inputs\n","H_train = torch.stack(list(df_train['vanilla_embedding.1'])).to(device)\n","labels_train = torch.LongTensor(list(df_train['chapter_idx'])).to(device)\n","\n","H_dev = torch.stack(list(df_dev['vanilla_embedding.1'])).to(device)\n","labels_dev = torch.LongTensor(list(df_dev['chapter_idx'])).to(device)\n","\n","H_val = torch.stack(list(df_val['vanilla_embedding.1'])).to(device)\n","labels_val = torch.LongTensor(list(df_val['chapter_idx'])).to(device)"],"metadata":{"id":"MkSHiOlybvoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train relationships where edge index is a tuple [0][0] > [1][0] The first element of list one, links to first element of list 2\n","train_edge_index = train_entities.nonzero(as_tuple=True)\n","train_edge_index = torch.stack(train_edge_index).long().to(device)\n","# train_edge_relation = torch.zeros(train_edge_index.size(1), dtype=torch.long)\n","\n","dev_edge_index = dev_entities.nonzero(as_tuple=True)\n","dev_edge_index = torch.stack(dev_edge_index).long().to(device)\n","# dev_edge_relation = torch.zeros(dev_edge_index.size(1), dtype=torch.long)\n","\n","val_edge_index = val_entities.nonzero(as_tuple=True)\n","val_edge_index = torch.stack(val_edge_index).long().to(device)\n","# val_edge_relation = torch.zeros(val_edge_index.size(1), dtype=torch.long)"],"metadata":{"id":"pHHVIJqZcIlp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.data import Data\n","\n","train_data = Data(x=H_train, edge_index=train_edge_index, y=labels_train)\n","dev_data = Data(x=H_dev, edge_index=dev_edge_index, y=labels_dev)\n","val_data = Data(x=H_val, edge_index=val_edge_index, y=labels_val)"],"metadata":{"id":"h8qp93KRbT-q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Model}$\n"],"metadata":{"id":"7gHf4pRRec33"}},{"cell_type":"code","source":["from torch_geometric.utils import degree\n","from torch_geometric.nn.conv import MessagePassing\n","from torch import nn\n","from torch.nn import functional as F\n","\n","class GNNLayer(MessagePassing):\n","  def __init__(self, in_channels, out_channels, dropout=0.55):\n","    super(GNNLayer, self).__init__(aggr='add') # Use 'add' aggregation.\n","    self.in_channels = in_channels\n","    self.out_channels = out_channels\n","    self.dropout = dropout\n","\n","    # Weight matrices for node self-projection and message passing\n","    self.T = nn.Parameter(torch.Tensor(in_channels, out_channels))\n","    self.E = nn.Parameter(torch.Tensor(in_channels, out_channels))\n","\n","    # Batch normalization\n","    self.batch_norm = nn.BatchNorm1d(out_channels)\n","    self.reset_parameters()\n","\n","  def reset_parameters(self):\n","    nn.init.xavier_uniform_(self.T)\n","    nn.init.xavier_uniform_(self.E)\n","\n","  def forward(self, x, edge_index):\n","    # Calculate node degrees\n","    row, col = edge_index\n","    deg = degree(col, x.size(0), dtype=x.dtype)\n","    deg_inv_sqrt = deg.pow(-0.5)\n","    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","\n","    # Create normalization parameters\n","    norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","\n","    # Propagate messages based on edge_index\n","    transformed_x = x @ self.E\n","    messages = self.propagate(edge_index, x=transformed_x, norm=norm)\n","\n","    # Self-projection\n","    self_proj = x @ self.T\n","\n","    # Combine and process messages with skip connection\n","    out = x + F.leaky_relu(self_proj + messages)\n","\n","    # Apply batch normalization\n","    out = self.batch_norm(out)\n","\n","    # Apply dropout\n","    out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","    return out"],"metadata":{"id":"cohqkjtObUB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GNNModel(nn.Module):\n","    def __init__(self, d, h, c, num_layers=2, dropout_rate=0.55):\n","        super(GNNModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.gnn_layers = nn.ModuleList([GNNLayer(d, d, dropout_rate) for _ in range(num_layers)])\n","        self.fc1 = nn.Linear(d, h)\n","        self.batch_norm_fc1 = nn.BatchNorm1d(h)\n","        self.fc2 = nn.Linear(h, c)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, edge_index):\n","        for layer in self.gnn_layers:\n","            x = layer(x, edge_index)\n","\n","        x = self.relu(self.batch_norm_fc1(self.dropout(self.fc1(x))))\n","        Output = self.fc2(x)\n","        return Output\n","\n","    def forward_layer(self, x, edge_index, layer_idx):\n","        \"\"\"Forward pass for a specific layer.\"\"\"\n","        x = self.gnn_layers[layer_idx](x, edge_index)\n","        return x"],"metadata":{"id":"SHYnC6PZrXcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d = 768\n","h = 400   # hidden dimension of fully connected layer\n","c = 70   # number of classes\n","num_relations = 1   # number of relationship types\n","\n","# Model, Loss, Optimizer\n","model = GNNModel(d, h, c, num_relations)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"],"metadata":{"id":"nKdPLK7UyxI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_parameters_per_module(model):\n","    print(\"Module and parameter counts:\")\n","\n","    for name, module in model.named_modules():\n","        # Skip the top-level module (the model itself)\n","        if not isinstance(module, nn.Module) or name == \"\":\n","            continue\n","\n","        param_count = sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","        if param_count > 0:  # Only print modules that have parameters\n","            print(f\"{name}: {param_count} parameters\")"],"metadata":{"id":"Yr_9pjgP0Xv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count_parameters_per_module(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfjwlWEN0n70","executionInfo":{"status":"ok","timestamp":1738920437261,"user_tz":-60,"elapsed":4,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9aa8fce4-9e2b-460b-d75a-4f013e535e50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Module and parameter counts:\n","gnn_layers: 1181184 parameters\n","gnn_layers.0: 1181184 parameters\n","gnn_layers.0.batch_norm: 1536 parameters\n","fc1: 307600 parameters\n","batch_norm_fc1: 800 parameters\n","fc2: 28070 parameters\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Sampling}$\n"],"metadata":{"id":"DzuIfUdD1mgl"}},{"cell_type":"code","source":["from torch_geometric.loader import NeighborSampler\n","edge_index = train_data.edge_index\n","# Get unique linked nodes from edge_index\n","linked_nodes = torch.unique(edge_index[0])  # Get source nodes\n","linked_nodes = torch.unique(torch.cat([edge_index[0], edge_index[1]]))  # Get both ends of edges\n","\n","# Now you can pass linked_nodes to NeighborSampler\n","train_sampler = NeighborSampler(\n","  train_data.edge_index,\n","  node_idx=linked_nodes,  # Use only linked nodes\n","  sizes=[4,4],\n","  batch_size=64,\n","  shuffle=True,\n","  num_workers=0\n",")"],"metadata":{"id":"lohsBke8yxTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now you can pass linked_nodes to NeighborSampler\n","val_sampler = NeighborSampler(\n","  val_data.edge_index,\n","  node_idx=torch.arange(964),  # Use only linked nodes\n","  sizes=[4,4],\n","  batch_size=1024,\n","  shuffle=False,\n","  num_workers=0\n",")"],"metadata":{"id":"WJSbSKIy9NeF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","\n","for batch_size, n_id, adj in train_sampler:\n","  if count < 1:\n","    print(f'batch size: {batch_size}')\n","    print(f'n_id: {n_id}')\n","    print(f'adj: {adj}')\n","    count += 1\n","  break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hne2rwVdadGU","executionInfo":{"status":"ok","timestamp":1738920459249,"user_tz":-60,"elapsed":16,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"47631d91-40ce-4102-cd6d-3ba73ac6e66f","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["batch size: 64\n","n_id: tensor([ 2211, 10176,  7232,  ...,  4776, 11727,  5119])\n","adj: [EdgeIndex(edge_index=tensor([[  64,   67,  296,  ..., 1121, 1124, 1125],\n","        [   0,    1,    1,  ...,  295,  295,  295]]), e_id=tensor([890686, 293500, 597303,  ..., 374045, 367853, 919514]), size=(1127, 296)), EdgeIndex(edge_index=tensor([[ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n","          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n","          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n","         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,  86, 117, 118,\n","         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n","         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n","         147, 148, 149, 150, 151,  69, 152, 153, 154, 155, 156, 157, 158, 159,\n","         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n","         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n","         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n","         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n","         216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n","         230, 231, 232, 233, 234, 235, 236,  98, 237, 238, 239, 240, 241, 242,\n","         243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256,\n","         257, 258, 259, 260, 261, 262, 263, 246, 264, 265, 266, 267, 268, 269,\n","         270, 271, 272, 273, 274, 275, 276, 277, 278,  45, 279, 280, 281, 282,\n","          25, 155, 283, 284, 285, 286, 287, 288, 289,  66, 116, 290, 291, 292,\n","         293, 294, 295],\n","        [  0,   1,   1,   1,   1,   2,   2,   3,   3,   3,   3,   4,   4,   4,\n","           4,   5,   5,   5,   5,   6,   6,   6,   6,   7,   7,   7,   8,   8,\n","           8,   8,   9,   9,   9,   9,  10,  10,  10,  10,  11,  11,  11,  12,\n","          12,  12,  12,  13,  13,  13,  13,  14,  14,  14,  14,  15,  15,  15,\n","          15,  16,  16,  16,  16,  17,  17,  17,  17,  18,  18,  18,  18,  19,\n","          19,  19,  19,  20,  20,  20,  20,  21,  21,  21,  21,  22,  22,  22,\n","          22,  23,  23,  23,  23,  24,  24,  24,  24,  25,  25,  25,  25,  26,\n","          26,  26,  26,  27,  27,  27,  27,  28,  28,  28,  28,  29,  29,  29,\n","          29,  30,  30,  30,  30,  31,  31,  31,  31,  32,  32,  32,  32,  33,\n","          33,  33,  33,  34,  34,  34,  34,  35,  35,  35,  35,  36,  36,  36,\n","          36,  37,  37,  37,  37,  38,  38,  38,  38,  39,  39,  40,  40,  40,\n","          40,  41,  41,  41,  41,  42,  42,  42,  42,  43,  43,  43,  43,  44,\n","          44,  44,  44,  45,  45,  45,  45,  46,  46,  46,  46,  47,  47,  47,\n","          47,  48,  48,  48,  48,  49,  49,  49,  49,  50,  50,  50,  50,  51,\n","          51,  51,  51,  52,  52,  52,  52,  53,  53,  53,  53,  54,  54,  54,\n","          54,  55,  55,  55,  55,  56,  56,  56,  56,  57,  57,  57,  57,  58,\n","          59,  59,  59,  59,  60,  60,  60,  60,  61,  62,  62,  62,  62,  63,\n","          63,  63,  63]]), e_id=tensor([890686, 363080, 337403, 293500, 260144, 556646, 457342, 400510, 243429,\n","        551395, 833512, 615033, 403608, 679839, 363805, 238018, 785598, 801107,\n","        148963, 453476,  27890, 472510, 489692, 712691, 690435, 125084, 516670,\n","        524356, 221932, 256176, 170361, 472456, 379943, 806225, 552491, 866994,\n","        815630, 188019, 705030, 628224, 444541, 731592, 775232, 293029, 542032,\n","        585753, 361135, 493903, 452316, 234174, 761983, 583729, 568959, 489805,\n","        826981, 544775, 147696, 325383, 615250, 268136, 570059, 584916,  86985,\n","        156566, 454235,  77333, 446024, 664606, 572076, 799775, 759000, 524263,\n","        501946, 584863, 150081, 380648, 381232, 283522, 902435, 842929, 754362,\n","        705345, 887552, 677679,  66029,   3494, 620576, 133276, 269907, 556592,\n","        439339, 511290, 313129, 550116, 492155, 803730, 396295,   4251, 303594,\n","        394577, 908709, 682025, 479881, 340944, 250782,  94586, 540811, 706283,\n","         11263, 596799, 512018, 264834,   1164, 685557, 281016, 514976, 282269,\n","        210861, 212952,  80630, 550663, 340066, 517164, 400034, 253103, 390302,\n","        911591, 822207,   7793, 379811, 349540,  66164, 576897,  72380, 575324,\n","        895648, 423226, 177265, 532968, 458415, 512129, 843392, 822365, 841621,\n","        739148, 812769, 453245, 453970,  43748, 508621, 316480, 179212, 284989,\n","         95104, 341006,  50230, 849780, 408216, 497022, 490711, 716029, 534308,\n","        663501, 514194, 234371, 578927, 157967,  54918, 406247, 617498, 447880,\n","        210358, 355634, 882592, 872719, 552495, 723106, 437957,  83549, 587077,\n","        521744, 215991, 748721, 449150,   7944, 825190, 150042, 768357, 380728,\n","        114326,   6330,  10041, 826968, 206182, 460926, 441987, 660817, 653775,\n","        335591, 765913, 549487, 374933, 193618, 824810, 648813, 110030, 120931,\n","        322941,  70435, 462611, 821045, 837883, 111932, 877607, 549424, 646190,\n","        414982, 766893, 691745, 703976, 863596, 358955, 442420, 348822, 759520,\n","        550076, 586352, 365652, 177135, 482305,  48107, 819843, 869727, 337359,\n","        568989, 218145, 215882, 261141,  24114, 656489, 794128]), size=(296, 64))]\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Train-Validate}$\n"],"metadata":{"id":"DzclltjJ2pAD"}},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    # argmax to get predicted classes\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # count correct\n","    correct = (predicted == labels).sum().item()\n","\n","    # get average\n","    acc = correct / labels.size(0)  # Total number of samples\n","    return acc"],"metadata":{"id":"C5c0Gv_L272t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_edge_index(adj):\n","    # Initialize lists to hold edge source and target indices\n","    rows = []\n","    cols = []\n","\n","    for edge_index in adj:\n","        edge_index_tensor = edge_index.edge_index  # Extracting edge_index tensor\n","        rows.append(edge_index_tensor[0])  # Source nodes\n","        cols.append(edge_index_tensor[1])  # Target nodes\n","\n","    # Concatenate the sources and targets into long tensors\n","    rows_tensor = torch.cat(rows, dim=0)\n","    cols_tensor = torch.cat(cols, dim=0)\n","\n","    # Stack them into a new edge_index tensor\n","    new_edge_index = torch.stack([rows_tensor, cols_tensor], dim=0)\n","\n","    return new_edge_index"],"metadata":{"id":"3bTu9HMSufO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def train(model, sampler, criterion, optimizer):\n","    model.train()\n","    epoch_train_losses = []\n","    epoch_train_accuracy = []\n","    for batch_size, n_id, adj in sampler:\n","      optimizer.zero_grad()\n","\n","      x = train_data.x[n_id].to(device)  ##### Change to train\n","      edge_index = extract_edge_index(adj).to(device)\n","      out = model(x, edge_index)\n","      y = train_data.y[n_id].to(device) #### Change to train\n","\n","\n","      train_loss = criterion(out, y)\n","      train_accuracy = accuracy(out, y)\n","\n","\n","      epoch_train_losses.append(train_loss.item())\n","      epoch_train_accuracy.append(train_accuracy)\n","\n","      # Backpropagation and optimization\n","      train_loss.backward()\n","      optimizer.step()\n","\n","    return np.mean(epoch_train_losses), np.mean(epoch_train_accuracy)"],"metadata":{"id":"7z1e7Z1028pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mode(lstr):\n","  unique, counts = np.unique(lstr, return_counts=True)\n","  max_idx = np.argmax(counts)\n","  mode_val = unique[max_idx]\n","  return mode_val, lstr.index(mode_val)"],"metadata":{"id":"fHU2xYSvyBf6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from collections import defaultdict\n","\n","\n","\n","def validate(model, sampler, criterion):\n","    \"\"\"\n","    Validate the model on the validation dataset using the provided sampler.\n","\n","    Parameters:\n","    - model: The model to be evaluated.\n","    - sampler: The sampler to sample validation data.\n","    - criterion: The loss function used for evaluation.\n","\n","    Returns:\n","    - dev_loss: The calculated loss on the validation data.\n","    - dev_accuracy: The calculated accuracy on the validation data.\n","    \"\"\"\n","\n","    model.eval()\n","\n","    aggregated_outputs = defaultdict(list)  # Store raw model outputs\n","    aggregated_predictions = defaultdict(list)  # Store predicted class labels\n","    aggregated_labels = defaultdict(list)  # Store true labels\n","\n","    with torch.no_grad():\n","        for batch_size, n_id, adj in sampler:\n","            edge_index = extract_edge_index(adj).to(device)\n","            x = val_data.x[n_id].to(device)  # Assuming `data.x` is your node features\n","            out = model(x, edge_index)\n","            y = val_data.y[n_id].to(device)\n","\n","            # Create a mask for indices less than 964\n","            mask = (n_id < 964)\n","            filtered_n_id = n_id[mask]\n","            filtered_out = out[mask]\n","            filtered_y = y[mask]\n","\n","            # Determine the predicted class for each output\n","            _, predicted_classes = torch.max(filtered_out, dim=1)\n","\n","            # Aggregate outputs, predicted classes, and true labels\n","            for idx, node_id in enumerate(filtered_n_id):\n","                aggregated_outputs[node_id].append(filtered_out[idx])  # Store the raw output\n","                aggregated_predictions[node_id].append(predicted_classes[idx].item())\n","                aggregated_labels[node_id].append(filtered_y[idx].item())  # Assume these are identical per node\n","\n","    # final_predictions = []\n","    final_labels = []\n","    final_outputs = []  # Store outputs for the loss calculation\n","\n","    for node_id in aggregated_predictions:\n","        # Get the most common predicted class\n","        most_common_prediction_idx = mode(aggregated_predictions[node_id])[1]\n","\n","        # final_predictions.append(most_common_prediction)\n","        final_labels.append(aggregated_labels[node_id][most_common_prediction_idx])  # All labels are identical\n","        final_outputs.append(aggregated_outputs[node_id][most_common_prediction_idx])  # Store the corresponding output for loss calculation\n","\n","    # Convert to tensors for loss computation\n","    #final_predictions = torch.tensor(final_predictions)\n","    final_labels = torch.tensor(final_labels).to(device)\n","    final_outputs = torch.stack(final_outputs).to(device)  # Stack outputs for loss computation\n","\n","    dev_loss = criterion(final_outputs, final_labels)\n","    dev_accuracy = accuracy(final_outputs, final_labels)\n","\n","    return dev_loss, dev_accuracy"],"metadata":{"id":"dfWUP1WvbKz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 0):\n","  \"\"\"\n","  Runs a training setup\n","  verbose == 1 - print model results\n","  verbose == 2 -> print epoch and model results\n","  \"\"\"\n","  model = model.to(device)\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=alpha)\n","\n","  # Hold epoch stats\n","  train_losses = []\n","  train_accuracy = []\n","  dev_losses = []\n","  dev_accuracy = []\n","  epoch_holder = []\n","\n","  # Break if no improvement\n","  current_best = 0\n","  no_improvement = 0\n","\n","\n","  # Run epochs\n","  for epoch in range(epochs):\n","\n","    # break out of epochs\n","    if no_improvement >= 6:\n","      break\n","\n","    # # trace\n","    torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","    start_time = time.time()\n","    #call training and validation functions\n","    train_loss, train_acc = train(model, trace_sampler, criterion, optimizer)\n","    print(\"\\n--- Profiling Results for Training Phase ---\")\n","    training_time = time.time() - start_time  # Calculate elapsed time\n","    max_train_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","    print(f'Time: {training_time}\\nMax memory: {max_train_memory}')\n","\n","    torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","    start_time = time.time()\n","    print(\"\\n--- Profiling Results for Validation Phase ---\")\n","    dev_loss, dev_acc = validate(model, val_sampler, criterion)\n","    validation_time = time.time() - start_time  # Calculate elapsed time\n","    max_validation_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","    print(f'Time: {validation_time}\\nMax memory: {max_validation_memory}')\n","\n","    # Store epoch stats\n","    train_losses.append(train_loss)\n","    train_accuracy.append(train_acc)\n","    dev_losses.append(dev_loss)\n","    dev_accuracy.append(dev_acc)\n","    epoch_holder.append(epoch + 1)\n","\n","    # check for improvement\n","    if dev_acc > current_best:\n","      current_best = dev_acc\n","      no_improvement = 0\n","    else:\n","      no_improvement += 1\n","\n","    # save best model\n","    if dev_acc > max_accuracy:\n","      torch.save(model.state_dict(), path)\n","      max_accuracy = dev_acc\n","\n","\n","    # optionally print epoch results\n","    if verbose == 2:\n","      print(f'\\n --------- \\nEpoch: {epoch + 1}\\n')\n","      print(f'Epoch {epoch + 1} train loss: {train_loss:.4f}')\n","      print(f'Epoch {epoch + 1} train accuracy: {train_acc:.4f}')\n","      print(f'Epoch {epoch + 1} dev loss: {dev_loss:.4f}')\n","      print(f'Epoch {epoch + 1} dev accuracy: {dev_acc:.4f}')\n","\n","      # save best results\n","  max_ind = np.argmax(dev_accuracy)\n","\n","  stats = Stats(\n","      train_losses[max_ind],\n","      train_accuracy[max_ind],\n","      dev_losses[max_ind],\n","      dev_accuracy[max_ind],\n","      epoch_holder[max_ind],\n","      lr, alpha,\n","      max_accuracy\n","  )\n","\n","  # optionally print model results\n","  if verbose in [1,2]:\n","    print('\\n ######## \\n')\n","    print(f'lr:{stats.lr}, alpha:{stats.alpha} @ epoch {stats.epoch}.')\n","    print(f'TL:{stats.train_loss}, TA:{stats.train_accuracy}.')\n","    print(f'DL:{stats.dev_loss}, DA:{stats.dev_accuracy}')\n","\n","  return stats"],"metadata":{"id":"1z16rqE1nh0d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### $\\color{red}{Sanity-check:}$"],"metadata":{"id":"PLt297-koEFq"}},{"cell_type":"code","source":["from collections import namedtuple\n","Stats = namedtuple('Stats', [\n","    'train_loss',\n","    'train_accuracy',\n","    'dev_loss',\n","    'dev_accuracy',\n","    'epoch',\n","    'lr',\n","    'alpha',\n","    'max_accuracy'\n","])"],"metadata":{"id":"Gr0gpKwVnT47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tv_run(epochs=1, model=model, lr=0.00003, alpha=0.0005, max_accuracy=0, path=\"binme\", verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQipohINoMe1","executionInfo":{"status":"ok","timestamp":1738920556533,"user_tz":-60,"elapsed":2747,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"695b285a-1d3f-4993-d6f4-caae921f27c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 0.3142986297607422\n","Max memory: 212007424\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 0.07372665405273438\n","Max memory: 285145600\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 4.3206\n","Epoch 1 train accuracy: 0.0159\n","Epoch 1 dev loss: 4.2532\n","Epoch 1 dev accuracy: 0.0207\n","\n"," ######## \n","\n","lr:3e-05, alpha:0.0005 @ epoch 1.\n","TL:4.320555246793306, TA:0.015879582113967398.\n","DL:4.253239631652832, DA:0.02074688796680498\n"]},{"output_type":"execute_result","data":{"text/plain":["Stats(train_loss=4.320555246793306, train_accuracy=0.015879582113967398, dev_loss=tensor(4.2532, device='cuda:0'), dev_accuracy=0.02074688796680498, epoch=1, lr=3e-05, alpha=0.0005, max_accuracy=0.02074688796680498)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["def gen_config(lr_low, lr_high, alpha_low, alpha_high):\n","  np.random.seed()\n","  lr = round(10**float(np.random.uniform(lr_low,lr_high)),6)\n","  alpha = round(10**float(np.random.uniform(alpha_low,alpha_high)),6)\n","  return lr, alpha"],"metadata":{"id":"Cxz7XYn2nXL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_ranges( lr, lr_range, alpha, alpha_range):\n","\n","  lr_center = lr\n","  lr_low = lr_center - lr_range/2\n","  lr_high = lr_center + lr_range/2\n","  lr_diff = lr_high - lr_low\n","\n","  alpha_center = alpha\n","  alpha_low = alpha_center - alpha_range/2\n","  alpha_high = alpha_center + alpha_range/2\n","  alpha_diff = alpha_high - alpha_low\n","\n","  return (lr_low, lr_high, alpha_low, alpha_high)"],"metadata":{"id":"7tfL9PPQnZyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def search_stats(results):\n","  best_stats = None\n","  max_dev_accuracy = 0\n","  for i in range(len(results)):\n","    acc = results[i].dev_accuracy\n","    if acc > max_dev_accuracy:\n","      best_stats = results[i]\n","      max_dev_accuracy = acc\n","  return best_stats"],"metadata":{"id":"bb0vRh3Vnd-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs = 60\n","max_accuracy = 0\n","path = \"class/models/GNN_geom.1.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -5\n","lr_high = -3\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -3\n","alpha_range = alpha_high - alpha_low\n","\n","d = 768\n","h = 400\n","c = 70\n","num_relations = 2\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(3):\n","  # debug\n","  print(\"\\n################\\n\")\n","  print(f'round: {i}')\n","  # print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  # print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print('max', max_accuracy)\n","  print(\"\\n################\\n\")\n","\n","\n","  for j in range(12):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha = gen_config(lr_low, lr_high, alpha_low, alpha_high)\n","    # define model\n","    model = GNNModel(d, h, c, num_relations)\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 1)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range)\n","  lr_low, lr_high, alpha_low, alpha_high = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKK2OQbS58M4","outputId":"07002ecd-20e7-4791-ecee-3b802f79cdde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","################\n","\n","round: 0\n","max 0\n","\n","################\n","\n","1\n","\n"," ######## \n","\n","lr:0.000336, alpha:0.000114 @ epoch 9.\n","TL:0.754186844165836, TA:0.7979960528766625.\n","DL:2.4498090744018555, DA:0.46265560165975106\n","2\n","\n"," ######## \n","\n","lr:0.000105, alpha:1.3e-05 @ epoch 28.\n","TL:0.3983183858823031, TA:0.8944982536144503.\n","DL:2.672290563583374, DA:0.4896265560165975\n","3\n","\n"," ######## \n","\n","lr:2.9e-05, alpha:0.000218 @ epoch 12.\n","TL:1.2118226741307547, TA:0.699926851022546.\n","DL:2.1563241481781006, DA:0.45850622406639\n","4\n","\n"," ######## \n","\n","lr:1.3e-05, alpha:0.000124 @ epoch 29.\n","TL:1.104277127065829, TA:0.7273375425290917.\n","DL:2.122598886489868, DA:0.470954356846473\n","5\n","\n"," ######## \n","\n","lr:0.000326, alpha:1.6e-05 @ epoch 15.\n","TL:0.5962365707196295, TA:0.8399614192225077.\n","DL:2.5478997230529785, DA:0.483402489626556\n","6\n","\n"," ######## \n","\n","lr:0.000132, alpha:0.000899 @ epoch 8.\n","TL:0.821348932678146, TA:0.78892038595702.\n","DL:2.2576563358306885, DA:0.46265560165975106\n","7\n","\n"," ######## \n","\n","lr:0.000386, alpha:1.4e-05 @ epoch 13.\n","TL:0.6596934408641287, TA:0.8213984402725744.\n","DL:2.551778793334961, DA:0.47717842323651455\n","8\n","\n"," ######## \n","\n","lr:0.000219, alpha:8.9e-05 @ epoch 16.\n","TL:0.5497558281450932, TA:0.8520181535155387.\n","DL:2.683208703994751, DA:0.46887966804979253\n","9\n"]}]}]}