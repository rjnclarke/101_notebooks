{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fauEpas49JIK1vWh9s10XJwX_rn5wLTU","timestamp":1737991271114}],"gpuType":"T4","collapsed_sections":["NIT-f4xaaHAN","5h6V_IS4aUHE","7gHf4pRRec33","DzuIfUdD1mgl","DzclltjJ2pAD"],"authorship_tag":"ABX9TyP+07UTvzufswqfXGb/W+cU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Text Classification - Training a GNN with PyTorch Geometric and Distance Sampler\n"],"metadata":{"id":"dUIPrkd5ZhSk"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","* Admin\n","* Data\n","* Model\n","* Sampling\n","* Training Loop"],"metadata":{"id":"B8XfyA9PZvEw"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","We now train a GNN in PyTorch Geometric. We will keep the network quite close to the previous version. But it may lead to commutational efficiency and potentiall easier iteration.\n","\n","Note there are version issues, importing SparseTensor that is required for sampling. Although the code has run correctly, there are subsequent incompatabilities, and a stable version is yet to be assured."],"metadata":{"id":"vret55TUZ02j"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"NIT-f4xaaHAN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wcuqh_quIMyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742810995799,"user_tz":-60,"elapsed":8188,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f42d61ac-2ea6-4a95-93e5-4fdc95ee7b76"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"id":"DzhX1zvqaNvl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742811017638,"user_tz":-60,"elapsed":21837,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"5401e3d9-07c3-4c85-88e7-cbb6bded4562"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import torch\n","!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install git+https://github.com/pyg-team/pytorch_geometric.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndE1nWhnWJNw","executionInfo":{"status":"ok","timestamp":1742811495621,"user_tz":-60,"elapsed":477985,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"97f5202e-1f04-4fba-9d5a-67c16a3829b9","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","Collecting torch-scatter\n","  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: torch-scatter\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","Collecting torch-cluster\n","  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.14.1)\n","Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n","Building wheels for collected packages: torch-cluster\n","  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mCollecting git+https://github.com/pyg-team/pytorch_geometric.git\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-vwrnthmr\n","  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-vwrnthmr\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n","    return func(self, options, args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n","    requirement_set = resolver.resolve(\n","                      ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n","    collected = self.factory.collect_root_requirements(root_reqs)\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n","    reqs = list(\n","           ^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n","    cand = self._make_base_candidate_from_link(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n","    self._link_candidate_cache[link] = LinkCandidate(\n","                                       ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n","    super().__init__(\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n","    self.dist = self._prepare()\n","                ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n","    dist = self._prepare_distribution()\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n","    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n","^C\n"]}]},{"cell_type":"code","source":["import torch_geometric"],"metadata":{"id":"e9oamFSEX3-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data\n","* Load adjacency matrices\n","* Instantiate PyTorch Geometric Data objects"],"metadata":{"id":"5h6V_IS4aUHE"}},{"cell_type":"code","source":["path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train_augmentation_ft')\n","df_dev = pd.read_pickle(path + 'df_dev_augmentation_ft')\n","df_test = pd.read_pickle(path + 'df_test_augmentation_ft')"],"metadata":{"id":"ODsXJcTmaSS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_dev.columns"],"metadata":{"id":"M9FeFP2flfzo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_dev.shape"],"metadata":{"id":"iSCIaM8smhuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_dev['connected'] = df_dev['ner_responses'].str.contains('@@')"],"metadata":{"id":"wYTTbsiymTMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = 'class/tensors/adj_{}.pt'\n","\n","# train\n","# train_people = torch.load(path.format('train_people'), weights_only=True)\n","# train_locations = torch.load(path.format('train_locations'), weights_only=True)\n","train_entities = torch.load(path.format('train_augmented_entities'), weights_only=True)\n","\n","# dev\n","# dev_people = torch.load(path.format('dev_people'), weights_only=True)\n","# dev_locations = torch.load(path.format('dev_locations'), weights_only=True)\n","dev_entities = torch.load(path.format('dev_augmented_entities'), weights_only=True)\n","\n","# val (contains the adjacency matrix for both the training and the development set)\n","# val_people = torch.load(path.format('val_people.1'), weights_only=True)\n","# val_locations = torch.load(path.format('val_locations.1'), weights_only=True)\n","val_entities = torch.load(path.format('val_augmented_entities'), weights_only=True)"],"metadata":{"id":"Gq2r3eC3aYsu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.columns"],"metadata":{"id":"BmM__cM3j6q7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = df_train[[ 'chapter_idx', 'direct_ft_augmented_embedding']]\n","df2 = df_dev[['chapter_idx', 'direct_ft_augmented_embedding']]\n","df_val = pd.concat([df2,df1])"],"metadata":{"id":"O_nJwwBo6tuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inputs\n","H_train = torch.stack([torch.tensor(el) for el in list(df_train['direct_ft_augmented_embedding'])]).to(device)\n","labels_train = torch.LongTensor(list(df_train['chapter_idx'])).to(device)\n","\n","H_dev = torch.stack([torch.tensor(el) for el in list(df_dev['direct_ft_augmented_embedding'])]).to(device)\n","labels_dev = torch.LongTensor(list(df_dev['chapter_idx'])).to(device)\n","\n","H_val = torch.stack([torch.tensor(el) for el in list(df_val['direct_ft_augmented_embedding'])]).to(device)\n","labels_val = torch.LongTensor(list(df_val['chapter_idx'])).to(device)"],"metadata":{"id":"MkSHiOlybvoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train relationships where edge index is a tuple [0][0] > [1][0] The first element of list one, links to first element of list 2\n","train_edge_index = train_entities.nonzero(as_tuple=True)\n","train_edge_index = torch.stack(train_edge_index).long().to(device)\n","# train_edge_relation = torch.zeros(train_edge_index.size(1), dtype=torch.long)\n","\n","dev_edge_index = dev_entities.nonzero(as_tuple=True)\n","dev_edge_index = torch.stack(dev_edge_index).long().to(device)\n","# dev_edge_relation = torch.zeros(dev_edge_index.size(1), dtype=torch.long)\n","\n","val_edge_index = val_entities.nonzero(as_tuple=True)\n","val_edge_index = torch.stack(val_edge_index).long().to(device)\n","# val_edge_relation = torch.zeros(val_edge_index.size(1), dtype=torch.long)"],"metadata":{"id":"pHHVIJqZcIlp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.data import Data\n","\n","train_data = Data(x=H_train, edge_index=train_edge_index, y=labels_train)\n","dev_data = Data(x=H_dev, edge_index=dev_edge_index, y=labels_dev)\n","val_data = Data(x=H_val, edge_index=val_edge_index, y=labels_val)"],"metadata":{"id":"h8qp93KRbT-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# H_trace = torch.stack(list(df_train['vanilla_embedding.1'])[:2000]).to(device)\n","# labels_trace = torch.LongTensor(list(df_train['chapter_idx'])[:2000]).to(device)\n","# trace_entities = train_entities[:2000,:2000].to(device)\n","# trace_edge_index = trace_entities.nonzero(as_tuple=True)\n","# trace_edge_index = torch.stack(trace_edge_index).long().to(device)\n","# trace_data = Data(x=H_trace, edge_index=trace_edge_index, y=labels_trace)"],"metadata":{"id":"ZzBAoB7b3PAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","\n","def create_closest_neighbors_dict(embedding_matrix, adjacency_matrix, k=4):\n","    \"\"\"\n","    Create a dictionary of closest neighbors based on cosine similarity.\n","\n","    Parameters:\n","    - embedding_matrix: (n x d) tensor where n is the number of nodes and d is the embedding dimension.\n","    - adjacency_matrix: (n x n) tensor representing the graph connectivity.\n","    - k: Number of closest neighbors to find for each node.\n","\n","    Returns:\n","    - closest_neighbor_indices_dict: A dictionary where keys are node indices and values are lists of closest neighbor indices.\n","    \"\"\"\n","    num_nodes = embedding_matrix.size(0)\n","    closest_neighbor_indices_dict = {}\n","\n","    # Iterate over each node\n","    for i in range(num_nodes):\n","        # Get similarities with all other nodes\n","        # Use only neighbors defined by the adjacency matrix\n","        neighbor_indices = adjacency_matrix[i].nonzero(as_tuple=True)[0].to(device)  # Indices of neighbors\n","\n","        # Calculate cosine similarities if there are neighbors\n","        if neighbor_indices.numel() > 0:\n","            similarities = F.cosine_similarity(embedding_matrix[i].unsqueeze(0), embedding_matrix[neighbor_indices], dim=1)\n","            # Get the top k neighbor indices based on similarities\n","            if similarities.size(0) < k:\n","                top_k_vals, top_k_indices = similarities.topk(similarities.size(0))\n","                top_k_vals = [el.item() for el in top_k_vals]\n","            else:\n","                top_k_vals, top_k_indices = similarities.topk(k)\n","                top_k_vals = [el.item() for el in top_k_vals]\n","\n","            closest_neighbors = neighbor_indices[top_k_indices].tolist() # Convert to list\n","\n","            closest_neighbor_indices_dict[i] = list(zip(closest_neighbors, top_k_vals))\n","        else:\n","            # If no neighbors, return an empty list\n","            closest_neighbor_indices_dict[i] = []\n","\n","    return closest_neighbor_indices_dict"],"metadata":{"id":"4r28mxKrW894"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_closest_neighbors = create_closest_neighbors_dict(H_train, train_entities)\n","val_closest_neighbors = create_closest_neighbors_dict(H_val, val_entities)\n"],"metadata":{"id":"3Uf7Ar-IYHRS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Model}$\n"],"metadata":{"id":"7gHf4pRRec33"}},{"cell_type":"code","source":["from torch_geometric.utils import degree\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree\n","from torch import nn\n","from torch.nn import functional as F\n","\n","class GNNLayer(MessagePassing):\n","  def __init__(self, in_channels, out_channels, dropout=0.42):\n","    super(GNNLayer, self).__init__(aggr='add') # Use 'add' aggregation.\n","    self.in_channels = in_channels\n","    self.out_channels = out_channels\n","    self.dropout = dropout\n","\n","    # Weight matrices for node self-projection and message passing\n","    self.T = nn.Parameter(torch.Tensor(in_channels, out_channels))\n","    self.E = nn.Parameter(torch.Tensor(in_channels, out_channels))\n","\n","    # Batch normalization\n","    self.batch_norm = nn.BatchNorm1d(out_channels)\n","    self.reset_parameters()\n","\n","  def reset_parameters(self):\n","    nn.init.xavier_uniform_(self.T)\n","    nn.init.xavier_uniform_(self.E)\n","\n","  def forward(self, x, edge_index):\n","\n","    # add self loops\n","    #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n","\n","    # Calculate node degrees\n","    row, col, _ = edge_index.coo()\n","    deg = degree(col, x.size(0), dtype=x.dtype)\n","    deg_inv_sqrt = deg.pow(-0.5)\n","    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","\n","    # Create normalization parameters\n","    norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","\n","\n","\n","    # Propagate messages based on edge_index\n","    transformed_x = x @ self.E\n","    messages = self.propagate(edge_index, x=transformed_x, norm=norm)\n","\n","    # Self-projection\n","    self_proj = x @ self.T\n","\n","    # Combine and process messages with skip connection\n","    out = x + F.leaky_relu(self_proj + messages)\n","\n","    # Apply batch normalization\n","    out = self.batch_norm(out)\n","\n","    # Apply dropout\n","    out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","    return out"],"metadata":{"id":"cohqkjtObUB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GNNModel(nn.Module):\n","    def __init__(self, d, h, c, num_layers=2, dropout_rate=0.42):\n","        super(GNNModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.gnn_layers = nn.ModuleList([GNNLayer(d, d, dropout_rate) for _ in range(num_layers)])\n","        self.fc1 = nn.Linear(d, h)\n","        self.batch_norm_fc1 = nn.BatchNorm1d(h)\n","        self.fc2 = nn.Linear(h, c)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, edge_index):\n","        for layer in self.gnn_layers:\n","            x = layer(x, edge_index)\n","\n","        x = self.relu(self.batch_norm_fc1(self.dropout(self.fc1(x))))\n","        Output = self.fc2(x)\n","        return Output\n","\n","    def forward_layer(self, x, edge_index, layer_idx):\n","        \"\"\"Forward pass for a specific layer.\"\"\"\n","        x = self.gnn_layers[layer_idx](x, edge_index)\n","        return x"],"metadata":{"id":"SHYnC6PZrXcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d = 768\n","h = 400   # hidden dimension of fully connected layer\n","c = 70   # number of classes\n","num_relations = 2   # number of relationship types\n","\n","# Model, Loss, Optimizer\n","model = GNNModel(d,h,c)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"],"metadata":{"id":"nKdPLK7UyxI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_parameters_per_module(model):\n","    print(\"Module and parameter counts:\")\n","\n","    for name, module in model.named_modules():\n","        # Skip the top-level module (the model itself)\n","        if not isinstance(module, nn.Module) or name == \"\":\n","            continue\n","\n","        param_count = sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","        if param_count > 0:  # Only print modules that have parameters\n","            print(f\"{name}: {param_count} parameters\")"],"metadata":{"id":"Yr_9pjgP0Xv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count_parameters_per_module(model)"],"metadata":{"id":"AfjwlWEN0n70"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Sampling}$\n"],"metadata":{"id":"DzuIfUdD1mgl"}},{"cell_type":"code","source":["import torch\n","from torch import Tensor\n","from torch_geometric.loader import NeighborSampler\n","from torch_geometric.typing import SparseTensor\n","from collections import defaultdict\n","from typing import Callable, List, NamedTuple, Optional, Tuple, Union\n","\n","class EdgeIndex(NamedTuple):\n","    edge_index: Tensor\n","    e_id: Optional[Tensor]\n","    size: Tuple[int, int]\n","\n","    def to(self, *args, **kwargs):\n","        edge_index = self.edge_index.to(*args, **kwargs)\n","        e_id = self.e_id.to(*args, **kwargs) if self.e_id is not None else None\n","        return EdgeIndex(edge_index, e_id, self.size)\n","\n","\n","class CustomNeighborSampler(NeighborSampler):\n","    def __init__(self, edge_index, closest_neighbor_indices_dict, k_neighbor=4, **kwargs):\n","        super(CustomNeighborSampler, self).__init__(edge_index, **kwargs)\n","        self.closest_neighbor_indices_dict = closest_neighbor_indices_dict\n","        self.k_neighbor = k_neighbor\n","\n","    def sample(self, node_idx):\n","        \"\"\"Sample neighbors based on precomputed closest neighbor indices.\"\"\"\n","\n","        batch_size = len(node_idx)\n","        adjs = []\n","        n_id = torch.tensor(node_idx)\n","        # Sample first-hop neighbors\n","        first_hop_neighbors_dict = defaultdict(list)\n","        for node in n_id:\n","            neighbors = self.closest_neighbor_indices_dict.get(node.item(), [])\n","            # Select the top k neighbors\n","            sampled_neighbors = neighbors[:self.k_neighbor]\n","            sampled_neighbors = [x for x,y in sampled_neighbors]  # Sample first-hop neighbors\n","            first_hop_neighbors_dict[node.item()].extend(sampled_neighbors)\n","\n","        # Flatten first-hop neighbors into a set for uniqueness\n","        first_hop_node_ids_set = set()\n","        for node_neighbors in first_hop_neighbors_dict.values():\n","            first_hop_node_ids_set.update(node_neighbors)  # Keep unique entries\n","\n","        # Prepare to store second-hop neighbors\n","        second_hop_neighbors_dict = defaultdict(list)\n","        second_hop_node_ids_set = set()  # Keep unique second-hop IDs\n","        for node in first_hop_node_ids_set:\n","            neighbors = self.closest_neighbor_indices_dict.get(node, [])\n","            # Select the top k neighbors\n","            sampled_neighbors = neighbors[:self.k_neighbor]  # Sample second-hop neighbors\n","            # Filter out first-hop neighbors\n","            sampled_neighbors_filtered = [n[0] for n in sampled_neighbors if n[0] not in first_hop_node_ids_set]\n","            second_hop_neighbors_dict[node].extend(sampled_neighbors_filtered) # dict of tuples (ind, cosine similarity)\n","\n","        second_hop_neighbors = [val for vals in second_hop_neighbors_dict.values() for val in vals]\n","        second_hop_node_ids_set = set(second_hop_neighbors)  # Save second-hop neighbors\n","\n","\n","        # Combine first-hop and second-hop nodes to n_id\n","        all_neighbors = first_hop_node_ids_set.union(second_hop_node_ids_set).union(set(node_idx))\n","        n_id = torch.tensor(list(all_neighbors))  # Update n_id to include all unique first and second hop neighbors\n","\n","        # Create the adjacency tensor for both first-hop and second-hop neighbors\n","        adj_t = self.create_adj_tensor(first_hop_neighbors_dict, second_hop_neighbors_dict,n_id)\n","\n","        # Append the adjacency structure\n","        adjs.append(adj_t)\n","\n","        # Return the batch size, combined node IDs excluding seed nodes, and any adjacency structures\n","        return batch_size, n_id, adjs[::-1]  # Return updated n_id and adjacency list\n","\n","    def create_adj_tensor(self, first_hop_neighbors_dict, second_hop_neighbors_dict, n_id):\n","        # Step 1: Create a combined dictionary from both first and second hop neighbors\n","        combined_neighbors = defaultdict(set)\n","\n","        # Add first-hop neighbors\n","        for seed_node, neighbors in first_hop_neighbors_dict.items():\n","            combined_neighbors[seed_node].update(neighbors)\n","\n","        # Add second-hop neighbors\n","        for first_hop_node, neighbors in second_hop_neighbors_dict.items():\n","            combined_neighbors[first_hop_node].update(neighbors)\n","\n","        # Step 2: Create a node_id to index mapping\n","        mapping = {node: idx for idx, node in enumerate(n_id.numpy())}\n","\n","        # Step 3: Fill row and column indices for the sparse tensor\n","        row_indices = []\n","        col_indices = []\n","\n","        for node, neighbors in combined_neighbors.items():\n","            if node in mapping:  # Ensure the source node is in the mapping\n","                for neighbor in neighbors:\n","                    if neighbor in mapping:  # Ensure the neighbor is in the mapping\n","                        row_indices.append(mapping[node])\n","                        col_indices.append(mapping[neighbor])\n","\n","        edge_index = torch.tensor([row_indices, col_indices], dtype=torch.long)\n","\n","        # When creating the SparseTensor, ensure you are specifying correct sparse size\n","        edge_index_sparse = SparseTensor(\n","            row=edge_index[0],\n","            col=edge_index[1],\n","            sparse_sizes=(len(n_id), len(n_id))\n","        )\n","\n","        # Instead of using sparse_size, use directly the 'sparse_sizes' tuple you defined.\n","        edge_index_obj = EdgeIndex(\n","            edge_index=edge_index_sparse,\n","            e_id=None,\n","            size=edge_index_sparse.sizes()  # Use the method or property for size\n","        )\n","\n","        return [edge_index_obj]  # Return as a list containing the EdgeIndex object\n","\n"],"metadata":{"id":"L-1NL20qYp0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["edge_index = train_data.edge_index\n","# Get unique linked nodes from edge_index\n","linked_nodes = torch.unique(edge_index[0])  # Get source nodes\n","linked_nodes = torch.unique(torch.cat([edge_index[0], edge_index[1]]))  # Get both ends of edges\n","\n","# Now you can pass linked_nodes to NeighborSampler\n","train_sampler = CustomNeighborSampler(\n","  train_data.edge_index,\n","  closest_neighbor_indices_dict = train_closest_neighbors,\n","  node_idx=linked_nodes,  # Use only linked nodes\n","  sizes=[4, 4],\n","  batch_size=32,\n","  shuffle=True,\n","  num_workers=0\n",")"],"metadata":{"id":"lohsBke8yxTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","m = df_dev.shape[0]\n","# Now you can pass linked_nodes to NeighborSampler\n","val_sampler = CustomNeighborSampler(\n","  val_data.edge_index,\n","  closest_neighbor_indices_dict = val_closest_neighbors,\n","  node_idx=torch.arange(m),  # Use only linked nodes\n","  sizes=[4, 4],\n","  batch_size=m,\n","  shuffle=False,\n","  num_workers=0\n",")"],"metadata":{"id":"WJSbSKIy9NeF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","\n","for batch_size, n_id, adj in val_sampler:\n","  if count < 1:\n","    print(f'batch size: {batch_size}')\n","    print(f'n_id: {n_id}')\n","    print(f'adj: {adj}')\n","    count += 1\n","  break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hne2rwVdadGU","executionInfo":{"status":"ok","timestamp":1742810875800,"user_tz":-60,"elapsed":13,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"e10bdc19-3ea3-43b2-8ad3-4284c2fe6fdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["batch size: 746\n","n_id: tensor([    0,     1,     2,  ..., 16375, 16377, 16383])\n","adj: [[EdgeIndex(edge_index=SparseTensor(row=tensor([   0,    0,    0,  ..., 3401, 3402, 3402]),\n","             col=tensor([ 748,  810,  814,  ..., 2399, 1493, 2875]),\n","             size=(3405, 3405), nnz=4151, density=0.04%), e_id=None, size=[3405, 3405])]]\n"]}]},{"cell_type":"code","source":["adj[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acOyfBI86Rod","executionInfo":{"status":"ok","timestamp":1738747292334,"user_tz":-60,"elapsed":393,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"80abd14d-97a8-42f2-877b-fac04922caaa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[EdgeIndex(edge_index=SparseTensor(row=tensor([  1,   1,   1,   1,   6,   8,   8,   8,   8,   9,   9,   9,   9,  15,\n","                             17,  17,  17,  19,  19,  19,  21,  21,  21,  24,  24,  24,  29,  29,\n","                             29,  29,  37,  37,  38,  38,  38,  38,  47,  47,  47,  47,  48,  50,\n","                             50,  50,  51,  51,  51,  53,  53,  53,  54,  54,  54,  54,  55,  55,\n","                             55,  55,  57,  57,  57,  61,  61,  61,  61,  62,  62,  62,  62,  67,\n","                             67,  67,  67,  68,  68,  68,  68,  73,  73,  73,  74,  74,  74,  77,\n","                             77,  77,  78,  78,  78,  78,  81,  81,  81,  83,  83,  83,  84,  84,\n","                             84,  84,  86,  86,  86,  86,  87,  87,  87,  87,  92,  92,  92,  92,\n","                             96,  96,  96,  97,  97,  97,  97,  98,  98,  98,  98,  99,  99,  99,\n","                             99, 105, 105, 105, 112, 112, 112, 114, 114, 114, 114, 118, 118, 119,\n","                            119, 119, 123, 123, 123, 127, 130, 130, 131, 131, 131, 132, 132, 132,\n","                            139, 139, 139, 139, 140, 140, 140, 140, 141, 144, 145, 145, 145, 145,\n","                            146, 146, 146, 146, 147, 147, 147, 148, 148, 148, 148, 149, 149, 149,\n","                            149, 151, 151, 151, 151, 152, 152, 152, 152, 154, 154, 158, 158, 158,\n","                            158, 164, 164, 164, 166, 166, 166, 166, 168, 168, 168, 168, 171, 171,\n","                            171, 173, 173, 173, 184, 186, 186, 186, 186, 189, 189, 189]),\n","              col=tensor([118, 130, 131, 171,  38,  17,  37,  50,  74,   3,  49, 153, 161,  38,\n","                             33,  64,  71,  31,  85,  95,  97, 125, 128,  72, 134, 163,  43,  89,\n","                            184, 192,   8,  71,   6,  15,  19,  54,  51,  73,  98, 123, 127,  22,\n","                             64,  71,   7,  47,  88,  78,  90, 155,  34,  75, 116, 172,  57,  77,\n","                            148, 173,  16,  44,  80,   2,  39, 115, 117,   5,  56, 126, 186,  14,\n","                             99, 108, 157,  25,  70, 104, 167,  47,  82, 150,  22,  64,  71,   2,\n","                             34,  93,  53,  96, 105, 147,  27,  76,  93,  46, 109, 156,  41, 106,\n","                            122, 166,  42,  63,  91, 160, 112, 119, 145, 189,   0, 142, 182, 191,\n","                             46,  78, 121,  21,  61,  83,  86,  47, 113, 138, 162,  67, 139, 152,\n","                            168, 100, 183, 185,  52,  87, 110,  10,  13,  60,  66,  35,  45,  65,\n","                             87, 101,  47, 107, 190,  48,  94, 165, 159, 177, 178,  30, 179, 186,\n","                             32,  99, 120, 175,  26,  28,  59, 186, 154, 114,  36,  87, 129, 137,\n","                             63, 111, 160, 181,  12,  46, 180,  16,  63, 155, 181,  18,  30, 176,\n","                            186,   4,  23,  79, 124,  99, 102, 133, 188,  24, 141,  81,  92, 146,\n","                            164, 103, 143, 170,   9,  68,  84, 151,  40,  58, 169, 187,   1, 135,\n","                            159,  11,  20,  69,  29,  62, 132, 140, 149,  87, 136, 174]),\n","              size=(193, 193), nnz=222, density=0.60%), e_id=None, size=[193, 193])]"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## $\\color{blue}{Train-Validate}$\n"],"metadata":{"id":"DzclltjJ2pAD"}},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    # argmax to get predicted classes\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # count correct\n","    correct = (predicted == labels).sum().item()\n","\n","    # get average\n","    acc = correct / labels.size(0)  # Total number of samples\n","    return acc"],"metadata":{"id":"C5c0Gv_L272t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def train(model, sampler, criterion, optimizer, scheduler):\n","    model.train()\n","    epoch_train_losses = []\n","    epoch_train_accuracy = []\n","    for batch_size, n_id, adjs in sampler:\n","      optimizer.zero_grad()\n","\n","      x = train_data.x[n_id].to(device)  ##### Change to train\n","      edge_index = adjs[0][0].edge_index.t().to(device)\n","      out = model(x, edge_index)\n","      y = train_data.y[n_id].to(device) #### Change to train\n","\n","\n","      train_loss = criterion(out, y)\n","      train_accuracy = accuracy(out, y)\n","\n","\n","      epoch_train_losses.append(train_loss.item())\n","      epoch_train_accuracy.append(train_accuracy)\n","\n","      # Backpropagation and optimization\n","      train_loss.backward()\n","      optimizer.step()\n","    scheduler.step()\n","\n","    return np.mean(epoch_train_losses), np.mean(epoch_train_accuracy)"],"metadata":{"id":"7z1e7Z1028pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","def score(reals, preds):\n","  return (reals == preds).sum()/len(reals)\n","\n","def validate(model, sampler, criterion):\n","    \"\"\"\n","    Validate the model on the validation dataset using the provided sampler.\n","\n","    Parameters:\n","    - model: The model to be evaluated.\n","    - sampler: The sampler to sample validation data.\n","    - criterion: The loss function used for evaluation.\n","\n","    Returns:\n","    - dev_loss: The calculated loss on the validation data.\n","    - dev_accuracy: The calculated accuracy on the validation data.\n","    \"\"\"\n","\n","    model.eval()\n","\n","\n","    mask = df_dev.connected.to_numpy() # mask for validation points connected on the graph\n","    n = df_dev.shape[0] # cutoff for validation points\n","\n","    with torch.no_grad():\n","        for batch_size, n_id, adjs in sampler:\n","            edge_index = adjs[0][0].edge_index.t().to(device)\n","            x = val_data.x[n_id].to(device)  # Assuming `data.x` is your node features\n","            out = model(x, edge_index)\n","            y = val_data.y[n_id].to(device)\n","\n","            # loss = criterion(out, y)\n","            # acc = accuracy(out, y)\n","\n","            _, predicted = torch.max(out, 1)\n","            reals = y[:n]\n","            preds = predicted[:n]\n","            outs = out[:n,:]\n","            total_loss = criterion(outs, reals)\n","            total_acc = score(reals, preds)\n","\n","            print(reals.size())\n","            print(mask.shape)\n","\n","            # connected\n","            reals_con = reals[mask]\n","            preds_con = preds[mask]\n","            connected_acc = score(reals_con, preds_con)\n","\n","            # isolated\n","            reals_iso = reals[~mask]\n","            preds_iso = preds[~mask]\n","            isolated_acc = score(reals_iso, preds_iso)\n","\n","    return total_loss, total_acc, connected_acc, isolated_acc\n","\n","\n"],"metadata":{"id":"dfWUP1WvbKz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 0, trace=False):\n","  \"\"\"\n","  Runs a training setup\n","  verbose == 1 - print model results\n","  verbose == 2 -> print epoch and model results\n","  \"\"\"\n","  model = model.to(device)\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=alpha)\n","\n","  #Warm-up and linear decay scheduler\n","  num_warmup_steps = int(0.1 * epochs)  # 10% of epochs for warm-up\n","  def lr_lambda(current_step):\n","      if current_step < num_warmup_steps:\n","          return float(current_step) / float(max(1, num_warmup_steps))\n","      return max(\n","          0.0, float(epochs - current_step) / float(max(1, epochs - num_warmup_steps))\n","      )\n","\n","  scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n","\n","  # Hold epoch stats\n","  train_losses = []\n","  train_accuracy = []\n","  dev_losses = []\n","  dev_accuracy = []\n","  connected_accuracy = []\n","  isolated_accuracy = []\n","  epoch_holder = []\n","\n","  # Break if no improvement\n","  current_best = 0\n","  no_improvement = 0\n","\n","\n","  # Run epochs\n","  for epoch in range(epochs):\n","\n","    # break out of epochs\n","    if no_improvement >= 6:\n","      break\n","\n","    if trace:\n","      torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","      start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_sampler, criterion, optimizer, scheduler)\n","\n","    if trace:\n","      print(\"\\n--- Profiling Results for Training Phase ---\")\n","      training_time = time.time() - start_time  # Calculate elapsed time\n","      max_train_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","      print(f'Time: {training_time}\\nMax memory: {max_train_memory}')\n","      torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","      start_time = time.time()\n","      print(\"\\n--- Profiling Results for Validation Phase ---\")\n","\n","    dev_loss, dev_acc, connected_acc, isolated_acc = validate(model, val_sampler, criterion)\n","\n","    if trace:\n","      validation_time = time.time() - start_time  # Calculate elapsed time\n","      max_validation_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","      print(f'Time: {validation_time}\\nMax memory: {max_validation_memory}')\n","\n","    # Store epoch stats\n","    train_losses.append(train_loss)\n","    train_accuracy.append(train_acc)\n","    dev_losses.append(dev_loss)\n","    dev_accuracy.append(dev_acc)\n","    connected_accuracy.append(connected_acc.item())\n","    isolated_accuracy.append(isolated_acc)\n","    epoch_holder.append(epoch + 1)\n","\n","    # check for improvement\n","    if connected_acc > current_best:\n","      current_best = connected_acc\n","      no_improvement = 0\n","    else:\n","      no_improvement += 1\n","\n","    # save best model\n","    if connected_acc > max_accuracy:\n","      torch.save(model.state_dict(), path)\n","      max_accuracy = connected_acc\n","\n","\n","    # optionally print epoch results\n","    if verbose == 2:\n","      print(f'\\n --------- \\nEpoch: {epoch + 1}\\n')\n","      print(f'Epoch {epoch + 1} train loss: {train_loss:.4f}')\n","      print(f'Epoch {epoch + 1} train accuracy: {train_acc:.4f}')\n","      print(f'Epoch {epoch + 1} dev loss: {dev_loss:.4f}')\n","      print(f'Epoch {epoch + 1} dev accuracy: {dev_acc:.4f}')\n","      print(f'Epoch {epoch + 1} connected accuracy: {connected_acc:.4f}')\n","      print(f'Epoch {epoch + 1} isolated accuracy: {isolated_acc:.4f}')\n","\n","\n","\n","      # save best results\n","  #print('T',connected_accuracy)\n","  max_ind = np.argmax(connected_accuracy)\n","\n","  stats = Stats(\n","      train_losses[max_ind],\n","      train_accuracy[max_ind],\n","      dev_losses[max_ind],\n","      dev_accuracy[max_ind],\n","      connected_accuracy[max_ind],\n","      isolated_accuracy[max_ind],\n","      epoch_holder[max_ind],\n","      lr, alpha,\n","      max_accuracy\n","  )\n","\n","  # optionally print model results\n","  if verbose in [1,2]:\n","    print('\\n ######## \\n')\n","    print(f'lr:{stats.lr}, alpha:{stats.alpha} @ epoch {stats.epoch}.')\n","    print(f'TL:{stats.train_loss}, TA:{stats.train_accuracy}.')\n","    print(f'DL:{stats.dev_loss}, DA:{stats.dev_accuracy}')\n","    print(f'con_acc:{stats.connected_accuracy}, iso_acc:{stats.isolated_accuracy}')\n","\n","\n","  return stats"],"metadata":{"id":"1z16rqE1nh0d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### $\\color{red}{Sanity-check:}$"],"metadata":{"id":"PLt297-koEFq"}},{"cell_type":"code","source":["from collections import namedtuple\n","Stats = namedtuple('Stats', [\n","    'train_loss',\n","    'train_accuracy',\n","    'dev_loss',\n","    'dev_accuracy',\n","    'connected_accuracy',\n","    'isolated_accuracy',\n","    'epoch',\n","    'lr',\n","    'alpha',\n","    'max_accuracy'\n","])"],"metadata":{"id":"Gr0gpKwVnT47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tv_run(epochs=8, model=model, lr=0.00005, alpha=0.005, max_accuracy=0, path=\"binme2\", verbose=2)"],"metadata":{"id":"dQipohINoMe1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_config(lr_low, lr_high, alpha_low, alpha_high):\n","  np.random.seed()\n","  lr = round(10**float(np.random.uniform(lr_low,lr_high)),6)\n","  alpha = round(10**float(np.random.uniform(alpha_low,alpha_high)),6)\n","  return lr, alpha"],"metadata":{"id":"Cxz7XYn2nXL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_ranges( lr, lr_range, alpha, alpha_range):\n","\n","  lr_center = lr\n","  lr_low = lr_center - lr_range/2\n","  lr_high = lr_center + lr_range/2\n","  lr_diff = lr_high - lr_low\n","\n","  alpha_center = alpha\n","  alpha_low = alpha_center - alpha_range/2\n","  alpha_high = alpha_center + alpha_range/2\n","  alpha_diff = alpha_high - alpha_low\n","\n","  return (lr_low, lr_high, alpha_low, alpha_high)"],"metadata":{"id":"7tfL9PPQnZyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def search_stats(results):\n","  best_stats = None\n","  max_dev_accuracy = 0\n","  for i in range(len(results)):\n","    acc = results[i].dev_accuracy\n","    if acc > max_dev_accuracy:\n","      best_stats = results[i]\n","      max_dev_accuracy = acc\n","  return best_stats"],"metadata":{"id":"bb0vRh3Vnd-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs = 60\n","max_accuracy = 0\n","path = \"class/models/GNN_geom_distance.4.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -5\n","lr_high = -3\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -2\n","alpha_range = alpha_high - alpha_low\n","\n","d = 768\n","h = 400\n","c = 70\n","num_relations = 2\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(4):\n","  # debug\n","  print(\"\\n################\\n\")\n","  print(f'round: {i}')\n","  # print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  # print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print('max', max_accuracy)\n","  print(\"\\n################\\n\")\n","\n","\n","  for j in range(6):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha = gen_config(lr_low, lr_high, alpha_low, alpha_high)\n","    # define model\n","    model = GNNModel(d,h,c)\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 1)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range)\n","  lr_low, lr_high, alpha_low, alpha_high = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKK2OQbS58M4","outputId":"b272229c-90df-4f25-9c25-1543597130cc","executionInfo":{"status":"ok","timestamp":1738751867426,"user_tz":-60,"elapsed":706271,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","################\n","\n","round: 0\n","max 0\n","\n","################\n","\n","1\n","T [0.00917431153357029, 0.12614677846431732, 0.24541282653808594, 0.28669723868370056, 0.36467888951301575, 0.39678898453712463, 0.4266054928302765, 0.45642200112342834, 0.4816513657569885, 0.5137614607810974, 0.5321100950241089, 0.5481651425361633, 0.5596330165863037, 0.5779816508293152, 0.5940366983413696, 0.60550457239151, 0.6100917458534241, 0.6100917458534241, 0.6146788597106934, 0.6146788597106934, 0.6169724464416504, 0.6238532066345215, 0.6330274939537048, 0.6376146674156189, 0.6376146674156189, 0.6353210806846619, 0.6444953680038452, 0.6513761281967163, 0.6490825414657593, 0.6444953680038452, 0.6444953680038452, 0.6376146674156189, 0.6467889547348022, 0.6513761281967163]\n","\n"," ######## \n","\n","lr:5.2e-05, alpha:0.002825 @ epoch 28.\n","TL:0.46861774086952207, TA:0.8937791779287226.\n","DL:1.698555827140808, DA:0.5549792647361755\n","con_acc:0.6513761281967163, iso_acc:0.4753788113594055\n","2\n","T [0.0, 0.12155962735414505, 0.23853209614753723, 0.3096330165863037, 0.3692660331726074, 0.408256858587265, 0.45183485746383667, 0.4747706353664398, 0.49541282653808594, 0.5022935271263123, 0.5344036221504211, 0.5527522563934326, 0.5802751779556274, 0.5940366983413696, 0.600917398929596, 0.6100917458534241, 0.6123852729797363, 0.6192660331726074, 0.6215596199035645, 0.6192660331726074, 0.6261467337608337, 0.6284403204917908, 0.6399082541465759, 0.6330274939537048, 0.6284403204917908, 0.6307339072227478, 0.6467889547348022, 0.6444953680038452, 0.6467889547348022, 0.6376146674156189, 0.6467889547348022, 0.6444953680038452, 0.6376146674156189]\n","\n"," ######## \n","\n","lr:5.5e-05, alpha:2.7e-05 @ epoch 27.\n","TL:0.4564515718391963, TA:0.8956821024273811.\n","DL:1.7085509300231934, DA:0.5570539832115173\n","con_acc:0.6467889547348022, iso_acc:0.48295456171035767\n","3\n","T [0.01834862306714058, 0.18577980995178223, 0.2545871436595917, 0.353210985660553, 0.40366971492767334, 0.4541284143924713, 0.4816513657569885, 0.5252293348312378, 0.5435779690742493, 0.5711008906364441, 0.5940366983413696, 0.6169724464416504, 0.6238532066345215, 0.6215596199035645, 0.6399082541465759, 0.6422017812728882, 0.6490825414657593, 0.6444953680038452, 0.6513761281967163, 0.6605504155158997, 0.6697247624397278, 0.6559633016586304, 0.6697247624397278, 0.6559633016586304, 0.6697247624397278, 0.6674311757087708, 0.6628440022468567]\n","\n"," ######## \n","\n","lr:8.5e-05, alpha:0.000728 @ epoch 21.\n","TL:0.3558434706074851, TA:0.9208986622566809.\n","DL:1.6453458070755005, DA:0.5778008699417114\n","con_acc:0.6697247624397278, iso_acc:0.501893937587738\n","4\n","T [0.03211009129881859, 0.30504587292671204, 0.4013761281967163, 0.4793577790260315, 0.5504586696624756, 0.5963302254676819, 0.6353210806846619, 0.6261467337608337, 0.6536697149276733, 0.6444953680038452, 0.6674311757087708, 0.6490825414657593, 0.6605504155158997, 0.6490825414657593, 0.6559633016586304, 0.6536697149276733, 0.6559633016586304]\n","\n"," ######## \n","\n","lr:0.000337, alpha:0.0091 @ epoch 11.\n","TL:0.21919480093887875, TA:0.950621862760638.\n","DL:1.643255352973938, DA:0.5850622653961182\n","con_acc:0.6674311757087708, iso_acc:0.5170454978942871\n","5\n","T [0.00917431153357029, 0.15366971492767334, 0.2614678740501404, 0.3348623812198639, 0.3692660331726074, 0.41055044531822205, 0.4541284143924713, 0.49541282653808594, 0.5229357481002808, 0.5344036221504211, 0.5711008906364441, 0.5871559381484985, 0.60550457239151, 0.6123852729797363, 0.6192660331726074, 0.6146788597106934, 0.6261467337608337, 0.6215596199035645, 0.6215596199035645, 0.6215596199035645, 0.6192660331726074, 0.6215596199035645, 0.6261467337608337]\n","\n"," ######## \n","\n","lr:6.9e-05, alpha:0.002982 @ epoch 17.\n","TL:0.6631287479400635, TA:0.8461069263562137.\n","DL:1.7966630458831787, DA:0.5404564738273621\n","con_acc:0.6261467337608337, iso_acc:0.4696969985961914\n","6\n","T [0.01834862306714058, 0.04816513508558273, 0.17889907956123352, 0.24541282653808594, 0.27293577790260315, 0.30504587292671204, 0.31880733370780945, 0.3417431116104126, 0.3669724464416504, 0.39678898453712463, 0.4128440320491791, 0.4449540972709656, 0.44954127073287964, 0.46330273151397705, 0.4724770486354828, 0.48394492268562317, 0.49770641326904297, 0.5114678740501404, 0.5229357481002808, 0.5298165082931519, 0.5298165082931519, 0.5458715558052063, 0.5481651425361633, 0.5550458431243896, 0.56651371717453, 0.5688073039054871, 0.5825687646865845, 0.5871559381484985, 0.5894495248794556, 0.5917431116104126, 0.5894495248794556, 0.5894495248794556, 0.5940366983413696, 0.603210985660553, 0.603210985660553, 0.603210985660553, 0.5963302254676819, 0.607798159122467, 0.6123852729797363, 0.60550457239151, 0.6123852729797363, 0.6100917458534241, 0.6146788597106934, 0.6123852729797363, 0.6146788597106934, 0.6123852729797363, 0.6169724464416504, 0.6192660331726074, 0.6215596199035645, 0.6238532066345215, 0.6284403204917908, 0.6284403204917908, 0.6307339072227478, 0.6238532066345215, 0.6215596199035645, 0.6238532066345215, 0.6330274939537048, 0.6284403204917908, 0.6284403204917908, 0.6238532066345215]\n","\n"," ######## \n","\n","lr:2.4e-05, alpha:0.000695 @ epoch 57.\n","TL:0.7003083920478821, TA:0.8327094962207116.\n","DL:1.836340069770813, DA:0.5290456414222717\n","con_acc:0.6330274939537048, iso_acc:0.4431818425655365\n","Stats(train_loss=0.21919480093887875, train_accuracy=0.950621862760638, dev_loss=tensor(1.6433, device='cuda:0'), dev_accuracy=tensor(0.5851, device='cuda:0'), connected_accuracy=0.6674311757087708, isolated_accuracy=tensor(0.5170, device='cuda:0'), epoch=11, lr=0.000337, alpha=0.0091, max_accuracy=tensor(0.6697, device='cuda:0'))\n","\n","################\n","\n","round: 1\n","max tensor(0.6697, device='cuda:0')\n","\n","################\n","\n","7\n","T [0.011467888951301575, 0.3165137469768524, 0.41743117570877075, 0.5298165082931519, 0.5894495248794556, 0.6123852729797363, 0.6490825414657593, 0.6536697149276733, 0.6399082541465759, 0.6720183491706848, 0.6788990497589111, 0.6766054630279541, 0.6582568287849426, 0.6674311757087708, 0.6559633016586304, 0.6582568287849426, 0.6788990497589111]\n","\n"," ######## \n","\n","lr:0.000404, alpha:0.012479 @ epoch 11.\n","TL:0.1854664744223867, TA:0.9573435845936216.\n","DL:1.6578500270843506, DA:0.5923236608505249\n","con_acc:0.6788990497589111, iso_acc:0.5208333730697632\n","8\n","T [0.016055045649409294, 0.23165136575698853, 0.3463302552700043, 0.4449540972709656, 0.5114678740501404, 0.5619266033172607, 0.6169724464416504, 0.5986238121986389, 0.6284403204917908, 0.6307339072227478, 0.6513761281967163, 0.6284403204917908, 0.6444953680038452, 0.6559633016586304, 0.6559633016586304, 0.6766054630279541, 0.6559633016586304, 0.6490825414657593, 0.6513761281967163, 0.6582568287849426, 0.6628440022468567, 0.6605504155158997]\n","\n"," ######## \n","\n","lr:0.000203, alpha:0.018669 @ epoch 16.\n","TL:0.17428424886294774, TA:0.9618250633829575.\n","DL:1.6245476007461548, DA:0.5860996246337891\n","con_acc:0.6766054630279541, iso_acc:0.5113636255264282\n","9\n","T [0.00917431153357029, 0.27293577790260315, 0.37844035029411316, 0.45183485746383667, 0.5275229215621948, 0.5802751779556274, 0.603210985660553, 0.600917398929596, 0.6284403204917908, 0.6536697149276733, 0.6467889547348022, 0.6444953680038452, 0.6467889547348022, 0.6582568287849426, 0.6582568287849426, 0.6490825414657593, 0.6536697149276733, 0.6651375889778137, 0.6766054630279541, 0.6651375889778137, 0.6697247624397278, 0.6834862232208252, 0.6720183491706848, 0.6674311757087708, 0.6788990497589111, 0.6628440022468567, 0.6743118762969971, 0.6720183491706848]\n","\n"," ######## \n","\n","lr:0.000248, alpha:0.007789 @ epoch 22.\n","TL:0.06632769067372594, TA:0.9863984784837481.\n","DL:1.7006865739822388, DA:0.6099585294723511\n","con_acc:0.6834862232208252, iso_acc:0.5492424368858337\n","10\n","T [0.025229357182979584, 0.33027520775794983, 0.45642200112342834, 0.5550458431243896, 0.6123852729797363, 0.6353210806846619, 0.6330274939537048, 0.6444953680038452, 0.6467889547348022, 0.6513761281967163, 0.6651375889778137, 0.6674311757087708, 0.6444953680038452, 0.6651375889778137, 0.6857798099517822, 0.6743118762969971, 0.6628440022468567, 0.6720183491706848, 0.6788990497589111, 0.6811926364898682, 0.6605504155158997]\n","\n"," ######## \n","\n","lr:0.000549, alpha:0.006699 @ epoch 15.\n","TL:0.09127288622515542, TA:0.9776003757373233.\n","DL:1.7978469133377075, DA:0.6058091521263123\n","con_acc:0.6857798099517822, iso_acc:0.5397727489471436\n","11\n","T [0.013761467300355434, 0.24082568287849426, 0.36467888951301575, 0.45183485746383667, 0.5091742873191833, 0.5458715558052063, 0.600917398929596, 0.607798159122467, 0.6353210806846619, 0.6444953680038452, 0.6376146674156189, 0.6490825414657593, 0.6422017812728882, 0.6490825414657593, 0.6582568287849426, 0.6490825414657593, 0.6651375889778137, 0.6490825414657593, 0.6513761281967163, 0.6536697149276733, 0.6559633016586304, 0.6651375889778137, 0.6766054630279541, 0.6697247624397278, 0.6605504155158997, 0.6651375889778137, 0.6720183491706848, 0.6674311757087708, 0.6697247624397278]\n","\n"," ######## \n","\n","lr:0.000211, alpha:0.010462 @ epoch 23.\n","TL:0.07559206047228405, TA:0.9840324068488159.\n","DL:1.6777241230010986, DA:0.5985477566719055\n","con_acc:0.6766054630279541, iso_acc:0.5340909361839294\n","12\n","T [0.011467888951301575, 0.2637614607810974, 0.35091742873191833, 0.42431190609931946, 0.49770641326904297, 0.5527522563934326, 0.5871559381484985, 0.60550457239151, 0.6330274939537048, 0.6399082541465759, 0.6422017812728882, 0.6399082541465759, 0.6559633016586304, 0.6422017812728882, 0.6422017812728882, 0.6536697149276733, 0.6513761281967163, 0.6536697149276733, 0.6536697149276733]\n","\n"," ######## \n","\n","lr:0.000193, alpha:0.007527 @ epoch 13.\n","TL:0.2865520874091557, TA:0.9361591306639798.\n","DL:1.6352980136871338, DA:0.5778008699417114\n","con_acc:0.6559633016586304, iso_acc:0.5132575631141663\n","Stats(train_loss=0.06632769067372594, train_accuracy=0.9863984784837481, dev_loss=tensor(1.7007, device='cuda:0'), dev_accuracy=tensor(0.6100, device='cuda:0'), connected_accuracy=0.6834862232208252, isolated_accuracy=tensor(0.5492, device='cuda:0'), epoch=22, lr=0.000248, alpha=0.007789, max_accuracy=tensor(0.6835, device='cuda:0'))\n","\n","################\n","\n","round: 2\n","max tensor(0.6858, device='cuda:0')\n","\n","################\n","\n","13\n","T [0.004587155766785145, 0.2637614607810974, 0.3807339370250702, 0.4587155878543854, 0.5435779690742493, 0.5779816508293152, 0.6100917458534241, 0.6307339072227478, 0.6536697149276733, 0.6513761281967163, 0.6307339072227478, 0.6422017812728882, 0.6720183491706848, 0.6536697149276733, 0.6582568287849426, 0.6536697149276733, 0.6605504155158997, 0.6605504155158997, 0.6605504155158997]\n","\n"," ######## \n","\n","lr:0.000245, alpha:0.008324 @ epoch 13.\n","TL:0.2132299485376903, TA:0.9528442148730696.\n","DL:1.6346670389175415, DA:0.5964730381965637\n","con_acc:0.6720183491706848, iso_acc:0.5340909361839294\n","14\n","T [0.016055045649409294, 0.2637614607810974, 0.37614676356315613, 0.4220183193683624, 0.5045871138572693, 0.5596330165863037, 0.5802751779556274, 0.60550457239151, 0.6192660331726074, 0.6330274939537048, 0.6513761281967163, 0.6467889547348022, 0.6536697149276733, 0.6628440022468567, 0.6467889547348022, 0.6766054630279541, 0.6811926364898682, 0.6536697149276733, 0.6490825414657593, 0.6720183491706848, 0.6720183491706848, 0.6697247624397278, 0.6674311757087708]\n","\n"," ######## \n","\n","lr:0.000208, alpha:0.009753 @ epoch 17.\n","TL:0.1451280135342053, TA:0.9696706100716362.\n","DL:1.6768836975097656, DA:0.5975103974342346\n","con_acc:0.6811926364898682, iso_acc:0.5284091234207153\n","15\n","T [0.02752293460071087, 0.2499999850988388, 0.3692660331726074, 0.4128440320491791, 0.5022935271263123, 0.5573394298553467, 0.6169724464416504, 0.607798159122467, 0.6215596199035645, 0.6307339072227478, 0.6399082541465759, 0.6307339072227478, 0.6605504155158997, 0.6605504155158997, 0.6536697149276733, 0.6605504155158997, 0.6444953680038452, 0.6720183491706848, 0.6651375889778137, 0.6720183491706848, 0.6674311757087708, 0.6628440022468567, 0.6651375889778137, 0.6697247624397278]\n","\n"," ######## \n","\n","lr:0.000205, alpha:0.006452 @ epoch 18.\n","TL:0.13244238193546023, TA:0.9715848659470818.\n","DL:1.6736036539077759, DA:0.5881742835044861\n","con_acc:0.6720183491706848, iso_acc:0.5189394354820251\n","16\n","T [0.011467888951301575, 0.300458699464798, 0.3669724464416504, 0.44954127073287964, 0.5206421613693237, 0.564220130443573, 0.5986238121986389, 0.6123852729797363, 0.6261467337608337, 0.6192660331726074, 0.6490825414657593, 0.6399082541465759, 0.6444953680038452, 0.6513761281967163, 0.6376146674156189, 0.6582568287849426, 0.6513761281967163, 0.6651375889778137, 0.6651375889778137, 0.6605504155158997, 0.6697247624397278, 0.6674311757087708, 0.6720183491706848, 0.6788990497589111, 0.6628440022468567, 0.6743118762969971, 0.6743118762969971, 0.6697247624397278, 0.6766054630279541, 0.6674311757087708]\n","\n"," ######## \n","\n","lr:0.000194, alpha:0.006325 @ epoch 24.\n","TL:0.07885971258793559, TA:0.9831955624977642.\n","DL:1.7301050424575806, DA:0.5943983793258667\n","con_acc:0.6788990497589111, iso_acc:0.5246212482452393\n","17\n","T [0.01834862306714058, 0.2821100652217865, 0.4013761281967163, 0.4793577790260315, 0.5573394298553467, 0.5917431116104126, 0.6123852729797363, 0.6123852729797363, 0.6628440022468567, 0.6605504155158997, 0.6651375889778137, 0.6513761281967163, 0.6651375889778137, 0.6674311757087708, 0.6766054630279541, 0.6720183491706848, 0.6674311757087708, 0.6674311757087708, 0.6720183491706848, 0.6651375889778137, 0.6811926364898682, 0.6766054630279541, 0.6788990497589111, 0.6788990497589111, 0.6788990497589111, 0.6674311757087708, 0.6834862232208252, 0.6788990497589111, 0.6834862232208252, 0.6788990497589111, 0.6766054630279541, 0.6743118762969971, 0.6811926364898682]\n","\n"," ######## \n","\n","lr:0.000319, alpha:0.007079 @ epoch 27.\n","TL:0.04086269864014217, TA:0.9902180391402029.\n","DL:1.833931565284729, DA:0.6120332479476929\n","con_acc:0.6834862232208252, iso_acc:0.5530303120613098\n","18\n","T [0.011467888951301575, 0.2431192547082901, 0.36467888951301575, 0.4541284143924713, 0.5114678740501404, 0.5940366983413696, 0.6261467337608337, 0.6284403204917908, 0.6353210806846619, 0.6628440022468567, 0.6582568287849426, 0.6559633016586304, 0.6720183491706848, 0.6697247624397278, 0.6743118762969971, 0.6720183491706848, 0.6697247624397278, 0.6857798099517822, 0.6720183491706848, 0.6605504155158997, 0.6697247624397278, 0.6926605105400085, 0.6834862232208252, 0.6628440022468567, 0.6857798099517822, 0.6903669238090515, 0.6834862232208252, 0.6834862232208252]\n","\n"," ######## \n","\n","lr:0.000241, alpha:0.006908 @ epoch 22.\n","TL:0.07264607556164265, TA:0.9840093830909681.\n","DL:1.7026376724243164, DA:0.613070547580719\n","con_acc:0.6926605105400085, iso_acc:0.5473484992980957\n","Stats(train_loss=0.07264607556164265, train_accuracy=0.9840093830909681, dev_loss=tensor(1.7026, device='cuda:0'), dev_accuracy=tensor(0.6131, device='cuda:0'), connected_accuracy=0.6926605105400085, isolated_accuracy=tensor(0.5473, device='cuda:0'), epoch=22, lr=0.000241, alpha=0.006908, max_accuracy=tensor(0.6927, device='cuda:0'))\n","\n","################\n","\n","round: 3\n","max tensor(0.6927, device='cuda:0')\n","\n","################\n","\n","19\n","T [0.016055045649409294, 0.2958715558052063, 0.37155961990356445, 0.45183485746383667, 0.5298165082931519, 0.56651371717453, 0.603210985660553, 0.6100917458534241, 0.6100917458534241, 0.6444953680038452, 0.6559633016586304, 0.6467889547348022, 0.6766054630279541, 0.6490825414657593, 0.6697247624397278, 0.6582568287849426, 0.6743118762969971, 0.6628440022468567, 0.6674311757087708]\n","\n"," ######## \n","\n","lr:0.000223, alpha:0.006331 @ epoch 13.\n","TL:0.23913115186350686, TA:0.9475854641462157.\n","DL:1.6332893371582031, DA:0.5923236608505249\n","con_acc:0.6766054630279541, iso_acc:0.5227273106575012\n","20\n","T [0.01834862306714058, 0.29128438234329224, 0.37844035029411316, 0.46330273151397705, 0.5366972088813782, 0.5986238121986389, 0.600917398929596, 0.6353210806846619, 0.6261467337608337, 0.6536697149276733, 0.6444953680038452, 0.6513761281967163, 0.6582568287849426, 0.6467889547348022, 0.6720183491706848, 0.6628440022468567, 0.6697247624397278, 0.6720183491706848, 0.6582568287849426, 0.6513761281967163, 0.6857798099517822, 0.6788990497589111, 0.6697247624397278, 0.6834862232208252, 0.6605504155158997, 0.6972476840019226, 0.6720183491706848, 0.6834862232208252, 0.6834862232208252, 0.6628440022468567, 0.6743118762969971, 0.6811926364898682]\n","\n"," ######## \n","\n","lr:0.000242, alpha:0.00735 @ epoch 26.\n","TL:0.05208699264696666, TA:0.9892178139152221.\n","DL:1.7426588535308838, DA:0.6120332479476929\n","con_acc:0.6972476840019226, iso_acc:0.5416666865348816\n","21\n","T [0.006880733650177717, 0.2752293348312378, 0.39220181107521057, 0.4541284143924713, 0.5573394298553467, 0.603210985660553, 0.6100917458534241, 0.6169724464416504, 0.6261467337608337, 0.6215596199035645, 0.6238532066345215, 0.6307339072227478, 0.6490825414657593, 0.6330274939537048, 0.6399082541465759, 0.6536697149276733, 0.6536697149276733, 0.6536697149276733, 0.6651375889778137, 0.6628440022468567, 0.6628440022468567, 0.6605504155158997, 0.6766054630279541, 0.6674311757087708, 0.6743118762969971, 0.6513761281967163, 0.6628440022468567, 0.6559633016586304, 0.6743118762969971]\n","\n"," ######## \n","\n","lr:0.000254, alpha:0.007445 @ epoch 23.\n","TL:0.06351263050522123, TA:0.986359881347303.\n","DL:1.6997177600860596, DA:0.610995888710022\n","con_acc:0.6766054630279541, iso_acc:0.5568181872367859\n","22\n","T [0.016055045649409294, 0.28440365195274353, 0.3990825414657593, 0.4747706353664398, 0.5504586696624756, 0.6123852729797363, 0.6100917458534241, 0.6330274939537048, 0.6399082541465759, 0.6513761281967163, 0.6651375889778137, 0.6605504155158997, 0.6674311757087708, 0.6674311757087708, 0.6536697149276733, 0.6697247624397278, 0.6513761281967163, 0.6697247624397278, 0.6697247624397278, 0.6651375889778137, 0.6697247624397278, 0.6697247624397278]\n","\n"," ######## \n","\n","lr:0.000252, alpha:0.007142 @ epoch 16.\n","TL:0.1301062426822526, TA:0.9724512146151897.\n","DL:1.7259855270385742, DA:0.5829876065254211\n","con_acc:0.6697247624397278, iso_acc:0.5113636255264282\n","23\n","T [0.00917431153357029, 0.2821100652217865, 0.38302749395370483, 0.4541284143924713, 0.5229357481002808, 0.5733944773674011, 0.603210985660553, 0.6284403204917908, 0.6353210806846619, 0.6536697149276733, 0.6353210806846619, 0.6582568287849426, 0.6605504155158997, 0.6697247624397278, 0.6559633016586304, 0.6788990497589111, 0.6766054630279541, 0.6788990497589111, 0.6811926364898682, 0.6880733370780945, 0.6674311757087708, 0.6743118762969971, 0.6720183491706848, 0.6926605105400085, 0.6857798099517822, 0.6743118762969971, 0.6720183491706848, 0.6743118762969971, 0.6811926364898682, 0.6926605105400085]\n","\n"," ######## \n","\n","lr:0.000253, alpha:0.006182 @ epoch 24.\n","TL:0.05790837381567274, TA:0.9867626661229846.\n","DL:1.747822880744934, DA:0.6120332479476929\n","con_acc:0.6926605105400085, iso_acc:0.5454545617103577\n","24\n","T [0.016055045649409294, 0.2637614607810974, 0.38532108068466187, 0.4449540972709656, 0.5321100950241089, 0.5825687646865845, 0.6123852729797363, 0.6376146674156189, 0.6399082541465759, 0.6582568287849426, 0.6651375889778137, 0.6582568287849426, 0.6788990497589111, 0.6743118762969971, 0.6697247624397278, 0.6720183491706848, 0.6857798099517822, 0.6766054630279541, 0.6857798099517822, 0.6903669238090515, 0.6788990497589111, 0.6811926364898682, 0.6834862232208252, 0.6880733370780945, 0.6995412707328796, 0.6788990497589111, 0.6926605105400085, 0.6926605105400085, 0.6857798099517822, 0.6949540972709656, 0.6880733370780945]\n","\n"," ######## \n","\n","lr:0.000243, alpha:0.007317 @ epoch 25.\n","TL:0.05605664350092411, TA:0.9877094920239886.\n","DL:1.6933140754699707, DA:0.6161826252937317\n","con_acc:0.6995412707328796, iso_acc:0.5473484992980957\n","Stats(train_loss=0.05605664350092411, train_accuracy=0.9877094920239886, dev_loss=tensor(1.6933, device='cuda:0'), dev_accuracy=tensor(0.6162, device='cuda:0'), connected_accuracy=0.6995412707328796, isolated_accuracy=tensor(0.5473, device='cuda:0'), epoch=25, lr=0.000243, alpha=0.007317, max_accuracy=tensor(0.6995, device='cuda:0'))\n"]}]}]}