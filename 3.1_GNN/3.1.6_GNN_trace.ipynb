{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fIg-5fDJcWOwPIlKWUZr6uy0Xhz08FJK","timestamp":1737028047757},{"file_id":"1Q8SwOiR2bxtadXJeoC2c-bHDAG6P_HtL","timestamp":1736848209859}],"machine_shape":"hm","gpuType":"L4","collapsed_sections":["gQKaLkU1jxOb"],"authorship_tag":"ABX9TyOOk71rchsPjQGfBz0kIQCm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Text Classification - Training a GNN\n"],"metadata":{"id":"FBjat8lrIEsf"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","1.   Admin\n","2.   Dataset\n","3.   Model\n","4.   Train - Validate\n","5.   Training Loop"],"metadata":{"id":"O5wHwOnkIKvx"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","We now train a GNN in basic PyTorch. The model will look like a GCN. Inference willbe completed in another notebook as the whole graph must be uploaded at once."],"metadata":{"id":"2LYAHLRYIY_C"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"udtGvzIPItVT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vfqeSzgDH285","executionInfo":{"status":"ok","timestamp":1737041601044,"user_tz":-60,"elapsed":4194,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"24a5b7b0-5b95-4157-8179-dc1e624cb39d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSXQ2wAfPWoF","executionInfo":{"status":"ok","timestamp":1737041625370,"user_tz":-60,"elapsed":24331,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"60a8dec3-0a14-4a31-a39c-7cead2bad81f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data\n","* Load adjacency matrices"],"metadata":{"id":"q4Mn5bkiJDE8"}},{"cell_type":"code","source":["path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train')\n","df_dev = pd.read_pickle(path + 'df_dev')\n","df_test = pd.read_pickle(path + 'df_test')"],"metadata":{"id":"gPwH-5O5JHeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = 'class/tensors/adj_{}.pt'\n","\n","# train\n","train_people = torch.load(path.format('train_people'))\n","train_locations = torch.load(path.format('train_locations'))\n","train_entities = torch.load(path.format('train_entities'))\n","\n","# dev\n","dev_people = torch.load(path.format('dev_people'))\n","dev_locations = torch.load(path.format('dev_locations'))\n","dev_entities = torch.load(path.format('dev_entities'))\n","\n","# val (contains the adjacency matrix for both the training and the development set)\n","val_people = torch.load(path.format('val_people.1'))\n","val_locations = torch.load(path.format('val_locations.1'))\n","val_entities = torch.load(path.format('val_entities.1'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXpjrdiiJSO0","executionInfo":{"status":"ok","timestamp":1737041710840,"user_tz":-60,"elapsed":54058,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"abb38104-5d22-49fd-c7c3-adbe3774dfa1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-6f8839527fd4>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_people = torch.load(path.format('train_people'))\n","<ipython-input-4-6f8839527fd4>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_locations = torch.load(path.format('train_locations'))\n","<ipython-input-4-6f8839527fd4>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_entities = torch.load(path.format('train_entities'))\n","<ipython-input-4-6f8839527fd4>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_people = torch.load(path.format('dev_people'))\n","<ipython-input-4-6f8839527fd4>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_locations = torch.load(path.format('dev_locations'))\n","<ipython-input-4-6f8839527fd4>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_entities = torch.load(path.format('dev_entities'))\n","<ipython-input-4-6f8839527fd4>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_people = torch.load(path.format('val_people.1'))\n","<ipython-input-4-6f8839527fd4>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_locations = torch.load(path.format('val_locations.1'))\n","<ipython-input-4-6f8839527fd4>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_entities = torch.load(path.format('val_entities.1'))\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Sampling:}$"],"metadata":{"id":"Tml4hS4iKIGX"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from copy import deepcopy\n","\n","def sample_neighborhood(primary_inds, input, adj, distance, neighbor_max = 4):\n","    \"\"\"\n","    Takes the given inds and the inputs, returns the sampled set of indices and the corresponding activation flag.\n","    If the activation flag is True, then the the datapoint is primary and has been search for neighbors and neighbors\n","    of neighbors. This indicates that we rely on the datapoint for metrics and loss.\n","\n","    Args:\n","      primary_inds : iterable\n","          indices sampled by the dataloader\n","      input : torch.Tensor\n","          (m,d) input tensor\n","      adj : torch.Tensor\n","          (m,m) adjacency matrix\n","      distance : torch.Tensor\n","          (m,m) : cosine similarity between all inputs\n","      neighbour_max : int (optional)\n","          The maximum number of neighbors to consider for each point\n","\n","    Returns:\n","      sampled_indices : list\n","          indices of all datapoints to be processed in the batch\n","      activation_flag : list\n","          boolean_flag indicating whether the corresponding datapoint is to be considered for metrics\n","    \"\"\"\n","\n","    def _get_closest_neighbors(ind):\n","      \"\"\"get up to neighbor_max close neighbors\"\"\"\n","      local_neighbors = []\n","      local_activation_flag = []\n","      candidate_neighbors = [neighbor.item() for neighbor in (adj[ind] > 0).nonzero(as_tuple=True)[0] if neighbor.item() not in sampled_indices]\n","      candidate_distances = [(neighbor, distance[primary_ind][neighbor]) for neighbor in candidate_neighbors]\n","      sorted_neighbors = sorted(candidate_distances, key=lambda x: x[1])\n","      return [neighbor for neighbor, dist in sorted_neighbors[:neighbor_max]], candidate_neighbors\n","\n","    sampled_indices = []\n","    activation_flag = []\n","    all_banned_neighbors = []\n","\n","    for primary_ind in primary_inds:\n","\n","      # if primary ind has been added as a neighbor, convert the activation flag to true, else add it as a standard primary index\n","      if primary_ind in sampled_indices:\n","        activation_flag[sampled_indices.index(primary_ind)] = True\n","      else:\n","        sampled_indices.append(primary_ind)\n","        activation_flag.append(True)\n","\n","      # print('\\n', primary_ind)\n","      # print('sampled_indices', sampled_indices)\n","\n","      level_1_neighbors, candidate_neighbors = _get_closest_neighbors(primary_ind)\n","      banned_neighbors = list(set(candidate_neighbors) - set(level_1_neighbors))\n","      all_banned_neighbors.extend(banned_neighbors)\n","      # print('banned_neighbors', banned_neighbors)\n","      # print('all_banned_neighbors', all_banned_neighbors)\n","\n","      level_1_activation_flag = [False for el in level_1_neighbors]\n","      sampled_indices.extend(level_1_neighbors)\n","      activation_flag.extend(level_1_activation_flag)\n","\n","      # print('level_1_neighbors', level_1_neighbors)\n","      # print('sampled_indices', sampled_indices)\n","      # print('level_1_activation_flag', level_1_activation_flag)\n","      # print('activation_flag', activation_flag)\n","\n","      for level_1_ind in level_1_neighbors:\n","        level_2_neighbors, _ = _get_closest_neighbors(level_1_ind)\n","        level_2_activation_flag = [False for el in level_2_neighbors]\n","        sampled_indices.extend(level_2_neighbors)\n","        activation_flag.extend(level_2_activation_flag)\n","\n","        # print('level_2_neighbors', level_2_neighbors)\n","        # print('sampled_indices', sampled_indices)\n","        # print('level_2_activation_flag', level_2_activation_flag)\n","        # print('activation_flag', activation_flag)\n","\n","    # include only 4 level one neighbors for each primary index to avoid pollution\n","    clean_indices = []\n","    clean_flags = []\n","    for i in range(len(sampled_indices)):\n","      target = sampled_indices[i]\n","      if target in primary_inds:\n","        clean_indices.append(target)\n","        clean_flags.append(True)\n","      elif target in all_banned_neighbors:\n","        continue\n","      else:\n","        clean_indices.append(target)\n","        clean_flags.append(False)\n","    # print(f'\\ncleaning\\nsampled_indices : {sampled_indices}\\nclean_indices : {clean_indices}')\n","    return clean_indices, clean_flags\n"],"metadata":{"id":"wvPKQX4B_k9J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Sampling Test:}$"],"metadata":{"id":"gQKaLkU1jxOb"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","a = torch.Tensor([\n","    [0,1,0,0,0,0,0,1],\n","    [1,0,0,1,0,1,0,0],\n","    [0,1,0,1,0,0,1,0],\n","    [0,1,0,0,1,0,0,1],\n","    [1,1,0,0,1,0,0,0],\n","    [0,0,1,1,0,1,1,0],\n","    [0,0,0,1,0,0,0,1],\n","    [0,0,0,1,0,1,1,1]\n","])\n","\n","seed=42"],"metadata":{"id":"B5qimRXRPy4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","def neighbor_analysis(primary_inds: list[int], inds: list[int], adjacency_matrix: torch.Tensor):\n","    result = []\n","\n","    # Loop over each primary index\n","    for primary_idx in primary_inds:\n","        # Get neighbors for the primary index\n","        neighbors = []\n","        for ind in inds:\n","            # Check if ind is a neighbor of primary_idx\n","            if adjacency_matrix[primary_idx, ind] == 1:\n","                neighbors.append(ind)\n","\n","        # Find neighbors of neighbors (n + 1 neighbors)\n","        neighbors_of_neighbors = []\n","        for neighbor in neighbors:\n","            for ind in inds:\n","                # Check if ind is a neighbor of the current neighbor\n","                if adjacency_matrix[neighbor, ind] == 1 and ind != primary_idx:\n","                    neighbors_of_neighbors.append(ind)\n","\n","        # Remove duplicates for the neighbors of neighbors\n","        neighbors_of_neighbors = list(set(neighbors_of_neighbors))\n","\n","        # Add the tuple to results\n","        result.append((primary_idx, neighbors, neighbors_of_neighbors))\n","\n","    return result"],"metadata":{"id":"pj2hFslUIQu5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["primary_inds, input, adj, distance,"],"metadata":{"id":"efRNifUCP2zI"}},{"cell_type":"code","source":["def calculate_cosine(H):\n","    dot_product = torch.matmul(H, H.transpose(0, 1))  # shape (m, m)\n","\n","    lengths = torch.sqrt(dot_product.diagonal()).unsqueeze(1)  # shape (m, 1)\n","    denominator = lengths @ lengths.transpose(0, 1)  # shape (m, m)\n","\n","    return dot_product / denominator  # shape (m, m)"],"metadata":{"id":"ZnpjKIzOQI8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["H = torch.stack(list(df_train['vanilla_embedding.1']))\n"],"metadata":{"id":"nuz-dr2HQn3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["distance = calculate_cosine(H)"],"metadata":{"id":"BvI-vANjP6By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","inds = random.sample(list(range(12000)),6)\n","print(inds)\n","sample = sample_neighborhood(inds,H,train_entities,distance)\n","print(sample)\n","print(len(sample[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_FRZ_VOZt0D","executionInfo":{"status":"ok","timestamp":1736853092365,"user_tz":-60,"elapsed":538,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"09dfe984-304d-4d03-cde6-880e83d9649d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[6339, 2165, 4826, 11292, 11280, 5401]\n","\n"," 6339\n","sampled_indices [6339]\n","banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607]\n","level_1_neighbors [10087, 11957, 10768, 11320]\n","sampled_indices [6339, 10087, 11957, 10768, 11320]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False]\n","level_2_neighbors [26, 11083, 8133, 6232]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [6046, 4781, 3353, 11449]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [167, 3420, 6129, 11625]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [2143, 10461, 1226, 6948]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n"," 2165\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165]\n","banned_neighbors [11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959]\n","level_1_neighbors [6427, 8605, 4576, 8020]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False]\n","level_2_neighbors [2803, 7409, 721, 8961]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [9486, 8890, 2668, 3572]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [7502, 8615, 8959, 11]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4306, 5939, 8437, 10081]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n"," 4826\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826]\n","banned_neighbors []\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959]\n","level_1_neighbors []\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826]\n","level_1_activation_flag []\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n","\n"," 11292\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292]\n","banned_neighbors [2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959, 2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070]\n","level_1_neighbors [9235, 8778, 11085, 3998]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False]\n","level_2_neighbors [5419, 6283, 655, 10489]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4574, 3815, 2701, 2183]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [8465, 613, 2425, 8114]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [7153, 4905, 3613, 6116]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n"," 11280\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280]\n","banned_neighbors []\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959, 2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070]\n","level_1_neighbors []\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280]\n","level_1_activation_flag []\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n","\n"," 5401\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401]\n","banned_neighbors [9019, 10530, 2147, 11909, 10853, 1898, 6091, 4940, 3028, 8565, 7030, 5435, 9596, 9565, 2686]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959, 2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070, 9019, 10530, 2147, 11909, 10853, 1898, 6091, 4940, 3028, 8565, 7030, 5435, 9596, 9565, 2686]\n","level_1_neighbors [6382, 9910, 5054, 1274]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False]\n","level_2_neighbors [4028, 49, 2341, 5108]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4894, 545, 560, 1936]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4685, 11186, 4695, 8812]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [7399, 1612, 4249, 698]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612, 4249, 698]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n","cleaning\n","sampled_indices : [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612, 4249, 698]\n","clean_indices : [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 9910, 5054, 1274, 4028, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612]\n","([6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 9910, 5054, 1274, 4028, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612], [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False])\n","66\n"]}]},{"cell_type":"code","source":["analysis = neighbor_analysis(inds, sample[0], train_entities)\n","for item in analysis:\n","  print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flg7EyIjIm9X","executionInfo":{"status":"ok","timestamp":1736853171299,"user_tz":-60,"elapsed":1030,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"46cc6dec-2b5f-43b1-8b83-690dc3495939","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(6339, [10087, 11957, 10768, 11320], [8961, 10768, 26, 6427, 8605, 6948, 167, 11957, 11320, 8133, 1226, 11083, 721, 8020, 6232, 3420, 10461, 2143, 4576, 10087, 11625, 6129, 7409, 2803, 2165])\n","(2165, [10087, 6427, 8605, 4576, 8020], [8961, 10768, 26, 6427, 8605, 167, 11957, 11320, 6339, 8133, 11083, 721, 8020, 6232, 3420, 4576, 10087, 11625, 6129, 7409, 2803])\n","(4826, [], [])\n","(11292, [6129, 2143, 9235, 8778, 11085, 3998], [8961, 2183, 6283, 2701, 655, 10768, 1936, 8465, 9235, 6427, 3613, 4894, 3998, 545, 2341, 167, 2425, 4905, 5419, 560, 8114, 9910, 11320, 4028, 8778, 1612, 11085, 721, 3420, 4574, 2143, 6116, 613, 10087, 3815, 11625, 7399, 7409, 7153, 2803, 5108, 6129, 10489, 1274])\n","(11280, [], [])\n","(5401, [9910, 5054, 1274], [2183, 6283, 2701, 655, 1936, 9235, 4894, 545, 2341, 5419, 560, 11186, 4028, 5054, 8778, 1612, 4685, 4695, 4574, 3815, 7399, 8812, 6129, 7153, 5108, 10489, 1274])\n"]}]},{"cell_type":"code","source":["# inds = random.sample(list(range(12000)),4)\n","inds = list(range(101,105))\n","sample = sample_neighborhood([train_entities], inds, 16, 64, seed=42)\n","print(sample)\n","print(len(sample))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qK4tP7_j-ZH4","executionInfo":{"status":"ok","timestamp":1734532976830,"user_tz":-60,"elapsed":13,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"a6a8e195-9b34-45cd-a794-3ccf04c1f51d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[9221, 2061, 3599, 10261, 9214, 6937, 4386, 2855, 8492, 4654, 10039, 4152, 2363, 11581, 317, 6210, 580, 6725, 9046, 599, 5721, 3673, 1883, 3679, 4707, 4964, 101, 102, 103, 104, 8551, 5480, 5485, 11121, 3953, 7285, 8824, 11904, 6274, 9607, 11660, 7317, 5271, 8856, 3235, 7594, 4524, 5550, 10927, 4023, 1722, 4030, 10430, 8641, 4305, 8916, 9688, 2009, 10203, 10207, 9440, 9185, 1250, 8680, 6640, 11763, 2804, 510]\n","68\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Dataset:}$"],"metadata":{"id":"l7vHlB4K-U5i"}},{"cell_type":"code","source":["import torch\n","\n","class GNNDataset(Dataset):\n","  def __init__(self, H, A, labels, length, neighbor_max=4):\n","    \"\"\"Custom dataset with neighborhood sampling\n","\n","    Args:\n","      H : torch.tensor\n","        input embeddings (n x d)\n","\n","      A : torch.tensor\n","        adjacency matrix (n x n)\n","\n","      labels : torch.LongTensor\n","        y\n","\n","      meta_indices : torch.LongTensor\n","        index of datapoint to filter validation score\n","\n","      neighbor_max : int\n","        max neighbors for each node in mini-batch\n","\n","      batch_max : int\n","        max size of batch\n","\n","    \"\"\"\n","    # All inits must be tensors\n","    self.H = H.to(device)\n","    self.A = A.to(device)\n","    self.cosine = self.calculate_cosine(self.H)\n","    self.labels = labels.to(device)\n","    self.neighbor_max = neighbor_max\n","    self.length = length\n","\n","  def __len__(self):\n","    return self.length\n","\n","  def __getitem__(self, inds):\n","    # Sample neighborhood\n","\n","    # get inds in list\n","    inds = inds.tolist() if torch.is_tensor(inds) else (inds if isinstance(inds,list) else [inds])\n","\n","    # return the required inds (The inds are the sampes and the active flag dictates relatively if that sample should be counted)\n","    sampled_indices, active_flag = sample_neighborhood(inds, self.H, self.A, self.cosine, self.neighbor_max)\n","\n","    # get the input for the required inds\n","    H_batch = self.H[sampled_indices]\n","\n","    # get the adjacency matrix for the required inds\n","    A_batch = self.A[sampled_indices][:, sampled_indices]\n","\n","    # get the labels for the required inds\n","    labels_batch = self.labels[sampled_indices]\n","\n","    return H_batch, A_batch, labels_batch, torch.LongTensor(active_flag).to(device)\n","\n","  def calculate_cosine(self, H):\n","      dot_product = torch.matmul(H, H.transpose(0, 1))  # shape (m, m)\n","\n","      lengths = torch.sqrt(dot_product.diagonal()).unsqueeze(1)  # shape (m, 1)\n","      denominator = lengths @ lengths.transpose(0, 1)  # shape (m, m)\n","\n","      return dot_product / denominator  # shape (m, m)\n"],"metadata":{"id":"9Rag8OCtKo1r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" H, A, labels, length, neighbor_max=4"],"metadata":{"id":"YMO8D5We_FlU"}},{"cell_type":"code","source":["# # training loader\n","# H_train = torch.stack(list(df_train['vanilla_embedding.1']))\n","# labels_train = torch.LongTensor(list(df_train['chapter_idx']))\n","# A_train = train_entities\n","\n","\n","# train_dataset = GNNDataset(H_train, A_train, labels_train, H_train.size(0), neighbor_max=4)\n","\n","# # Prevent dataloader from calling a single index at a time\n","# custom_train_sampler = torch.utils.data.sampler.BatchSampler(\n","#     torch.utils.data.sampler.RandomSampler(train_dataset),\n","#     batch_size=8,\n","#     drop_last=False)\n","\n","\n","# train_loader = DataLoader(train_dataset, sampler = custom_train_sampler)\n","\n","# validation loader\n","df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df2, df1])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = val_entities\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, df2.shape[0], neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=8,\n","    drop_last=False)\n","\n","dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)\n"],"metadata":{"id":"AxzIHGzKRr2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training loader created with a subset of the data\n","H_train = torch.stack(list(df_train['vanilla_embedding.1'])[:2000])\n","labels_train = torch.LongTensor(list(df_train['chapter_idx'])[:2000])\n","A_train = train_entities[:2000,:2000]\n","\n","\n","train_dataset = GNNDataset(H_train, A_train, labels_train, H_train.size(0), neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_train_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.RandomSampler(train_dataset),\n","    batch_size=8,\n","    drop_last=False)\n","\n","\n","train_loader = DataLoader(train_dataset, sampler = custom_train_sampler)"],"metadata":{"id":"uAk0-RGe9Ltm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check batches\n","\n","# Number of batches to inspect\n","num_batches_to_check = 2\n","\n","for batch_idx, (inputs, adjacency, labels, flag) in enumerate(train_loader):\n","    print('\\n##########################\\n')\n","    print(f\"Batch {batch_idx + 1}/{num_batches_to_check}:\")\n","    print('-' * 10)\n","    print(\"Inputs:\")\n","    print(f\"  Type: {type(inputs)}\")\n","    print(f\"  Shape: {inputs.size()}\")\n","    print('-' * 10)\n","    print(\"Adjacency:\")\n","    print(f\"  Type: {type(adjacency)}\")\n","    print(f\"  Shape: {adjacency[0].size()}\")\n","    print('-' * 10)\n","    print(\"Indices:\")\n","    print(f\"  Type: {type(flag)}\")\n","    print(f\"  Shape: {flag.size()}\")\n","    print(flag)\n","    print('-' * 10)\n","    print(\"Labels:\")\n","    print(f\"  Type: {type(labels)}\")\n","    print(f\"  Shape: {labels.size()}\")\n","    print(labels)\n","\n","    # Stop after inspecting the desired number of batches\n","    if batch_idx + 1 >= num_batches_to_check:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MW9c2A1WE08","executionInfo":{"status":"ok","timestamp":1737041713294,"user_tz":-60,"elapsed":20,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9db06d1f-5d01-4581-cc9b-726087c459f6","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","##########################\n","\n","Batch 1/2:\n","----------\n","Inputs:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 13, 768])\n","----------\n","Adjacency:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([13, 13])\n","----------\n","Indices:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 13])\n","tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1]], device='cuda:0')\n","----------\n","Labels:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 13])\n","tensor([[26, 17, 64, 12, 11, 16, 16, 16, 10, 63, 17, 14,  2]], device='cuda:0')\n","\n","##########################\n","\n","Batch 2/2:\n","----------\n","Inputs:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 61, 768])\n","----------\n","Adjacency:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([61, 61])\n","----------\n","Indices:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 61])\n","tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n","----------\n","Labels:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 61])\n","tensor([[14, 14, 14, 14, 16, 16, 16, 14, 14, 14, 14, 14, 14, 14, 14, 14, 16, 16,\n","         11, 15, 16, 15,  1, 15, 16,  9, 13, 16, 63, 43, 15,  9, 10, 14, 14, 14,\n","         14, 13, 13,  5, 14, 14, 14, 50, 59, 57, 49, 51, 52, 54, 54, 52, 58, 40,\n","         56, 39, 39, 38, 25, 58, 44]], device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["The dataloader seems to be working correctly, the implementation of custom sampling on all indices at once leads to DataLoaders collate function inserting a new dimension that it will stach against. Because all indices are dealt with at once, there is no stacking.\n","\n","The simple solution will be to simply squeeze the tensors in the training loop. The validation loader eradicates randomness from the process."],"metadata":{"id":"6H8779aHR9wL"}},{"cell_type":"markdown","source":["## $\\color{blue}{Model:}$"],"metadata":{"id":"WrZ8xkIsSnvw"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class GNNLayer(nn.Module):\n","    def __init__(self, in_features, out_features, dropout=0.3, training=True):\n","        super(GNNLayer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.dropout = dropout\n","        self.training = training\n","\n","        self.T = nn.Parameter(torch.Tensor(in_features, out_features))\n","        self.E = nn.Parameter(torch.Tensor(in_features, out_features))\n","\n","        # Batch normalization\n","        self.batch_norm = nn.BatchNorm1d(out_features)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.T)\n","        nn.init.xavier_uniform_(self.E)\n","\n","    def forward(self, H, A):\n","        messages_projection = A.T @ H @ self.E\n","        degrees = A.sum(dim=1, keepdim=True)\n","        degrees[degrees == 0] = 1.0\n","        messages_projection /= degrees\n","\n","        self_projection = H @ self.T\n","\n","        # Include skip connection\n","        H_out = F.leaky_relu(self_projection + messages_projection) + H\n","        H_out = F.dropout(H_out, p=self.dropout)\n","\n","        # Apply batch normalization\n","        H_out = self.batch_norm(H_out)\n","\n","        return H_out\n","\n","class GNNModel(nn.Module):\n","    def __init__(self, d, h, c, num_layers=2, dropout=0.3):\n","        super(GNNModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.gnn_layers = nn.ModuleList([GNNLayer(d, d, dropout) for _ in range(num_layers)])\n","        self.fc1 = nn.Linear(d, h)\n","        self.batch_norm_fc1 = nn.BatchNorm1d(h)\n","        self.fc2 = nn.Linear(h, c)\n","        self.dropout = dropout\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.fc1.weight)\n","        nn.init.xavier_uniform_(self.fc2.weight)\n","        nn.init.zeros_(self.fc1.bias)\n","        nn.init.zeros_(self.fc2.bias)\n","\n","    def forward(self, H, A):\n","        for layer in self.gnn_layers:\n","            H = layer(H, A)\n","\n","        H = F.dropout(H, p=self.dropout, training=self.training)\n","        H = F.relu(self.batch_norm_fc1(self.fc1(H)))\n","        Output = self.fc2(H)\n","        return Output\n","\n","    def forward_layer(self, H, A, layer_idx):\n","        \"\"\"Forward pass for a specific layer.\"\"\"\n","        H = self.gnn_layers[layer_idx](H, A)\n","        return H\n"],"metadata":{"id":"64sKwqPvPXmM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","d = 768\n","h = 400   # hidden dimension of fully connected layer\n","c = 70   # number of classes\n","\n","# Model, Loss, Optimizer\n","model = GNNModel(d, h, c)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n","\n"],"metadata":{"id":"NP8Q4qpiVp-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_parameters_per_module(model):\n","    print(\"Module and parameter counts:\")\n","\n","    for name, module in model.named_modules():\n","        # Skip the top-level module (the model itself)\n","        if not isinstance(module, nn.Module) or name == \"\":\n","            continue\n","\n","        param_count = sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","        if param_count > 0:  # Only print modules that have parameters\n","            print(f\"{name}: {param_count} parameters\")"],"metadata":{"id":"2zm1UjLWZUBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count_parameters_per_module(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LxQpA1fYB5e","executionInfo":{"status":"ok","timestamp":1737041866244,"user_tz":-60,"elapsed":6,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"8dfd8e77-00c9-4825-d231-db574ed784b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Module and parameter counts:\n","gnn_layers: 2362368 parameters\n","gnn_layers.0: 1181184 parameters\n","gnn_layers.0.batch_norm: 1536 parameters\n","gnn_layers.1: 1181184 parameters\n","gnn_layers.1.batch_norm: 1536 parameters\n","fc1: 307600 parameters\n","batch_norm_fc1: 800 parameters\n","fc2: 28070 parameters\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Train-Validate:}$"],"metadata":{"id":"5so7JQvHdAvF"}},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    # argmax to get predicted classes\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # count correct\n","    correct = (predicted == labels).sum().item()\n","\n","    # get average\n","    acc = correct / labels.size(0)  # Total number of samples\n","    return acc"],"metadata":{"id":"EZhnvYLtWbqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def train(model, train_loader, criterion, optimizer):\n","    model.train()\n","    epoch_train_losses = []\n","    epoch_train_accuracy = []\n","\n","    for batch_idx, (H, A, y, flag) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        H = H.squeeze(0)\n","        A = A.squeeze(0)\n","        y = y.squeeze(0)\n","        flag = flag.squeeze(0)\n","\n","        out = model(H,A)\n","\n","\n","\n","        train_loss = criterion(out, y)\n","        train_accuracy = accuracy(out, y)\n","\n","\n","        epoch_train_losses.append(train_loss.item())\n","        epoch_train_accuracy.append(train_accuracy)\n","\n","        # Backpropagation and optimization\n","        train_loss.backward()\n","        optimizer.step()\n","\n","    return np.mean(epoch_train_losses), np.mean(epoch_train_accuracy)"],"metadata":{"id":"EftvJs1pdDlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dev_loader, criterion):\n","    model.eval()\n","    epoch_dev_losses = []\n","    epoch_dev_accuracy = []\n","    pred_holder = []\n","    real_holder = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (H, A, y, flag) in enumerate(dev_loader):\n","            H = H.squeeze(0)\n","            A = A.squeeze(0)\n","            y = y.squeeze(0)\n","            flag = flag.squeeze(0).bool()\n","\n","            out = model(H, A)\n","\n","            filtered_out = out[flag]\n","            filtered_y = y[flag]\n","\n","            dev_loss = criterion(filtered_out, filtered_y)\n","            dev_accuracy = accuracy(filtered_out, filtered_y)\n","\n","            epoch_dev_losses.append(dev_loss.item())\n","            epoch_dev_accuracy.append(dev_accuracy)\n","\n","    # Avoid division by zero if no validation points were processed\n","    return np.mean(epoch_dev_losses), np.mean(epoch_dev_accuracy)"],"metadata":{"id":"FEfSsAmimuEU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Training:}$"],"metadata":{"id":"dyzhkkmcR29K"}},{"cell_type":"code","source":["from collections import namedtuple\n","Stats = namedtuple('Stats', [\n","    'train_loss',\n","    'train_accuracy',\n","    'dev_loss',\n","    'dev_accuracy',\n","    'epoch',\n","    'lr',\n","    'alpha',\n","    'max_accuracy'\n","])"],"metadata":{"id":"8gM37WLCNRJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","def tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 0):\n","  \"\"\"\n","  Runs a training setup\n","  verbose == 1 - print model results\n","  verbose == 2 -> print epoch and model results\n","  \"\"\"\n","  model = model.to(device)\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=alpha)\n","\n","  # Prepare data loaders\n","  train_loader = DataLoader(train_dataset, sampler = custom_train_sampler)\n","  dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)\n","\n","  # Hold epoch stats\n","  train_losses = []\n","  train_accuracy = []\n","  dev_losses = []\n","  dev_accuracy = []\n","  epoch_holder = []\n","\n","  # Break if no improvement\n","  current_best = 0\n","  no_improvement = 0\n","\n","\n","  # Run epochs\n","  for epoch in range(epochs):\n","\n","    # break out of epochs\n","    if no_improvement >= 6:\n","      break\n","\n","    # call training\n","    torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","    start_time = time.time()  # Start timing the training\n","    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n","    print(\"\\n--- Profiling Results for Training Phase ---\")\n","    training_time = time.time() - start_time  # Calculate elapsed time\n","    max_train_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","    print(f'Time: {training_time}\\nMax memory: {max_train_memory}')\n","\n","    # call validation\n","    torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","    start_time = time.time()  # Start timing the training\n","    dev_loss, dev_acc = validate(model, dev_loader, criterion)\n","    print(\"\\n--- Profiling Results for Validation Phase ---\")\n","    validation_time = time.time() - start_time  # Calculate elapsed time\n","    max_validation_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","    print(f'Time: {validation_time}\\nMax memory: {max_validation_memory}')\n","\n","\n","\n","    train_losses.append(train_loss)\n","    train_accuracy.append(train_acc)\n","\n","    dev_losses.append(dev_loss)\n","    dev_accuracy.append(dev_acc)\n","    epoch_holder.append(epoch + 1)\n","\n","    # check for improvement\n","    if dev_acc > current_best:\n","      current_best = dev_acc\n","      no_improvement = 0\n","    else:\n","      no_improvement += 1\n","\n","    # save best model\n","    if dev_acc > max_accuracy:\n","      torch.save(model.state_dict(), path)\n","      max_accuracy = dev_acc\n","\n","\n","    # optionally print epoch results\n","    if verbose == 2:\n","      print(f'\\n --------- \\nEpoch: {epoch + 1}\\n')\n","      print(f'Epoch {epoch + 1} train loss: {train_loss:.4f}')\n","      print(f'Epoch {epoch + 1} train accuracy: {train_acc:.4f}')\n","      print(f'Epoch {epoch + 1} dev loss: {dev_loss:.4f}')\n","      print(f'Epoch {epoch + 1} dev accuracy: {dev_acc:.4f}')\n","\n","      # save best results\n","  max_ind = np.argmax(dev_accuracy)\n","\n","  stats = Stats(\n","      train_losses[max_ind],\n","      train_accuracy[max_ind],\n","      dev_losses[max_ind],\n","      dev_accuracy[max_ind],\n","      epoch_holder[max_ind],\n","      lr, alpha,\n","      max_accuracy\n","  )\n","\n","  # optionally print model results\n","  if verbose in [1,2]:\n","    print('\\n ######## \\n')\n","    print(f'lr:{stats.lr}, alpha:{stats.alpha} @ epoch {stats.epoch}.')\n","    print(f'TL:{stats.train_loss}, TA:{stats.train_accuracy}.')\n","    print(f'DL:{stats.dev_loss}, DA:{stats.dev_accuracy}')\n","\n","  return (training_time, max_train_memory), (validation_time, max_validation_memory)"],"metadata":{"id":"J3PQBpDIYnib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 1\n","lr = 0.0005\n","alpha = 0.00005\n","path = \"class/models/GNN_trace.pt\"\n","max_accuracy = 0\n","model = GNNModel(d,h,c)"],"metadata":{"id":"Qf0cxrsteYzM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_stats, validation_stats = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPYCNxFAUZPu","executionInfo":{"status":"ok","timestamp":1737042191101,"user_tz":-60,"elapsed":115780,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"921445b5-57fd-445a-90f3-42a8bf40a3c3","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 19.855705499649048\n","Max memory: 1540577792\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 95.31733846664429\n","Max memory: 1535012864\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 2.5837\n","Epoch 1 train accuracy: 0.4124\n","Epoch 1 dev loss: 2.9375\n","Epoch 1 dev accuracy: 0.3027\n","\n"," ######## \n","\n","lr:0.0005, alpha:0.0001 @ epoch 1.\n","TL:2.5836983284950255, TA:0.4123930328585182.\n","DL:2.9375194724926277, DA:0.30268595041322316\n"]}]},{"cell_type":"code","source":["df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df2, df1])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = val_entities\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, df2.shape[0], neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=1024,\n","    drop_last=False)\n","\n","dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)\n","\n","torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","start_time = time.time()  # Start timing the training\n","dev_loss, dev_acc = validate(model, dev_loader, criterion)\n","print(\"\\n--- Profiling Results for Validation Phase ---\")\n","validation_time = time.time() - start_time  # Calculate elapsed time\n","max_validation_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","print(f'Time: {validation_time}\\nMax memory: {max_validation_memory}')\n","print(dev_loss)\n","print(dev_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moD5IzXxvStX","executionInfo":{"status":"ok","timestamp":1737042772842,"user_tz":-60,"elapsed":33523,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"5865d957-a289-47ee-a762-74c04a9c0135"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Validation Phase ---\n","Time: 32.89159631729126\n","Max memory: 4280548864\n","2.9000470638275146\n","0.31016597510373445\n"]}]},{"cell_type":"markdown","source":["We have a lot of space increase batch size"],"metadata":{"id":"7k9VTCcnS8fU"}},{"cell_type":"code","source":["# training loader created with a subset of the data\n","H_train = torch.stack(list(df_train['vanilla_embedding.1'])[:2000])\n","labels_train = torch.LongTensor(list(df_train['chapter_idx'])[:2000])\n","A_train = train_entities[:2000,:2000]\n","\n","\n","train_dataset = GNNDataset(H_train, A_train, labels_train, H_train.size(0), neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_train_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.RandomSampler(train_dataset),\n","    batch_size=64,\n","    drop_last=False)\n","\n","\n","df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df2, df1])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = val_entities\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, df2.shape[0], neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=1024,\n","    drop_last=False)\n"],"metadata":{"id":"vbSFAiAZKq8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_stats, validation_stats = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RL3XM6yTpNb","executionInfo":{"status":"ok","timestamp":1737042900179,"user_tz":-60,"elapsed":45013,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"2c068296-4aad-47b8-ce5c-f8c62eae4f29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 11.893709421157837\n","Max memory: 4352926208\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 32.80560326576233\n","Max memory: 4490978304\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 1.3462\n","Epoch 1 train accuracy: 0.6995\n","Epoch 1 dev loss: 2.6072\n","Epoch 1 dev accuracy: 0.3527\n","\n"," ######## \n","\n","lr:0.0005, alpha:0.0001 @ epoch 1.\n","TL:1.3462302163243294, TA:0.6994579701375027.\n","DL:2.6072261333465576, DA:0.35269709543568467\n"]}]},{"cell_type":"code","source":["# training loader created with a subset of the data\n","H_train = torch.stack(list(df_train['vanilla_embedding.1'])[:2000])\n","labels_train = torch.LongTensor(list(df_train['chapter_idx'])[:2000])\n","A_train = train_entities[:2000,:2000]\n","\n","\n","train_dataset = GNNDataset(H_train, A_train, labels_train, H_train.size(0), neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_train_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.RandomSampler(train_dataset),\n","    batch_size=16,\n","    drop_last=False)\n","\n","\n","df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df2, df1])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = val_entities\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, df2.shape[0], neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=1024,\n","    drop_last=False)"],"metadata":{"id":"aBn7g5cPUnf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_stats, validation_stats = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Idb2dxq7UwBr","executionInfo":{"status":"ok","timestamp":1737043235040,"user_tz":-60,"elapsed":51377,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"96569db3-1378-498a-f24c-1359060c07b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 17.648733139038086\n","Max memory: 4351542272\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 33.276201009750366\n","Max memory: 4490362880\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 2.6135\n","Epoch 1 train accuracy: 0.4058\n","Epoch 1 dev loss: 2.9246\n","Epoch 1 dev accuracy: 0.2998\n","\n"," ######## \n","\n","lr:0.0005, alpha:5e-05 @ epoch 1.\n","TL:2.6134842596054075, TA:0.4058028126283634.\n","DL:2.9246041774749756, DA:0.29979253112033194\n"]}]},{"cell_type":"markdown","source":["looks like it is causing overfitting lets keep training the same and make gains on validation"],"metadata":{"id":"umbOlq5wVnR1"}},{"cell_type":"code","source":["# training loader created with a subset of the data\n","H_train = torch.stack(list(df_train['vanilla_embedding.1'])[:2000])\n","labels_train = torch.LongTensor(list(df_train['chapter_idx'])[:2000])\n","A_train = train_entities[:2000,:2000]\n","\n","\n","train_dataset = GNNDataset(H_train, A_train, labels_train, H_train.size(0), neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_train_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.RandomSampler(train_dataset),\n","    batch_size=8,\n","    drop_last=False)\n","\n","\n","df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df2, df1])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = val_entities\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, df2.shape[0], neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=1024,\n","    drop_last=False)"],"metadata":{"id":"DTrhS2V0V4HK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_stats, validation_stats = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3oGBt9FnWIuP","executionInfo":{"status":"ok","timestamp":1737044071383,"user_tz":-60,"elapsed":53287,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"6eec5998-92d1-49a9-a3c6-de34da086ce3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 19.32697558403015\n","Max memory: 4351483904\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 33.48703742027283\n","Max memory: 4340441088\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 0.9849\n","Epoch 1 train accuracy: 0.7763\n","Epoch 1 dev loss: 2.4917\n","Epoch 1 dev accuracy: 0.3641\n","\n"," ######## \n","\n","lr:0.0005, alpha:5e-05 @ epoch 1.\n","TL:0.9848547171354294, TA:0.7763352196350619.\n","DL:2.4916648864746094, DA:0.36410788381742737\n"]}]},{"cell_type":"markdown","source":["# new refence above\n","now make bs log2"],"metadata":{"id":"gi0hIrSr40Ar"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from copy import deepcopy\n","\n","def sample_neighborhood(primary_inds, input, adj, distance, neighbor_max = 4):\n","    \"\"\"\n","    Takes the given inds and the inputs, returns the sampled set of indices and the corresponding activation flag.\n","    If the activation flag is True, then the the datapoint is primary and has been search for neighbors and neighbors\n","    of neighbors. This indicates that we rely on the datapoint for metrics and loss.\n","\n","    Args:\n","      primary_inds : iterable\n","          indices sampled by the dataloader\n","      input : torch.Tensor\n","          (m,d) input tensor\n","      adj : torch.Tensor\n","          (m,m) adjacency matrix\n","      distance : torch.Tensor\n","          (m,m) : cosine similarity between all inputs\n","      neighbour_max : int (optional)\n","          The maximum number of neighbors to consider for each point\n","\n","    Returns:\n","      sampled_indices : list\n","          indices of all datapoints to be processed in the batch\n","      activation_flag : list\n","          boolean_flag indicating whether the corresponding datapoint is to be considered for metrics\n","    \"\"\"\n","\n","    def _get_closest_neighbors(ind):\n","      \"\"\"get up to neighbor_max close neighbors\"\"\"\n","      local_neighbors = []\n","      local_activation_flag = []\n","      candidate_neighbors = [neighbor.item() for neighbor in (adj[ind] > 0).nonzero(as_tuple=True)[0] if neighbor.item() not in sampled_indices]\n","      candidate_distances = [(neighbor, distance[primary_ind][neighbor]) for neighbor in candidate_neighbors]\n","      sorted_neighbors = sorted(candidate_distances, key=lambda x: x[1])\n","      return [neighbor for neighbor, dist in sorted_neighbors[:neighbor_max]], candidate_neighbors\n","\n","    sampled_indices = []\n","    activation_flag = []\n","    all_banned_neighbors = []\n","\n","    for primary_ind in primary_inds:\n","\n","      # if primary ind has been added as a neighbor, convert the activation flag to true, else add it as a standard primary index\n","      if primary_ind in sampled_indices:\n","        activation_flag[sampled_indices.index(primary_ind)] = True\n","      else:\n","        sampled_indices.append(primary_ind)\n","        activation_flag.append(True)\n","\n","      # print('\\n', primary_ind)\n","      # print('sampled_indices', sampled_indices)\n","\n","      level_1_neighbors, candidate_neighbors = _get_closest_neighbors(primary_ind)\n","      banned_neighbors = list(set(candidate_neighbors) - set(level_1_neighbors))\n","      all_banned_neighbors.extend(banned_neighbors)\n","      # print('banned_neighbors', banned_neighbors)\n","      # print('all_banned_neighbors', all_banned_neighbors)\n","\n","      level_1_activation_flag = [False for el in level_1_neighbors]\n","      sampled_indices.extend(level_1_neighbors)\n","      activation_flag.extend(level_1_activation_flag)\n","\n","      # print('level_1_neighbors', level_1_neighbors)\n","      # print('sampled_indices', sampled_indices)\n","      # print('level_1_activation_flag', level_1_activation_flag)\n","      # print('activation_flag', activation_flag)\n","\n","      for level_1_ind in level_1_neighbors:\n","        level_2_neighbors, _ = _get_closest_neighbors(level_1_ind)\n","        level_2_activation_flag = [False for el in level_2_neighbors]\n","        sampled_indices.extend(level_2_neighbors)\n","        activation_flag.extend(level_2_activation_flag)\n","\n","        # print('level_2_neighbors', level_2_neighbors)\n","        # print('sampled_indices', sampled_indices)\n","        # print('level_2_activation_flag', level_2_activation_flag)\n","        # print('activation_flag', activation_flag)\n","\n","    # include only 4 level one neighbors for each primary index to avoid pollution\n","    clean_indices = []\n","    clean_flags = []\n","    for i in range(len(sampled_indices)):\n","      target = sampled_indices[i]\n","      if target in primary_inds:\n","        clean_indices.append(target)\n","        clean_flags.append(True)\n","      elif target in all_banned_neighbors:\n","        continue\n","      else:\n","        clean_indices.append(target)\n","        clean_flags.append(False)\n","    # print(f'\\ncleaning\\nsampled_indices : {sampled_indices}\\nclean_indices : {clean_indices}')\n","\n","    limit = 2**int(np.floor(np.log2(len(clean_indices))))\n","    return clean_indices[:limit], clean_flags[:limit]\n"],"metadata":{"id":"brfWgOaGazn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_stats, validation_stats = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mQIzuSEbUS1","executionInfo":{"status":"ok","timestamp":1737044301012,"user_tz":-60,"elapsed":53416,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"d3b768c0-3c5a-4ddd-e7f5-4fa03dfcd26f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 19.72818875312805\n","Max memory: 2920893952\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 33.25472927093506\n","Max memory: 3038790144\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 0.8533\n","Epoch 1 train accuracy: 0.7958\n","Epoch 1 dev loss: 2.5077\n","Epoch 1 dev accuracy: 0.3769\n","\n"," ######## \n","\n","lr:0.0005, alpha:5e-05 @ epoch 1.\n","TL:0.8532900586128235, TA:0.7958125.\n","DL:2.5076897144317627, DA:0.3769035532994924\n"]}]},{"cell_type":"markdown","source":["# No impact on power 2\n","\n","Check sparse calc"],"metadata":{"id":"HNEtfIkk6SGe"}},{"cell_type":"code","source":["#rest sample neighborhood\n","\n","from torch.utils.data import Dataset, DataLoader\n","from copy import deepcopy\n","\n","def sample_neighborhood(primary_inds, input, adj, distance, neighbor_max = 4):\n","    \"\"\"\n","    Takes the given inds and the inputs, returns the sampled set of indices and the corresponding activation flag.\n","    If the activation flag is True, then the the datapoint is primary and has been search for neighbors and neighbors\n","    of neighbors. This indicates that we rely on the datapoint for metrics and loss.\n","\n","    Args:\n","      primary_inds : iterable\n","          indices sampled by the dataloader\n","      input : torch.Tensor\n","          (m,d) input tensor\n","      adj : torch.Tensor\n","          (m,m) adjacency matrix\n","      distance : torch.Tensor\n","          (m,m) : cosine similarity between all inputs\n","      neighbour_max : int (optional)\n","          The maximum number of neighbors to consider for each point\n","\n","    Returns:\n","      sampled_indices : list\n","          indices of all datapoints to be processed in the batch\n","      activation_flag : list\n","          boolean_flag indicating whether the corresponding datapoint is to be considered for metrics\n","    \"\"\"\n","\n","    def _get_closest_neighbors(ind):\n","      \"\"\"get up to neighbor_max close neighbors\"\"\"\n","      local_neighbors = []\n","      local_activation_flag = []\n","      candidate_neighbors = [neighbor.item() for neighbor in (adj[ind] > 0).nonzero(as_tuple=True)[0] if neighbor.item() not in sampled_indices]\n","      candidate_distances = [(neighbor, distance[primary_ind][neighbor]) for neighbor in candidate_neighbors]\n","      sorted_neighbors = sorted(candidate_distances, key=lambda x: x[1])\n","      return [neighbor for neighbor, dist in sorted_neighbors[:neighbor_max]], candidate_neighbors\n","\n","    sampled_indices = []\n","    activation_flag = []\n","    all_banned_neighbors = []\n","\n","    for primary_ind in primary_inds:\n","\n","      # if primary ind has been added as a neighbor, convert the activation flag to true, else add it as a standard primary index\n","      if primary_ind in sampled_indices:\n","        activation_flag[sampled_indices.index(primary_ind)] = True\n","      else:\n","        sampled_indices.append(primary_ind)\n","        activation_flag.append(True)\n","\n","      # print('\\n', primary_ind)\n","      # print('sampled_indices', sampled_indices)\n","\n","      level_1_neighbors, candidate_neighbors = _get_closest_neighbors(primary_ind)\n","      banned_neighbors = list(set(candidate_neighbors) - set(level_1_neighbors))\n","      all_banned_neighbors.extend(banned_neighbors)\n","      # print('banned_neighbors', banned_neighbors)\n","      # print('all_banned_neighbors', all_banned_neighbors)\n","\n","      level_1_activation_flag = [False for el in level_1_neighbors]\n","      sampled_indices.extend(level_1_neighbors)\n","      activation_flag.extend(level_1_activation_flag)\n","\n","      # print('level_1_neighbors', level_1_neighbors)\n","      # print('sampled_indices', sampled_indices)\n","      # print('level_1_activation_flag', level_1_activation_flag)\n","      # print('activation_flag', activation_flag)\n","\n","      for level_1_ind in level_1_neighbors:\n","        level_2_neighbors, _ = _get_closest_neighbors(level_1_ind)\n","        level_2_activation_flag = [False for el in level_2_neighbors]\n","        sampled_indices.extend(level_2_neighbors)\n","        activation_flag.extend(level_2_activation_flag)\n","\n","        # print('level_2_neighbors', level_2_neighbors)\n","        # print('sampled_indices', sampled_indices)\n","        # print('level_2_activation_flag', level_2_activation_flag)\n","        # print('activation_flag', activation_flag)\n","\n","    # include only 4 level one neighbors for each primary index to avoid pollution\n","    clean_indices = []\n","    clean_flags = []\n","    for i in range(len(sampled_indices)):\n","      target = sampled_indices[i]\n","      if target in primary_inds:\n","        clean_indices.append(target)\n","        clean_flags.append(True)\n","      elif target in all_banned_neighbors:\n","        continue\n","      else:\n","        clean_indices.append(target)\n","        clean_flags.append(False)\n","    # print(f'\\ncleaning\\nsampled_indices : {sampled_indices}\\nclean_indices : {clean_indices}')\n","    return clean_indices, clean_flags\n"],"metadata":{"id":"G0hL_kkpbxLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class GNNLayer(nn.Module):\n","    def __init__(self, in_features, out_features, dropout=0.3, training=True):\n","        super(GNNLayer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.dropout = dropout\n","        self.training = training\n","\n","        self.T = nn.Parameter(torch.Tensor(in_features, out_features))\n","        self.E = nn.Parameter(torch.Tensor(in_features, out_features))\n","\n","        # Batch normalization\n","        self.batch_norm = nn.BatchNorm1d(out_features)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.T)\n","        nn.init.xavier_uniform_(self.E)\n","\n","    def forward(self, H, A):\n","        messages_projection = A.T @ H @ self.E\n","        degrees = A.sum(dim=1, keepdim=True)\n","        degrees[degrees == 0] = 1.0\n","        messages_projection /= degrees\n","\n","        self_projection = H @ self.T\n","\n","        # Include skip connection\n","        H_out = F.leaky_relu(self_projection + messages_projection) + H\n","        H_out = F.dropout(H_out, p=self.dropout)\n","\n","        # Apply batch normalization\n","        H_out = self.batch_norm(H_out)\n","\n","        return H_out\n","\n","class GNNModel(nn.Module):\n","    def __init__(self, d, h, c, num_layers=2, dropout=0.3):\n","        super(GNNModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.gnn_layers = nn.ModuleList([GNNLayer(d, d, dropout) for _ in range(num_layers)])\n","        self.fc1 = nn.Linear(d, h)\n","        self.batch_norm_fc1 = nn.BatchNorm1d(h)\n","        self.fc2 = nn.Linear(h, c)\n","        self.dropout = dropout\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.fc1.weight)\n","        nn.init.xavier_uniform_(self.fc2.weight)\n","        nn.init.zeros_(self.fc1.bias)\n","        nn.init.zeros_(self.fc2.bias)\n","\n","    def forward(self, H, A):\n","        for layer in self.gnn_layers:\n","            H = layer(H, A)\n","\n","        H = F.dropout(H, p=self.dropout, training=self.training)\n","        H = F.relu(self.batch_norm_fc1(self.fc1(H)))\n","        Output = self.fc2(H)\n","        return Output\n","\n","    def forward_layer(self, H, A, layer_idx):\n","        \"\"\"Forward pass for a specific layer.\"\"\"\n","        H = self.gnn_layers[layer_idx](H, A)\n","        return H\n"],"metadata":{"id":"ABkY4TOW8NJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 1\n","lr = 0.0005\n","alpha = 0.00005\n","path = \"class/models/GNN_trace.pt\"\n","max_accuracy = 0\n","model = GNNModel(d,h,c)"],"metadata":{"id":"F08sLkL87GpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_stats, validation_stats = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3kDAxlF_S8_","executionInfo":{"status":"ok","timestamp":1737045706125,"user_tz":-60,"elapsed":52603,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"60f83312-3bfd-4c2c-a78e-2943302c8fd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 19.56251311302185\n","Max memory: 2921960448\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 32.56710410118103\n","Max memory: 3060967424\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 2.5983\n","Epoch 1 train accuracy: 0.4109\n","Epoch 1 dev loss: 2.8818\n","Epoch 1 dev accuracy: 0.3029\n","\n"," ######## \n","\n","lr:0.0005, alpha:5e-05 @ epoch 1.\n","TL:2.5983164286613465, TA:0.41088487058579787.\n","DL:2.8818299770355225, DA:0.3029045643153527\n"]}]},{"cell_type":"markdown","source":["# No Effect\n","\n","low precision"],"metadata":{"id":"ftdaCINQAAes"}},{"cell_type":"code","source":["from torch.cuda.amp import GradScaler, autocast\n","import numpy as np\n","\n","def train(model, train_loader, criterion, optimizer, scaler):\n","    model.train()\n","    epoch_train_losses = []\n","    epoch_train_accuracy = []\n","\n","    for batch_idx, (H, A, y, flag) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        H = H.squeeze(0)\n","        A = A.squeeze(0)\n","        y = y.squeeze(0)\n","        flag = flag.squeeze(0)\n","\n","        with autocast():  # Assuming torch.cuda.amp.autocast\n","            out = model(H, A)\n","            train_loss = criterion(out, y)\n","            train_accuracy = accuracy(out, y)\n","\n","        # Scale the loss, perform backward, and update\n","        scaler.scale(train_loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        epoch_train_losses.append(train_loss.item())\n","        epoch_train_accuracy.append(train_accuracy)\n","\n","    return np.mean(epoch_train_losses), np.mean(epoch_train_accuracy)"],"metadata":{"id":"9dVxWT3rEVog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","def tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 0):\n","  \"\"\"\n","  Runs a training setup\n","  verbose == 1 - print model results\n","  verbose == 2 -> print epoch and model results\n","  \"\"\"\n","  model = model.to(device)\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=alpha)\n","  scaler = GradScaler()\n","\n","  # Prepare data loaders\n","  train_loader = DataLoader(train_dataset, sampler = custom_train_sampler)\n","  dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)\n","\n","  # Hold epoch stats\n","  train_losses = []\n","  train_accuracy = []\n","  dev_losses = []\n","  dev_accuracy = []\n","  epoch_holder = []\n","\n","  # Break if no improvement\n","  current_best = 0\n","  no_improvement = 0\n","\n","\n","  # Run epochs\n","  for epoch in range(epochs):\n","\n","    # break out of epochs\n","    if no_improvement >= 6:\n","      break\n","\n","    # call training\n","    torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","    start_time = time.time()  # Start timing the training\n","    train_loss, train_acc = train(model, train_loader, criterion, optimizer, scaler)\n","    print(\"\\n--- Profiling Results for Training Phase ---\")\n","    training_time = time.time() - start_time  # Calculate elapsed time\n","    max_train_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","    print(f'Time: {training_time}\\nMax memory: {max_train_memory}')\n","\n","    # call validation\n","    torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","    start_time = time.time()  # Start timing the training\n","    dev_loss, dev_acc = validate(model, dev_loader, criterion)\n","    print(\"\\n--- Profiling Results for Validation Phase ---\")\n","    validation_time = time.time() - start_time  # Calculate elapsed time\n","    max_validation_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","    print(f'Time: {validation_time}\\nMax memory: {max_validation_memory}')\n","\n","\n","\n","    train_losses.append(train_loss)\n","    train_accuracy.append(train_acc)\n","\n","    dev_losses.append(dev_loss)\n","    dev_accuracy.append(dev_acc)\n","    epoch_holder.append(epoch + 1)\n","\n","    # check for improvement\n","    if dev_acc > current_best:\n","      current_best = dev_acc\n","      no_improvement = 0\n","    else:\n","      no_improvement += 1\n","\n","    # save best model\n","    if dev_acc > max_accuracy:\n","      torch.save(model.state_dict(), path)\n","      max_accuracy = dev_acc\n","\n","\n","    # optionally print epoch results\n","    if verbose == 2:\n","      print(f'\\n --------- \\nEpoch: {epoch + 1}\\n')\n","      print(f'Epoch {epoch + 1} train loss: {train_loss:.4f}')\n","      print(f'Epoch {epoch + 1} train accuracy: {train_acc:.4f}')\n","      print(f'Epoch {epoch + 1} dev loss: {dev_loss:.4f}')\n","      print(f'Epoch {epoch + 1} dev accuracy: {dev_acc:.4f}')\n","\n","      # save best results\n","  max_ind = np.argmax(dev_accuracy)\n","\n","  stats = Stats(\n","      train_losses[max_ind],\n","      train_accuracy[max_ind],\n","      dev_losses[max_ind],\n","      dev_accuracy[max_ind],\n","      epoch_holder[max_ind],\n","      lr, alpha,\n","      max_accuracy\n","  )\n","\n","  # optionally print model results\n","  if verbose in [1,2]:\n","    print('\\n ######## \\n')\n","    print(f'lr:{stats.lr}, alpha:{stats.alpha} @ epoch {stats.epoch}.')\n","    print(f'TL:{stats.train_loss}, TA:{stats.train_accuracy}.')\n","    print(f'DL:{stats.dev_loss}, DA:{stats.dev_accuracy}')\n","\n","  return (training_time, max_train_memory), (validation_time, max_validation_memory)"],"metadata":{"id":"akzPNtBPFHTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_stats, validation_stats = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwqaaHp5FjqQ","executionInfo":{"status":"ok","timestamp":1737047593299,"user_tz":-60,"elapsed":53135,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"823dd782-a2dd-48d7-e05a-499fdded7781"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-71-5753a12d5a77>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-70-8032fced2c32>:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():  # Assuming torch.cuda.amp.autocast\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Profiling Results for Training Phase ---\n","Time: 19.43116569519043\n","Max memory: 4391714816\n","\n","--- Profiling Results for Validation Phase ---\n","Time: 33.2727472782135\n","Max memory: 4380591104\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 1.3900\n","Epoch 1 train accuracy: 0.6911\n","Epoch 1 dev loss: 2.5692\n","Epoch 1 dev accuracy: 0.3392\n","\n"," ######## \n","\n","lr:0.0005, alpha:5e-05 @ epoch 1.\n","TL:1.3899921100139618, TA:0.6910955044707143.\n","DL:2.569183588027954, DA:0.3392116182572614\n"]}]},{"cell_type":"markdown","source":["# change batch size\n","# sparse metrices\n","# mixed precision training\n","# memory pinning"],"metadata":{"id":"SOuKhUBtDtNj"}},{"cell_type":"code","source":[],"metadata":{"id":"anf8MMRrWo5s"},"execution_count":null,"outputs":[]}]}