{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOPok9PPX/Hn2UFvMFMtvbp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Text Classification - GNN Inference\n"],"metadata":{"id":"X_8ti75bDLxt"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","1.   Admin\n","2.   Dataset\n","3.   Model\n","4.   Train - Validate\n","5.   Training Loop"],"metadata":{"id":"wZIpe_waDL3M"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","We now look to infer the entire graph at once, relying on layerwise propogation."],"metadata":{"id":"ePT4vq35DL5n"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"qYbJFtOuDL0a"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"mDOQmYMSCdTJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734448352242,"user_tz":-60,"elapsed":4286,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"77468ce2-ed1b-4534-c1da-02f5428e0006"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"id":"IHgEq1_zEIOw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734448376588,"user_tz":-60,"elapsed":24352,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"93121cd2-adef-48ae-bb71-e7d979759175"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data\n","* Load adjacency matrices"],"metadata":{"id":"XNUYb7PmENbA"}},{"cell_type":"code","source":["path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train')\n","df_dev = pd.read_pickle(path + 'df_dev')\n","df_test = pd.read_pickle(path + 'df_test')\n","df1 = df_train[['vanilla_embedding.1','chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1','chapter_idx']]\n","df_val = pd.concat([df1, df2])"],"metadata":{"id":"VjESklMTEKkP","executionInfo":{"status":"ok","timestamp":1734448396045,"user_tz":-60,"elapsed":19472,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["path = 'class/tensors/adj_{}.pt'\n","\n","# train\n","train_people = torch.load(path.format('train_people'))\n","train_locations = torch.load(path.format('train_locations'))\n","train_entities = torch.load(path.format('train_entities'))\n","\n","# dev\n","dev_people = torch.load(path.format('dev_people'))\n","dev_locations = torch.load(path.format('dev_locations'))\n","dev_entities = torch.load(path.format('dev_entities'))\n","\n","# val (contains the adjacency matrix for both the training and the development set)\n","val_people = torch.load(path.format('val_people'))\n","val_locations = torch.load(path.format('val_locations'))\n","val_entities = torch.load(path.format('val_entities'))"],"metadata":{"id":"gelR5lmHEa5J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734448439502,"user_tz":-60,"elapsed":43470,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9c0e1f5e-cc30-4d61-cd44-75462547cc93"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-fd49eb201090>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_people = torch.load(path.format('train_people'))\n","<ipython-input-4-fd49eb201090>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_locations = torch.load(path.format('train_locations'))\n","<ipython-input-4-fd49eb201090>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_entities = torch.load(path.format('train_entities'))\n","<ipython-input-4-fd49eb201090>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_people = torch.load(path.format('dev_people'))\n","<ipython-input-4-fd49eb201090>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_locations = torch.load(path.format('dev_locations'))\n","<ipython-input-4-fd49eb201090>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_entities = torch.load(path.format('dev_entities'))\n","<ipython-input-4-fd49eb201090>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_people = torch.load(path.format('val_people'))\n","<ipython-input-4-fd49eb201090>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_locations = torch.load(path.format('val_locations'))\n","<ipython-input-4-fd49eb201090>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_entities = torch.load(path.format('val_entities'))\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Dataset:}$"],"metadata":{"id":"x8mdsEBrEqzB"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","def sample_neighborhood(A, inds, neighbor_max, batch_max, seed=None):\n","    # Set the random seed for deterministic responses\n","    if seed is not None:\n","        np.random.seed(seed)\n","\n","    np.random.shuffle(A)  # Shuffle the list of adjacency matrices in place\n","    sampled_indices = set(inds)  # Initialize the set of sampled indices\n","\n","    for ind in inds:  # Iterate through node in mini-batch\n","        neighbors = set()\n","\n","        for adj in A:  # Iterate through all adjacency matrices\n","            # Get the indices of all neighbors that idx links to\n","            neighbors.update((adj[ind] > 0).nonzero(as_tuple=True)[0].tolist())\n","\n","            if len(neighbors) > neighbor_max:  # Check if we have too many neighbors\n","                # Take a random subset using np.random.choice\n","                neighbors = set(np.random.choice(list(neighbors), neighbor_max, replace=False))\n","\n","            sampled_indices.update(neighbors)  # Add new neighbors\n","\n","            if len(sampled_indices) >= batch_max:\n","                break\n","\n","    sampled_indices = list(sampled_indices)[:batch_max]  # Limit to batch_max\n","    return sampled_indices"],"metadata":{"id":"iHrpWiauKaGR","executionInfo":{"status":"ok","timestamp":1734448442399,"user_tz":-60,"elapsed":384,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class GNNDataset(Dataset):\n","  def __init__(self, H, A, labels, meta_indices, neighbor_max=8, batch_max=64, seed=None):\n","    \"\"\"Custom dataset with neighborhood sampling\n","\n","    Args:\n","      H : torch.tensor\n","        input embeddings (n x d)\n","\n","      A : list[torch.tensor]\n","        list of (n x n)\n","\n","      labels : torch.LongTensor\n","        y\n","\n","      meta_indices : torch.LongTensor\n","        index of datapoint to filter validation score\n","\n","      neighbor_max : int\n","        max neighbors for each node in mini-batch\n","\n","      batch_max : int\n","        max size of batch\n","\n","    \"\"\"\n","    # All inits must be tensors\n","    self.H = H.to(device)\n","    self.A = [a.to(device) for a in A]\n","    self.labels = labels.to(device)\n","    self.meta_indices = meta_indices\n","    self.neighbor_max = neighbor_max\n","    self.batch_max = batch_max\n","    self.seed = seed\n","\n","  def __len__(self):\n","    return len(self.labels)\n","\n","  def __getitem__(self, inds):\n","    # print('\\n####################\\n')\n","    # print('GET ITEM CALLED', 'INDS:', inds)\n","    # Sample neighborhood\n","\n","    # get inds in list\n","    inds = inds.tolist() if torch.is_tensor(inds) else (inds if isinstance(inds,list) else [inds])\n","\n","    # return the required inds\n","    sampled_indices = sample_neighborhood(self.A, inds, self.neighbor_max, self.batch_max,seed=self.seed)\n","\n","    # get the input for the required inds\n","    H_batch = self.H[sampled_indices]\n","\n","    # get the adjacency matrix for the required inds\n","    A_batch = [self.A[k][sampled_indices][:, sampled_indices] for k in range(len(self.A))]\n","\n","    # get the labels for the required inds\n","    labels_batch = self.labels[sampled_indices]\n","\n","    # get meta indices\n","    index_batch = self.meta_indices[sampled_indices]\n","\n","    return H_batch, A_batch, labels_batch, index_batch"],"metadata":{"id":"jU03yW3dKeK7","executionInfo":{"status":"ok","timestamp":1734448445069,"user_tz":-60,"elapsed":5,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# training loader\n","df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df1, df2])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = []\n","A_val.append(val_entities)\n","val_indices = torch.LongTensor(list(range(df_val.shape[0])))\n","\n","\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, val_indices, neighbor_max=8, batch_max=32, seed=42)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=8,\n","    drop_last=False)\n","\n","\n","dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)"],"metadata":{"id":"sksAsLpDK0CS","executionInfo":{"status":"ok","timestamp":1734448736845,"user_tz":-60,"elapsed":1401,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class GNNInferenceDataset(Dataset):\n","    def __init__(self, H, A, labels, threshold=12000):\n","        \"\"\"\n","        Args:\n","            H (torch.Tensor): tensor of node embeddings.\n","            A (list[torch.Tensor]): A list of torch.tensor adjacency matrices, one for each link type.\n","            labels (torch.LongTensor): classification labels\n","            threshold (int) : cut-off point for the training data\n","        \"\"\"\n","        self.H = H.to(device)\n","        self.A = [a.to(device) for a in A]\n","        self.labels = labels.to(device)\n","        self.is_training = (torch.arange(H.size(0)) < threshold).to(device)\n","\n","    def __len__(self):\n","        # Return the total number of samples\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # Get the data point and its training status\n","        H_batch = self.H[idx]\n","        A_batch = [self.A[k][idx] for k in range(len(self.A))]\n","        labels_batch = self.labels[idx]\n","        is_training_batch = self.is_training[idx]\n","\n","        # Return an instance of DataPoint\n","        return H_batch, A_batch, labels_batch, is_training_batch"],"metadata":{"id":"kq_pwkKKGXC7","executionInfo":{"status":"ok","timestamp":1734446709079,"user_tz":-60,"elapsed":414,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["H = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels = torch.LongTensor(list(df_val['chapter_idx']))\n","A = []\n","A.append(val_entities)"],"metadata":{"id":"HXFw9r9jM6Zu","executionInfo":{"status":"ok","timestamp":1734446715080,"user_tz":-60,"elapsed":1049,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["inference_dataset = GNNInferenceDataset(H,A,labels)"],"metadata":{"id":"eJbbuO-qIHGp","executionInfo":{"status":"ok","timestamp":1734446716124,"user_tz":-60,"elapsed":5,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["len(inference_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NOgfo3mazI1z","executionInfo":{"status":"ok","timestamp":1734446426384,"user_tz":-60,"elapsed":22,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"1c564370-0001-4509-ff18-dc7c0e9233b7"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12964"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["inference_dataset[0][3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7xfLll9zMON","executionInfo":{"status":"ok","timestamp":1734446426384,"user_tz":-60,"elapsed":18,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"e27d387d-13c2-4d24-e979-4a466f4526bd"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True, device='cuda:0')"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["inference_dataset[12000][3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4bdURsI0n_8","executionInfo":{"status":"ok","timestamp":1734446562535,"user_tz":-60,"elapsed":417,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"d655b2fa-ac64-4b36-e228-c178aacff003"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(False, device='cuda:0')"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["inference_dataloader = DataLoader(inference_dataset, batch_size=len(inference_dataset), shuffle=False)"],"metadata":{"id":"1wD-SUzN1n5_","executionInfo":{"status":"ok","timestamp":1734446719012,"user_tz":-60,"elapsed":419,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Model:}$"],"metadata":{"id":"S3rKXf1DOXJr"}},{"cell_type":"code","source":["# Make robust to change of degrees at inference\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class GNNLayer(nn.Module):\n","   def __init__(self, in_features, out_features, num_relations=1):\n","      super(GNNLayer, self).__init__()\n","      self.in_features = in_features\n","      self.out_features = out_features\n","      self.num_relations = num_relations\n","\n","      # Define weight matrices for different relationship types\n","      self.T = nn.ParameterList([nn.Parameter(torch.Tensor(in_features, out_features)) for _ in range(num_relations)])\n","      self.E = nn.ParameterList([nn.Parameter(torch.Tensor(in_features, out_features)) for _ in range(num_relations)])\n","\n","      # Learnable normalization factor\n","      self.norm = nn.Parameter(torch.ones(out_features))\n","\n","      # Initialize parameters\n","      self.reset_parameters()\n","\n","   def reset_parameters(self):\n","      for t in self.T:\n","          nn.init.xavier_uniform_(t)\n","      for e in self.E:\n","          nn.init.xavier_uniform_(e)\n","\n","   def forward(self, H, A):\n","      H_out = torch.zeros_like(H)\n","      for k in range(self.num_relations):\n","\n","          messages_projection = A[k].T @ H @ self.E[k] # get messages\n","          degrees = A[k].sum(dim=1, keepdim=True) # calculate degrees\n","          degrees[degrees == 0] = 1.0\n","          messages_projection /= degrees # adjust messages to degrees\n","\n","          self_projection = H @ self.T[k] # get self projection\n","\n","          H_out += F.leaky_relu(self_projection + messages_projection) # combine self projection and messages\n","\n","      return H_out / self.norm"],"metadata":{"id":"ePZHtFFH19J9","executionInfo":{"status":"ok","timestamp":1734448752823,"user_tz":-60,"elapsed":564,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class GNNModel(nn.Module):\n","  def __init__(self, d, h, c, num_relations=1, num_layers=3):\n","    super(GNNModel, self).__init__()\n","    self.num_layers = num_layers\n","    self.gnn_layers = nn.ModuleList([GNNLayer(d, d) for _ in range(num_layers)])\n","    self.fc1 = nn.Linear(d, h)\n","    self.fc2 = nn.Linear(h, c)\n","\n","  def forward(self, H, A):\n","    for layer in self.gnn_layers:\n","      H = layer(H, A)\n","    # Classification\n","    H = F.relu(self.fc1(H))\n","    Output = self.fc2(H)\n","    return Output\n","\n","  def forward_layer(self, H, A, layer_idx):\n","    \"\"\"Forward pass for a specific layer.\"\"\"\n","    H = self.gnn_layers[layer_idx](H, A)\n","    return H"],"metadata":{"id":"o3iX3zup2HQg","executionInfo":{"status":"ok","timestamp":1734448754848,"user_tz":-60,"elapsed":8,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["d = 768\n","h = 400\n","c = 70\n","num_relations = 1\n","path = \"class/models/GNN.1.pt\"\n"],"metadata":{"id":"A0WxOwAE-Sxv","executionInfo":{"status":"ok","timestamp":1734448757928,"user_tz":-60,"elapsed":465,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model = GNNModel(d, h, c, num_relations)\n","criterion = nn.CrossEntropyLoss()\n","path = \"class/models/GNN.1.pt\"\n","model.load_state_dict(torch.load(path))\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"WwhOVb_R-NUL","executionInfo":{"status":"ok","timestamp":1734449142218,"user_tz":-60,"elapsed":2529,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"8621cfa5-feba-4edd-e2af-7f30e7343c62"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-3854a42efbc9>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(path))\n"]}]},{"cell_type":"code","source":["def layerwise_propagation(H, A, model):\n","  with torch.no_grad(): # No need to track gradients during inference\n","    for idx in range(model.num_layers):\n","      H = model.forward_layer(H, A, idx)\n","      # After propagating through all GNN layers, pass through the classification head\n","      H = F.leaky_relu(model.fc1(H))\n","      Output = model.fc2(H)\n","  return Output"],"metadata":{"id":"yfU5DKTP_qHs","executionInfo":{"status":"ok","timestamp":1734446602467,"user_tz":-60,"elapsed":507,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    # argmax to get predicted classes\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # count correct\n","    correct = (predicted == labels).sum().item()\n","\n","    # get average\n","    acc = correct / labels.size(0)  # Total number of samples\n","    return acc"],"metadata":{"id":"nbJc7_uMAGy-","executionInfo":{"status":"ok","timestamp":1734448784968,"user_tz":-60,"elapsed":432,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def validate(model, val_loader, criterion):\n","    model.eval()\n","    epoch_dev_losses = []\n","    epoch_dev_accuracy = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (H, A, y, training) in enumerate(val_loader):\n","\n","            out = model(H, A)\n","            print(out.size())\n","\n","            # Filter out training points\n","            mask = ~training\n","            filtered_out = out[mask]\n","            filtered_y = y[mask]\n","\n","\n","            dev_loss = criterion(filtered_out, filtered_y)\n","            dev_accuracy = accuracy(filtered_out, filtered_y)\n","\n","    # Avoid division by zero if no validation points were processed\n","    return dev_loss.item(), dev_accuracy, A"],"metadata":{"id":"w8gapaRnAM4Q","executionInfo":{"status":"ok","timestamp":1734446925638,"user_tz":-60,"elapsed":1030,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def validate(model, dev_loader, criterion, threshold=12000):\n","    model.eval()\n","    epoch_dev_losses = []\n","    epoch_dev_accuracy = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (H, A, y, indices) in enumerate(dev_loader):\n","            H = H.squeeze(0)\n","            A = [a.squeeze(0) for a in A]\n","            y = y.squeeze(0)\n","            indices = indices.squeeze(0)\n","\n","            out = model(H, A)\n","\n","            # Filter out training points\n","            mask = indices >= threshold\n","            filtered_out = out[mask]\n","            filtered_y = y[mask]\n","\n","            # Calculate loss and accuracy only on filtered outputs\n","            if filtered_out.size(0) > 0:  # Ensure there are samples to evaluate\n","                dev_loss = criterion(filtered_out, filtered_y)\n","                dev_accuracy = accuracy(filtered_out, filtered_y)\n","\n","                epoch_dev_losses.append(dev_loss.item())\n","                epoch_dev_accuracy.append(dev_accuracy)\n","\n","    # Avoid division by zero if no validation points were processed\n","    return np.mean(epoch_dev_losses), np.mean(epoch_dev_accuracy)"],"metadata":{"id":"XIv_DzqHKCeZ","executionInfo":{"status":"ok","timestamp":1734449093700,"user_tz":-60,"elapsed":934,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["loss, acc = validate(model, dev_loader, criterion)"],"metadata":{"id":"uJCQxVxvBA0g","executionInfo":{"status":"ok","timestamp":1734449156505,"user_tz":-60,"elapsed":6289,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DzTSirU7FgGq","executionInfo":{"status":"ok","timestamp":1734449162312,"user_tz":-60,"elapsed":1069,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f277cd44-c9a3-4aaa-ffd8-7cbc218f7527"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3.177604614874062"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMkD9r_sFiDR","executionInfo":{"status":"ok","timestamp":1734449164571,"user_tz":-60,"elapsed":7,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"8f9a3de8-f2e3-4d6c-a29d-2b197b993ba1"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6281040596830071"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["type(val_entities)\n","val_entities.size()\n","val_entities.sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFwMaPFhGBnB","executionInfo":{"status":"ok","timestamp":1734446990064,"user_tz":-60,"elapsed":1062,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"12735ed0-1631-418d-c387-06d23df05934"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1085820.)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["val_entities = val_entities.to(device)\n"],"metadata":{"id":"cCpOXPPHGP4F","executionInfo":{"status":"ok","timestamp":1734447084272,"user_tz":-60,"elapsed":5,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["(val_entities == A[0]).sum() / (val_entities == A[0]).size(0)**2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAsNuDBLGkUv","executionInfo":{"status":"ok","timestamp":1734447348790,"user_tz":-60,"elapsed":428,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f7595cca-b7c5-439a-c234-995e49380787"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1., device='cuda:0')"]},"metadata":{},"execution_count":59}]}]}