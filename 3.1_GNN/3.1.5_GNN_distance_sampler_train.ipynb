{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Q8SwOiR2bxtadXJeoC2c-bHDAG6P_HtL","timestamp":1736848209859}],"machine_shape":"hm","gpuType":"L4","collapsed_sections":["gQKaLkU1jxOb"],"authorship_tag":"ABX9TyOlhAThN4xMyj0k77qfaYCA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Text Classification - Training a GNN\n"],"metadata":{"id":"FBjat8lrIEsf"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","1.   Admin\n","2.   Dataset\n","3.   Model\n","4.   Train - Validate\n","5.   Training Loop"],"metadata":{"id":"O5wHwOnkIKvx"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","We now train a GNN in basic PyTorch. The model will look like a GCN. Inference willbe completed in another notebook as the whole graph must be uploaded at once."],"metadata":{"id":"2LYAHLRYIY_C"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"udtGvzIPItVT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vfqeSzgDH285","executionInfo":{"status":"ok","timestamp":1737188126430,"user_tz":-60,"elapsed":4110,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"bc19c451-e106-4945-aeea-143240d62714"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSXQ2wAfPWoF","executionInfo":{"status":"ok","timestamp":1737189510786,"user_tz":-60,"elapsed":2562,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"94523fe4-08a3-4f18-f5bf-f0212024b67d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data\n","* Load adjacency matrices"],"metadata":{"id":"q4Mn5bkiJDE8"}},{"cell_type":"code","source":["path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train')\n","df_dev = pd.read_pickle(path + 'df_dev')\n","df_test = pd.read_pickle(path + 'df_test')"],"metadata":{"id":"gPwH-5O5JHeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = 'class/tensors/adj_{}.pt'\n","\n","# train\n","train_people = torch.load(path.format('train_people'))\n","train_locations = torch.load(path.format('train_locations'))\n","train_entities = torch.load(path.format('train_entities'))\n","\n","# dev\n","dev_people = torch.load(path.format('dev_people'))\n","dev_locations = torch.load(path.format('dev_locations'))\n","dev_entities = torch.load(path.format('dev_entities'))\n","\n","# val (contains the adjacency matrix for both the training and the development set) #### train set stacked on top of dev set in the adjacency matrix\n","val_people = torch.load(path.format('val_people.1'))\n","val_locations = torch.load(path.format('val_locations.1'))\n","val_entities = torch.load(path.format('val_entities.1'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXpjrdiiJSO0","executionInfo":{"status":"ok","timestamp":1737188238362,"user_tz":-60,"elapsed":56236,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"240d5ba6-6586-42fc-cd62-27b97e26a816"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-6f8839527fd4>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_people = torch.load(path.format('train_people'))\n","<ipython-input-5-6f8839527fd4>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_locations = torch.load(path.format('train_locations'))\n","<ipython-input-5-6f8839527fd4>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  train_entities = torch.load(path.format('train_entities'))\n","<ipython-input-5-6f8839527fd4>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_people = torch.load(path.format('dev_people'))\n","<ipython-input-5-6f8839527fd4>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_locations = torch.load(path.format('dev_locations'))\n","<ipython-input-5-6f8839527fd4>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dev_entities = torch.load(path.format('dev_entities'))\n","<ipython-input-5-6f8839527fd4>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_people = torch.load(path.format('val_people.1'))\n","<ipython-input-5-6f8839527fd4>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_locations = torch.load(path.format('val_locations.1'))\n","<ipython-input-5-6f8839527fd4>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  val_entities = torch.load(path.format('val_entities.1'))\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Sampling:}$"],"metadata":{"id":"Tml4hS4iKIGX"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from copy import deepcopy\n","\n","def sample_neighborhood(primary_inds, input, adj, distance, neighbor_max = 4):\n","    \"\"\"\n","    Takes the given inds and the inputs, returns the sampled set of indices and the corresponding activation flag.\n","    If the activation flag is True, then the the datapoint is primary and has been search for neighbors and neighbors\n","    of neighbors. This indicates that we rely on the datapoint for metrics and loss.\n","\n","    Args:\n","      primary_inds : iterable\n","          indices sampled by the dataloader\n","      input : torch.Tensor\n","          (m,d) input tensor\n","      adj : torch.Tensor\n","          (m,m) adjacency matrix\n","      distance : torch.Tensor\n","          (m,m) : cosine similarity between all inputs\n","      neighbour_max : int (optional)\n","          The maximum number of neighbors to consider for each point\n","\n","    Returns:\n","      sampled_indices : list\n","          indices of all datapoints to be processed in the batch\n","      activation_flag : list\n","          boolean_flag indicating whether the corresponding datapoint is to be considered for metrics\n","    \"\"\"\n","\n","    def _get_closest_neighbors(ind):\n","      \"\"\"get up to neighbor_max close neighbors\"\"\"\n","      local_neighbors = []\n","      local_activation_flag = []\n","      candidate_neighbors = [neighbor.item() for neighbor in (adj[ind] > 0).nonzero(as_tuple=True)[0] if neighbor.item() not in sampled_indices]\n","      candidate_distances = [(neighbor, distance[primary_ind][neighbor]) for neighbor in candidate_neighbors]\n","      sorted_neighbors = sorted(candidate_distances, key=lambda x: x[1])\n","      return [neighbor for neighbor, dist in sorted_neighbors[:neighbor_max]], candidate_neighbors\n","\n","    sampled_indices = []\n","    activation_flag = []\n","    all_banned_neighbors = []\n","\n","    for primary_ind in primary_inds:\n","\n","      # if primary ind has been added as a neighbor, convert the activation flag to true, else add it as a standard primary index\n","      if primary_ind in sampled_indices:\n","        activation_flag[sampled_indices.index(primary_ind)] = True\n","      else:\n","        sampled_indices.append(primary_ind)\n","        activation_flag.append(True)\n","\n","      # print('\\n', primary_ind)\n","      # print('sampled_indices', sampled_indices)\n","\n","      level_1_neighbors, candidate_neighbors = _get_closest_neighbors(primary_ind)\n","      banned_neighbors = list(set(candidate_neighbors) - set(level_1_neighbors))\n","      all_banned_neighbors.extend(banned_neighbors)\n","      # print('banned_neighbors', banned_neighbors)\n","      # print('all_banned_neighbors', all_banned_neighbors)\n","\n","      level_1_activation_flag = [False for el in level_1_neighbors]\n","      sampled_indices.extend(level_1_neighbors)\n","      activation_flag.extend(level_1_activation_flag)\n","\n","      # print('level_1_neighbors', level_1_neighbors)\n","      # print('sampled_indices', sampled_indices)\n","      # print('level_1_activation_flag', level_1_activation_flag)\n","      # print('activation_flag', activation_flag)\n","\n","      for level_1_ind in level_1_neighbors:\n","        level_2_neighbors, _ = _get_closest_neighbors(level_1_ind)\n","        level_2_activation_flag = [False for el in level_2_neighbors]\n","        sampled_indices.extend(level_2_neighbors)\n","        activation_flag.extend(level_2_activation_flag)\n","\n","        # print('level_2_neighbors', level_2_neighbors)\n","        # print('sampled_indices', sampled_indices)\n","        # print('level_2_activation_flag', level_2_activation_flag)\n","        # print('activation_flag', activation_flag)\n","\n","    # include only 4 level one neighbors for each primary index to avoid pollution\n","    clean_indices = []\n","    clean_flags = []\n","    for i in range(len(sampled_indices)):\n","      target = sampled_indices[i]\n","      flag = activation_flag[i]\n","      if target in primary_inds:\n","        clean_indices.append(target)\n","        clean_flags.append(flag)\n","      elif target in all_banned_neighbors:\n","        continue\n","      else:\n","        clean_indices.append(target)\n","        clean_flags.append(flag)\n","    # print(f'\\ncleaning\\nsampled_indices : {sampled_indices}\\nclean_indices : {clean_indices}')\n","    return clean_indices, clean_flags\n"],"metadata":{"id":"wvPKQX4B_k9J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Sampling Test:}$"],"metadata":{"id":"gQKaLkU1jxOb"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","a = torch.Tensor([\n","    [0,1,0,0,0,0,0,1],\n","    [1,0,0,1,0,1,0,0],\n","    [0,1,0,1,0,0,1,0],\n","    [0,1,0,0,1,0,0,1],\n","    [1,1,0,0,1,0,0,0],\n","    [0,0,1,1,0,1,1,0],\n","    [0,0,0,1,0,0,0,1],\n","    [0,0,0,1,0,1,1,1]\n","])\n","\n","seed=42"],"metadata":{"id":"B5qimRXRPy4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","def neighbor_analysis(primary_inds: list[int], inds: list[int], adjacency_matrix: torch.Tensor):\n","    result = []\n","\n","    # Loop over each primary index\n","    for primary_idx in primary_inds:\n","        # Get neighbors for the primary index\n","        neighbors = []\n","        for ind in inds:\n","            # Check if ind is a neighbor of primary_idx\n","            if adjacency_matrix[primary_idx, ind] == 1:\n","                neighbors.append(ind)\n","\n","        # Find neighbors of neighbors (n + 1 neighbors)\n","        neighbors_of_neighbors = []\n","        for neighbor in neighbors:\n","            for ind in inds:\n","                # Check if ind is a neighbor of the current neighbor\n","                if adjacency_matrix[neighbor, ind] == 1 and ind != primary_idx:\n","                    neighbors_of_neighbors.append(ind)\n","\n","        # Remove duplicates for the neighbors of neighbors\n","        neighbors_of_neighbors = list(set(neighbors_of_neighbors))\n","\n","        # Add the tuple to results\n","        result.append((primary_idx, neighbors, neighbors_of_neighbors))\n","\n","    return result"],"metadata":{"id":"pj2hFslUIQu5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["primary_inds, input, adj, distance,"],"metadata":{"id":"efRNifUCP2zI"}},{"cell_type":"code","source":["def calculate_cosine(H):\n","    dot_product = torch.matmul(H, H.transpose(0, 1))  # shape (m, m)\n","\n","    lengths = torch.sqrt(dot_product.diagonal()).unsqueeze(1)  # shape (m, 1)\n","    denominator = lengths @ lengths.transpose(0, 1)  # shape (m, m)\n","\n","    return dot_product / denominator  # shape (m, m)"],"metadata":{"id":"ZnpjKIzOQI8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["H = torch.stack(list(df_train['vanilla_embedding.1']))\n"],"metadata":{"id":"nuz-dr2HQn3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["distance = calculate_cosine(H)"],"metadata":{"id":"BvI-vANjP6By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","inds = random.sample(list(range(12000)),6)\n","print(inds)\n","sample = sample_neighborhood(inds,H,train_entities,distance)\n","print(sample)\n","print(len(sample[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_FRZ_VOZt0D","executionInfo":{"status":"ok","timestamp":1736853092365,"user_tz":-60,"elapsed":538,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"09dfe984-304d-4d03-cde6-880e83d9649d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[6339, 2165, 4826, 11292, 11280, 5401]\n","\n"," 6339\n","sampled_indices [6339]\n","banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607]\n","level_1_neighbors [10087, 11957, 10768, 11320]\n","sampled_indices [6339, 10087, 11957, 10768, 11320]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False]\n","level_2_neighbors [26, 11083, 8133, 6232]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [6046, 4781, 3353, 11449]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [167, 3420, 6129, 11625]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [2143, 10461, 1226, 6948]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n"," 2165\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165]\n","banned_neighbors [11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959]\n","level_1_neighbors [6427, 8605, 4576, 8020]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False]\n","level_2_neighbors [2803, 7409, 721, 8961]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [9486, 8890, 2668, 3572]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [7502, 8615, 8959, 11]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4306, 5939, 8437, 10081]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n"," 4826\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826]\n","banned_neighbors []\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959]\n","level_1_neighbors []\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826]\n","level_1_activation_flag []\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n","\n"," 11292\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292]\n","banned_neighbors [2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959, 2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070]\n","level_1_neighbors [9235, 8778, 11085, 3998]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False]\n","level_2_neighbors [5419, 6283, 655, 10489]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4574, 3815, 2701, 2183]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [8465, 613, 2425, 8114]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [7153, 4905, 3613, 6116]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n"," 11280\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280]\n","banned_neighbors []\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959, 2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070]\n","level_1_neighbors []\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280]\n","level_1_activation_flag []\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n","\n"," 5401\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401]\n","banned_neighbors [9019, 10530, 2147, 11909, 10853, 1898, 6091, 4940, 3028, 8565, 7030, 5435, 9596, 9565, 2686]\n","all_banned_neighbors [9728, 3589, 7176, 11273, 11784, 3084, 3597, 5644, 10259, 11796, 2581, 5653, 6170, 3617, 6690, 7203, 11302, 552, 8755, 10804, 6198, 3640, 8252, 2622, 64, 7744, 10305, 10817, 10823, 9802, 10826, 591, 81, 7250, 5207, 4187, 9821, 10847, 2144, 9825, 11872, 4195, 11877, 5223, 4717, 10861, 8305, 5246, 9342, 1664, 5760, 3714, 10879, 6276, 10375, 648, 11915, 144, 2195, 3733, 10393, 6298, 6814, 8865, 6819, 1702, 9897, 4781, 8365, 1711, 3762, 7346, 9906, 7864, 11449, 2234, 5307, 7866, 3261, 11453, 8383, 10431, 1730, 3266, 2247, 4808, 9415, 6862, 2768, 3797, 9431, 6363, 7387, 10462, 5856, 7394, 1253, 6377, 7403, 2796, 2286, 3311, 1776, 5876, 7928, 2810, 765, 5885, 9471, 1794, 1795, 6403, 6920, 1290, 2315, 4363, 1293, 8464, 11025, 8468, 3353, 10532, 8485, 7975, 9511, 10024, 1838, 3375, 306, 11571, 6965, 7477, 9525, 7482, 2366, 4414, 2880, 3392, 8000, 4419, 8001, 11595, 7501, 10576, 9042, 4436, 345, 3418, 9568, 2403, 10093, 1904, 4979, 3961, 2938, 4474, 9594, 9597, 8574, 7552, 11143, 394, 10634, 11149, 5010, 3989, 2456, 2457, 6042, 6046, 415, 2976, 8606, 10144, 10655, 5541, 10150, 10661, 9641, 5036, 6575, 6066, 5559, 7612, 2493, 10177, 9157, 971, 11726, 7632, 8145, 469, 3541, 8149, 5594, 989, 481, 5092, 2536, 2025, 11755, 7148, 495, 7668, 4086, 5111, 3065, 2556, 4607, 11265, 3, 9732, 2056, 11, 6414, 3343, 9486, 6934, 11543, 3864, 796, 8992, 546, 2086, 4651, 9773, 2352, 5939, 55, 9022, 1343, 835, 9287, 7502, 10081, 9316, 7275, 1900, 2668, 5229, 9582, 2933, 3203, 10889, 1419, 652, 1933, 8335, 5265, 6290, 10130, 9109, 6557, 10914, 9380, 8615, 8370, 8890, 6331, 459, 11211, 3280, 4306, 3027, 6874, 9180, 6623, 10722, 2791, 9960, 1008, 3572, 8437, 8189, 1278, 8959, 2, 6146, 9222, 9224, 10249, 4109, 1037, 21, 6166, 4123, 5149, 5152, 11297, 9251, 4133, 45, 48, 49, 8240, 2099, 8244, 10288, 10293, 9265, 7218, 2105, 5172, 7222, 1081, 4157, 9273, 4159, 7231, 4172, 11349, 8289, 8291, 10339, 6245, 3173, 1127, 8297, 5232, 6257, 1139, 8315, 8316, 2173, 9339, 5249, 136, 139, 140, 5259, 4238, 7312, 1170, 149, 11416, 4249, 1177, 6300, 158, 8352, 5283, 4260, 7331, 168, 2217, 1192, 10411, 8364, 9391, 8368, 4275, 6325, 1205, 9397, 4281, 9409, 8388, 11461, 203, 6347, 10443, 5325, 6351, 7379, 8406, 11478, 10456, 2266, 6364, 10466, 4323, 10468, 7397, 11494, 232, 5357, 6382, 5361, 11507, 3316, 7415, 11512, 6397, 7421, 7425, 258, 5379, 7431, 6410, 8458, 10510, 2319, 273, 5394, 11539, 11540, 3354, 3361, 9506, 10534, 2344, 296, 1321, 9515, 1326, 7478, 2364, 3389, 10562, 9542, 1355, 5451, 9547, 7506, 3413, 11608, 10585, 5470, 10592, 7523, 1383, 9575, 10601, 2411, 8555, 6514, 2419, 8563, 1397, 381, 390, 10632, 1420, 4495, 8595, 9619, 406, 3480, 2459, 5538, 6573, 11697, 8630, 9654, 6584, 9662, 1473, 6605, 8665, 3545, 1499, 2527, 8675, 7651, 11749, 4584, 7658, 3564, 10733, 2542, 5614, 2544, 5620, 2549, 1525, 4605, 10750, 9727, 7680, 5633, 2562, 11782, 1547, 10764, 9739, 11792, 11793, 1556, 534, 4630, 7707, 543, 1568, 3618, 5666, 6693, 3624, 9768, 4650, 4652, 2608, 3632, 11824, 2611, 3635, 5683, 9779, 11831, 11839, 2626, 1602, 9796, 11845, 583, 4679, 585, 1608, 7752, 2637, 7753, 6735, 7756, 10834, 2643, 10837, 7765, 600, 2650, 6746, 10843, 2653, 6749, 4703, 1626, 7771, 9820, 3679, 8804, 7779, 3686, 3695, 6773, 10872, 10877, 7812, 11910, 8839, 2696, 10887, 11914, 8844, 10893, 6801, 10898, 4756, 2711, 6811, 8863, 8868, 7846, 10919, 8874, 2736, 4786, 4787, 1715, 9912, 6841, 698, 3769, 1723, 8896, 3787, 7883, 6864, 6873, 9954, 3811, 6888, 8942, 1774, 7920, 8948, 7925, 4854, 2814, 7934, 7935, 8963, 9991, 7945, 4880, 4881, 3863, 11038, 3874, 7973, 6951, 9000, 6953, 2858, 1833, 6956, 11052, 6958, 10033, 3896, 5945, 5946, 7994, 10042, 6977, 9028, 10054, 11079, 8008, 2892, 4945, 2905, 4955, 8033, 4967, 8040, 7028, 9076, 891, 8059, 9085, 3968, 8064, 2960, 8090, 9117, 9120, 2981, 934, 9127, 10153, 5035, 7083, 5039, 8111, 7092, 2997, 4021, 11195, 7100, 7101, 1979, 6075, 5063, 9160, 8140, 5070, 6094, 5074, 5075, 8151, 3032, 10202, 2013, 11231, 995, 3045, 2023, 1000, 1001, 5097, 4079, 11253, 9209, 3070, 9019, 10530, 2147, 11909, 10853, 1898, 6091, 4940, 3028, 8565, 7030, 5435, 9596, 9565, 2686]\n","level_1_neighbors [6382, 9910, 5054, 1274]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274]\n","level_1_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False]\n","level_2_neighbors [4028, 49, 2341, 5108]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4894, 545, 560, 1936]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [4685, 11186, 4695, 8812]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","level_2_neighbors [7399, 1612, 4249, 698]\n","sampled_indices [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612, 4249, 698]\n","level_2_activation_flag [False, False, False, False]\n","activation_flag [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n","\n","cleaning\n","sampled_indices : [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 6046, 4781, 3353, 11449, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 9486, 8890, 2668, 3572, 7502, 8615, 8959, 11, 4306, 5939, 8437, 10081, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 6382, 9910, 5054, 1274, 4028, 49, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612, 4249, 698]\n","clean_indices : [6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 9910, 5054, 1274, 4028, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612]\n","([6339, 10087, 11957, 10768, 11320, 26, 11083, 8133, 6232, 167, 3420, 6129, 11625, 2143, 10461, 1226, 6948, 2165, 6427, 8605, 4576, 8020, 2803, 7409, 721, 8961, 4826, 11292, 9235, 8778, 11085, 3998, 5419, 6283, 655, 10489, 4574, 3815, 2701, 2183, 8465, 613, 2425, 8114, 7153, 4905, 3613, 6116, 11280, 5401, 9910, 5054, 1274, 4028, 2341, 5108, 4894, 545, 560, 1936, 4685, 11186, 4695, 8812, 7399, 1612], [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False])\n","66\n"]}]},{"cell_type":"code","source":["analysis = neighbor_analysis(inds, sample[0], train_entities)\n","for item in analysis:\n","  print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flg7EyIjIm9X","executionInfo":{"status":"ok","timestamp":1736853171299,"user_tz":-60,"elapsed":1030,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"46cc6dec-2b5f-43b1-8b83-690dc3495939","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(6339, [10087, 11957, 10768, 11320], [8961, 10768, 26, 6427, 8605, 6948, 167, 11957, 11320, 8133, 1226, 11083, 721, 8020, 6232, 3420, 10461, 2143, 4576, 10087, 11625, 6129, 7409, 2803, 2165])\n","(2165, [10087, 6427, 8605, 4576, 8020], [8961, 10768, 26, 6427, 8605, 167, 11957, 11320, 6339, 8133, 11083, 721, 8020, 6232, 3420, 4576, 10087, 11625, 6129, 7409, 2803])\n","(4826, [], [])\n","(11292, [6129, 2143, 9235, 8778, 11085, 3998], [8961, 2183, 6283, 2701, 655, 10768, 1936, 8465, 9235, 6427, 3613, 4894, 3998, 545, 2341, 167, 2425, 4905, 5419, 560, 8114, 9910, 11320, 4028, 8778, 1612, 11085, 721, 3420, 4574, 2143, 6116, 613, 10087, 3815, 11625, 7399, 7409, 7153, 2803, 5108, 6129, 10489, 1274])\n","(11280, [], [])\n","(5401, [9910, 5054, 1274], [2183, 6283, 2701, 655, 1936, 9235, 4894, 545, 2341, 5419, 560, 11186, 4028, 5054, 8778, 1612, 4685, 4695, 4574, 3815, 7399, 8812, 6129, 7153, 5108, 10489, 1274])\n"]}]},{"cell_type":"code","source":["# inds = random.sample(list(range(12000)),4)\n","inds = list(range(101,105))\n","sample = sample_neighborhood([train_entities], inds, 16, 64, seed=42)\n","print(sample)\n","print(len(sample))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qK4tP7_j-ZH4","executionInfo":{"status":"ok","timestamp":1734532976830,"user_tz":-60,"elapsed":13,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"a6a8e195-9b34-45cd-a794-3ccf04c1f51d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[9221, 2061, 3599, 10261, 9214, 6937, 4386, 2855, 8492, 4654, 10039, 4152, 2363, 11581, 317, 6210, 580, 6725, 9046, 599, 5721, 3673, 1883, 3679, 4707, 4964, 101, 102, 103, 104, 8551, 5480, 5485, 11121, 3953, 7285, 8824, 11904, 6274, 9607, 11660, 7317, 5271, 8856, 3235, 7594, 4524, 5550, 10927, 4023, 1722, 4030, 10430, 8641, 4305, 8916, 9688, 2009, 10203, 10207, 9440, 9185, 1250, 8680, 6640, 11763, 2804, 510]\n","68\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Dataset:}$"],"metadata":{"id":"l7vHlB4K-U5i"}},{"cell_type":"code","source":["import torch\n","\n","class GNNDataset(Dataset):\n","  def __init__(self, H, A, labels, length, neighbor_max=4):\n","    \"\"\"Custom dataset with neighborhood sampling\n","\n","    Args:\n","      H : torch.tensor\n","        input embeddings (n x d)\n","\n","      A : torch.tensor\n","        adjacency matrix (n x n)\n","\n","      labels : torch.LongTensor\n","        y\n","\n","      meta_indices : torch.LongTensor\n","        index of datapoint to filter validation score\n","\n","      neighbor_max : int\n","        max neighbors for each node in mini-batch\n","\n","      batch_max : int\n","        max size of batch\n","\n","    \"\"\"\n","    # All inits must be tensors\n","    self.H = H.to(device)\n","    self.A = A.to(device)\n","    self.cosine = self.calculate_cosine(self.H)\n","    self.labels = labels.to(device)\n","    self.neighbor_max = neighbor_max\n","    self.length = length\n","\n","  def __len__(self):\n","    return self.length\n","\n","  def __getitem__(self, inds):\n","    # Sample neighborhood\n","\n","    # get inds in list\n","    inds = inds.tolist() if torch.is_tensor(inds) else (inds if isinstance(inds,list) else [inds])\n","\n","    # return the required inds (The inds are the sampes and the active flag dictates relatively if that sample should be counted)\n","    sampled_indices, active_flag = sample_neighborhood(inds, self.H, self.A, self.cosine, self.neighbor_max)\n","\n","    # get the input for the required inds\n","    H_batch = self.H[sampled_indices]\n","\n","    # get the adjacency matrix for the required inds\n","    A_batch = self.A[sampled_indices][:, sampled_indices]\n","\n","    # get the labels for the required inds\n","    labels_batch = self.labels[sampled_indices]\n","\n","    return H_batch, A_batch, labels_batch, torch.LongTensor(active_flag).to(device)\n","\n","  def calculate_cosine(self, H):\n","      dot_product = torch.matmul(H, H.transpose(0, 1))  # shape (m, m)\n","\n","      lengths = torch.sqrt(dot_product.diagonal()).unsqueeze(1)  # shape (m, 1)\n","      denominator = lengths @ lengths.transpose(0, 1)  # shape (m, m)\n","\n","      return dot_product / denominator  # shape (m, m)\n"],"metadata":{"id":"9Rag8OCtKo1r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" H, A, labels, length, neighbor_max=4"],"metadata":{"id":"YMO8D5We_FlU"}},{"cell_type":"code","source":["# training loader\n","H_train = torch.stack(list(df_train['vanilla_embedding.1']))\n","labels_train = torch.LongTensor(list(df_train['chapter_idx']))\n","A_train = train_entities\n","\n","\n","train_dataset = GNNDataset(H_train, A_train, labels_train, H_train.size(0), neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_train_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.RandomSampler(train_dataset),\n","    batch_size=8,\n","    drop_last=False)\n","\n","\n","train_loader = DataLoader(train_dataset, sampler = custom_train_sampler)\n","\n","# validation loader\n","df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df2, df1])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = val_entities\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, df2.shape[0], neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=1024,\n","    drop_last=False)\n","\n","dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)\n"],"metadata":{"id":"AxzIHGzKRr2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check batches\n","\n","# Number of batches to inspect\n","num_batches_to_check = 2\n","\n","for batch_idx, (inputs, adjacency, labels, flag) in enumerate(train_loader):\n","    print('\\n##########################\\n')\n","    print(f\"Batch {batch_idx + 1}/{num_batches_to_check}:\")\n","    print('-' * 10)\n","    print(\"Inputs:\")\n","    print(f\"  Type: {type(inputs)}\")\n","    print(f\"  Shape: {inputs.size()}\")\n","    print('-' * 10)\n","    print(\"Adjacency:\")\n","    print(f\"  Type: {type(adjacency)}\")\n","    print(f\"  Shape: {adjacency[0].size()}\")\n","    print('-' * 10)\n","    print(\"Indices:\")\n","    print(f\"  Type: {type(flag)}\")\n","    print(f\"  Shape: {flag.size()}\")\n","    print(flag)\n","    print('-' * 10)\n","    print(\"Labels:\")\n","    print(f\"  Type: {type(labels)}\")\n","    print(f\"  Shape: {labels.size()}\")\n","    print(labels)\n","\n","    # Stop after inspecting the desired number of batches\n","    if batch_idx + 1 >= num_batches_to_check:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MW9c2A1WE08","executionInfo":{"status":"ok","timestamp":1737047837756,"user_tz":-60,"elapsed":1459,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"74ef75d2-1ff6-4344-f8cd-ebf661962611","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","##########################\n","\n","Batch 1/2:\n","----------\n","Inputs:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 52, 768])\n","----------\n","Adjacency:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([52, 52])\n","----------\n","Indices:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 52])\n","tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","         0, 0, 0, 0]], device='cuda:0')\n","----------\n","Labels:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 52])\n","tensor([[64, 25, 25, 25, 25, 25, 16, 40, 33, 16, 17, 57, 16, 16, 16, 16, 16, 14,\n","         25, 25, 25, 25, 68, 15, 62, 42, 58, 49, 47, 44, 58, 56, 37, 49, 50, 41,\n","         48, 50, 17, 42, 12, 46, 63, 40, 40, 35, 39, 58,  8, 47, 58, 45]],\n","       device='cuda:0')\n","\n","##########################\n","\n","Batch 2/2:\n","----------\n","Inputs:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 62, 768])\n","----------\n","Adjacency:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([62, 62])\n","----------\n","Indices:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 62])\n","tensor([[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], device='cuda:0')\n","----------\n","Labels:\n","  Type: <class 'torch.Tensor'>\n","  Shape: torch.Size([1, 62])\n","tensor([[56, 44, 44, 42, 45, 14, 14, 14, 14, 14, 16, 16, 16, 16, 16, 15, 16, 14,\n","         15, 16, 16, 11, 53, 34, 35, 52, 56, 58, 57, 58, 54, 13, 47, 63, 60, 60,\n","         60, 60, 60, 60, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n","         32, 32, 32, 32, 32, 32, 32,  8]], device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["The dataloader seems to be working correctly, the implementation of custom sampling on all indices at once leads to DataLoaders collate function inserting a new dimension that it will stach against. Because all indices are dealt with at once, there is no stacking.\n","\n","The simple solution will be to simply squeeze the tensors in the training loop. The validation loader eradicates randomness from the process."],"metadata":{"id":"6H8779aHR9wL"}},{"cell_type":"markdown","source":["## $\\color{blue}{Model:}$"],"metadata":{"id":"WrZ8xkIsSnvw"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class GNNLayer(nn.Module):\n","    def __init__(self, in_features, out_features, dropout=0.5, training=True):\n","        super(GNNLayer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.num_relations = num_relations\n","        self.dropout = dropout\n","        self.training = training\n","\n","        self.T = nn.Parameter(torch.Tensor(in_features, out_features))\n","        self.E = nn.Parameter(torch.Tensor(in_features, out_features))\n","\n","        # Batch normalization\n","        self.batch_norm = nn.BatchNorm1d(out_features)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.T)\n","        nn.init.xavier_uniform_(self.E)\n","\n","    def forward(self, H, A):\n","        messages_projection = A.T @ H @ self.E\n","        degrees = A.sum(dim=1, keepdim=True)\n","        degrees[degrees == 0] = 1.0\n","        messages_projection /= degrees\n","\n","        self_projection = H @ self.T\n","\n","        # Include skip connection\n","        H_out = F.leaky_relu(self_projection + messages_projection) + H\n","        H_out = F.dropout(H_out, p=self.dropout)\n","\n","        # Apply batch normalization\n","        H_out = self.batch_norm(H_out)\n","\n","        return H_out\n","\n","class GNNModel(nn.Module):\n","    def __init__(self, d, h, c, num_layers=2, dropout=0.5):\n","        super(GNNModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.gnn_layers = nn.ModuleList([GNNLayer(d, d, dropout) for _ in range(num_layers)])\n","        self.fc1 = nn.Linear(d, h)\n","        self.batch_norm_fc1 = nn.BatchNorm1d(h)\n","        self.fc2 = nn.Linear(h, c)\n","        self.dropout = dropout\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.fc1.weight)\n","        nn.init.xavier_uniform_(self.fc2.weight)\n","        nn.init.zeros_(self.fc1.bias)\n","        nn.init.zeros_(self.fc2.bias)\n","\n","    def forward(self, H, A):\n","        for layer in self.gnn_layers:\n","            H = layer(H, A)\n","\n","        H = F.dropout(H, p=self.dropout, training=self.training)\n","        H = F.relu(self.batch_norm_fc1(self.fc1(H)))\n","        Output = self.fc2(H)\n","        return Output\n","\n","    def forward_layer(self, H, A, layer_idx):\n","        \"\"\"Forward pass for a specific layer.\"\"\"\n","        H = self.gnn_layers[layer_idx](H, A)\n","        return H\n"],"metadata":{"id":"64sKwqPvPXmM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","d = 768\n","h = 400   # hidden dimension of fully connected layer\n","c = 70   # number of classes\n","num_relations = 1   # number of relationship types\n","\n","# Model, Loss, Optimizer\n","model = GNNModel(d, h, c)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001)\n","\n"],"metadata":{"id":"NP8Q4qpiVp-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_parameters_per_module(model):\n","    print(\"Module and parameter counts:\")\n","\n","    for name, module in model.named_modules():\n","        # Skip the top-level module (the model itself)\n","        if not isinstance(module, nn.Module) or name == \"\":\n","            continue\n","\n","        param_count = sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","        if param_count > 0:  # Only print modules that have parameters\n","            print(f\"{name}: {param_count} parameters\")"],"metadata":{"id":"2zm1UjLWZUBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count_parameters_per_module(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LxQpA1fYB5e","executionInfo":{"status":"ok","timestamp":1737189531774,"user_tz":-60,"elapsed":377,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"c67783ac-6eaf-4d14-acb2-213e353d0e47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Module and parameter counts:\n","gnn_layers: 2362368 parameters\n","gnn_layers.0: 1181184 parameters\n","gnn_layers.0.batch_norm: 1536 parameters\n","gnn_layers.1: 1181184 parameters\n","gnn_layers.1.batch_norm: 1536 parameters\n","fc1: 307600 parameters\n","batch_norm_fc1: 800 parameters\n","fc2: 28070 parameters\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Train-Validate:}$"],"metadata":{"id":"5so7JQvHdAvF"}},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    # argmax to get predicted classes\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # count correct\n","    correct = (predicted == labels).sum().item()\n","\n","    # get average\n","    acc = correct / labels.size(0)  # Total number of samples\n","    return acc"],"metadata":{"id":"EZhnvYLtWbqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def train(model, train_loader, criterion, optimizer):\n","    model.train()\n","    epoch_train_losses = []\n","    epoch_train_accuracy = []\n","\n","    for batch_idx, (H, A, y, flag) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        H = H.squeeze(0)\n","        A = A.squeeze(0)\n","        y = y.squeeze(0)\n","        flag = flag.squeeze(0).bool()\n","\n","        out = model(H,A)\n","\n","        filtered_out = out[flag]\n","        filtered_y = y[flag]\n","\n","        train_loss = criterion(filtered_out, filtered_y)\n","        train_accuracy = accuracy(filtered_out, filtered_y)\n","\n","\n","        epoch_train_losses.append(train_loss.item())\n","        epoch_train_accuracy.append(train_accuracy)\n","\n","        # Backpropagation and optimization\n","        train_loss.backward()\n","        optimizer.step()\n","\n","    return np.mean(epoch_train_losses), np.mean(epoch_train_accuracy)"],"metadata":{"id":"EftvJs1pdDlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dev_loader, criterion, threshold=12000):\n","    model.eval()\n","    epoch_dev_losses = []\n","    epoch_dev_accuracy = []\n","    pred_holder = []\n","    real_holder = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (H, A, y, flag) in enumerate(dev_loader):\n","            H = H.squeeze(0)\n","            A = A.squeeze(0)\n","            y = y.squeeze(0)\n","            flag = flag.squeeze(0).bool()\n","\n","            out = model(H, A)\n","\n","            filtered_out = out[flag]\n","            filtered_y = y[flag]\n","\n","\n","            dev_loss = criterion(filtered_out, filtered_y)\n","            dev_accuracy = accuracy(filtered_out, filtered_y)\n","\n","            epoch_dev_losses.append(dev_loss.item())\n","            epoch_dev_accuracy.append(dev_accuracy)\n","\n","    # Avoid division by zero if no validation points were processed\n","    return np.mean(epoch_dev_losses), np.mean(epoch_dev_accuracy)"],"metadata":{"id":"FEfSsAmimuEU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Training:}$"],"metadata":{"id":"dyzhkkmcR29K"}},{"cell_type":"code","source":["from collections import namedtuple\n","Stats = namedtuple('Stats', [\n","    'train_loss',\n","    'train_accuracy',\n","    'dev_loss',\n","    'dev_accuracy',\n","    'epoch',\n","    'lr',\n","    'alpha',\n","    'max_accuracy'\n","])"],"metadata":{"id":"8gM37WLCNRJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_config(lr_low, lr_high, alpha_low, alpha_high):\n","  np.random.seed()\n","  lr = round(10**float(np.random.uniform(lr_low,lr_high)),6)\n","  alpha = round(10**float(np.random.uniform(alpha_low,alpha_high)),6)\n","  return lr, alpha"],"metadata":{"id":"E_DaEjRlNXl7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_ranges( lr, lr_range, alpha, alpha_range):\n","\n","  lr_center = lr\n","  lr_low = lr_center - lr_range/2\n","  lr_high = lr_center + lr_range/2\n","  lr_diff = lr_high - lr_low\n","\n","  alpha_center = alpha\n","  alpha_low = alpha_center - alpha_range/2\n","  alpha_high = alpha_center + alpha_range/2\n","  alpha_diff = alpha_high - alpha_low\n","\n","  return (lr_low, lr_high, alpha_low, alpha_high)"],"metadata":{"id":"4V9JC3PUNbpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def search_stats(results):\n","  best_stats = None\n","  max_dev_accuracy = 0\n","  for i in range(len(results)):\n","    acc = results[i].dev_accuracy\n","    if acc > max_dev_accuracy:\n","      best_stats = results[i]\n","      max_dev_accuracy = acc\n","  return best_stats"],"metadata":{"id":"-sNDLKonNj_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 0):\n","  \"\"\"\n","  Runs a training setup\n","  verbose == 1 - print model results\n","  verbose == 2 -> print epoch and model results\n","  \"\"\"\n","  model = model.to(device)\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=alpha)\n","\n","  # Prepare data loaders\n","  train_loader = DataLoader(train_dataset, sampler = custom_train_sampler)\n","  dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)\n","\n","  # Hold epoch stats\n","  train_losses = []\n","  train_accuracy = []\n","  dev_losses = []\n","  dev_accuracy = []\n","  epoch_holder = []\n","\n","  # Break if no improvement\n","  current_best = 0\n","  no_improvement = 0\n","\n","\n","  # Run epochs\n","  for epoch in range(epochs):\n","\n","    # break out of epochs\n","    if no_improvement >= 6:\n","      break\n","\n","    # call training and validation functions\n","    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n","    dev_loss, dev_acc = validate(model, dev_loader, criterion)\n","\n","    # Store epoch stats\n","    train_losses.append(train_loss)\n","    train_accuracy.append(train_acc)\n","    dev_losses.append(dev_loss)\n","    dev_accuracy.append(dev_acc)\n","    epoch_holder.append(epoch + 1)\n","\n","    # check for improvement\n","    if dev_acc > current_best:\n","      current_best = dev_acc\n","      no_improvement = 0\n","    else:\n","      no_improvement += 1\n","\n","    # save best model\n","    if dev_acc > max_accuracy:\n","      torch.save(model.state_dict(), path)\n","      max_accuracy = dev_acc\n","\n","\n","    # optionally print epoch results\n","    if verbose == 2:\n","      print(f'\\n --------- \\nEpoch: {epoch + 1}\\n')\n","      print(f'Epoch {epoch + 1} train loss: {train_loss:.4f}')\n","      print(f'Epoch {epoch + 1} train accuracy: {train_acc:.4f}')\n","      print(f'Epoch {epoch + 1} dev loss: {dev_loss:.4f}')\n","      print(f'Epoch {epoch + 1} dev accuracy: {dev_acc:.4f}')\n","\n","      # save best results\n","  max_ind = np.argmax(dev_accuracy)\n","\n","  stats = Stats(\n","      train_losses[max_ind],\n","      train_accuracy[max_ind],\n","      dev_losses[max_ind],\n","      dev_accuracy[max_ind],\n","      epoch_holder[max_ind],\n","      lr, alpha,\n","      max_accuracy\n","  )\n","\n","  # optionally print model results\n","  if verbose in [1,2]:\n","    print('\\n ######## \\n')\n","    print(f'lr:{stats.lr}, alpha:{stats.alpha} @ epoch {stats.epoch}.')\n","    print(f'TL:{stats.train_loss}, TA:{stats.train_accuracy}.')\n","    print(f'DL:{stats.dev_loss}, DA:{stats.dev_accuracy}')\n","\n","  return stats"],"metadata":{"id":"J3PQBpDIYnib"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### $\\color{red}{Sanity-check:}$"],"metadata":{"id":"1C-wVpsPUasU"}},{"cell_type":"code","source":["# model\n","model = GNNModel(d, h, c)"],"metadata":{"id":"h9dVcM1VaN6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training loader\n","H_train = torch.stack(list(df_train['vanilla_embedding.1']))\n","labels_train = torch.LongTensor(list(df_train['chapter_idx']))\n","A_train = train_entities\n","\n","\n","train_dataset = GNNDataset(H_train, A_train, labels_train, H_train.size(0), neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_train_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.RandomSampler(train_dataset),\n","    batch_size=256,\n","    drop_last=False)\n","\n","\n","train_loader = DataLoader(train_dataset, sampler = custom_train_sampler)\n","\n","# validation loader\n","df1 = df_train[['vanilla_embedding.1', 'chapter_idx']]\n","df2 = df_dev[['vanilla_embedding.1', 'chapter_idx']]\n","df_val = pd.concat([df2, df1])\n","H_val = torch.stack(list(df_val['vanilla_embedding.1']))\n","labels_val = torch.LongTensor(list(df_val['chapter_idx']))\n","A_val = val_entities\n","\n","validation_dataset = GNNDataset(H_val, A_val, labels_val, df2.shape[0], neighbor_max=4)\n","\n","# Prevent dataloader from calling a single index at a time\n","custom_validation_sampler = torch.utils.data.sampler.BatchSampler(\n","    torch.utils.data.sampler.SequentialSampler(validation_dataset),\n","    batch_size=1024,\n","    drop_last=False)\n","\n","dev_loader = DataLoader(validation_dataset, sampler = custom_validation_sampler)\n"],"metadata":{"id":"9pxw5ELFaN8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 2\n","lr = 0.0005\n","alpha = 0.0001\n","path = \"class/models/GNN_distance_sampler.pt\"\n","max_accuracy = 0\n","model = GNNModel"],"metadata":{"id":"Qf0cxrsteYzM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RPYCNxFAUZPu","executionInfo":{"status":"error","timestamp":1736864935780,"user_tz":-60,"elapsed":1216028,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"27df3f9d-d5f3-4f7c-97d2-66270357a840","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3351, 2961, 1285, 11337, 10087, 9692, 10548, 1902]\n","[11313, 9937, 7837, 10536, 11687, 9238, 11239, 5075]\n","[10284, 6339, 4617, 7661, 2543, 3138, 11978, 11237]\n","[1364, 6227, 9042, 5224, 7459, 1499, 2438, 10970]\n","[3210, 7092, 10889, 7501, 536, 7731, 7564, 2785]\n","[5961, 6612, 8085, 7418, 10261, 10557, 10888, 5634]\n","[4770, 1478, 3988, 7703, 1954, 401, 3216, 6247]\n","[10301, 8860, 11203, 11517, 4248, 2303, 8128, 7034]\n","[6071, 3634, 3199, 2586, 8699, 6732, 6274, 6016]\n","[7061, 5872, 7977, 6859, 3872, 10797, 1767, 10002]\n","[1832, 2426, 8090, 4733, 741, 2342, 7554, 9251]\n","[1068, 8486, 1210, 1807, 8642, 7645, 3396, 3679]\n","[8188, 5558, 1521, 940, 10845, 10791, 5361, 10150]\n","[6437, 3148, 4963, 4060, 10691, 760, 9404, 8283]\n","[10943, 4561, 5300, 839, 118, 941, 820, 11949]\n","[3569, 10426, 3808, 10730, 2647, 11624, 10677, 9683]\n","[11919, 3391, 10789, 7591, 9429, 7432, 1208, 11011]\n","[6709, 2267, 4404, 3724, 2874, 9964, 3376, 6983]\n","[5099, 474, 3078, 11491, 3052, 4808, 4289, 3154]\n","[9043, 775, 10721, 781, 6209, 3440, 9473, 4161]\n","[10567, 5215, 8621, 4621, 8790, 515, 729, 1739]\n","[8770, 3181, 3537, 7255, 9265, 7451, 3608, 6051]\n","[1595, 11317, 11164, 10765, 886, 4001, 11554, 2765]\n","[2863, 656, 11854, 8998, 2947, 5455, 5399, 11605]\n","[11871, 4687, 657, 4022, 7935, 8118, 2843, 3706]\n","[10367, 1328, 4169, 10457, 7994, 9834, 4467, 11420]\n","[1243, 1660, 8921, 2368, 8547, 2608, 4353, 4066]\n","[5101, 7242, 929, 7988, 66, 3599, 5465, 5994]\n","[7553, 4864, 11442, 2535, 3075, 10258, 11757, 7910]\n","[2648, 9712, 2879, 7926, 4160, 3132, 5542, 3401]\n","[7361, 1738, 8846, 3623, 902, 11108, 5048, 11946]\n","[4940, 7806, 11987, 8903, 6766, 5874, 4149, 10035]\n","[4570, 5352, 11888, 2951, 9439, 6303, 9789, 5013]\n","[10629, 5232, 6352, 5062, 10731, 11525, 7888, 4232]\n","[8251, 2312, 11680, 11006, 4197, 8240, 11417, 9656]\n","[2270, 11559, 5608, 4748, 6841, 9483, 5318, 11914]\n","[7513, 4987, 8212, 8850, 7172, 6249, 10277, 7408]\n","[8893, 3909, 5775, 1898, 2306, 9586, 10432, 6295]\n","[3482, 7439, 4639, 8691, 2462, 6019, 1100, 5609]\n","[7297, 7593, 5456, 5548, 8873, 11172, 108, 3294]\n","[6921, 9469, 6545, 1788, 3626, 11076, 1347, 5024]\n","[10674, 11439, 2066, 6620, 11283, 3687, 2891, 8842]\n","[3631, 7974, 8756, 7636, 9320, 8530, 11986, 2432]\n","[8637, 9364, 5234, 6646, 4796, 2944, 8514, 8916]\n","[4935, 7923, 856, 10234, 2876, 2635, 2020, 1386]\n","[1581, 637, 9357, 10438, 10805, 5141, 5405, 3524]\n","[10138, 9141, 3370, 11240, 11963, 3685, 8964, 2934]\n","[3592, 2885, 9244, 9618, 2006, 5589, 3665, 7473]\n","[1874, 5566, 11371, 5419, 11898, 10212, 11855, 4375]\n","[8816, 11782, 2053, 3866, 2134, 4012, 6962, 7750]\n","[1443, 11562, 6361, 10544, 11661, 5803, 8300, 4930]\n","[7454, 7330, 7563, 8931, 5695, 1144, 9143, 2172]\n","[5752, 1403, 1964, 907, 11046, 11684, 2121, 10870]\n","[9517, 5815, 2732, 4998, 6384, 10991, 9899, 11013]\n","[3581, 8172, 7325, 6892, 10227, 7349, 1559, 1925]\n","[5322, 2229, 8714, 4856, 6981, 10895, 4863, 5881]\n","[9572, 10835, 9536, 3549, 6713, 8828, 10311, 8859]\n","[10748, 5771, 8898, 3141, 1498, 8501, 2102, 2203]\n","[6011, 3334, 2734, 10094, 9099, 182, 2139, 7353]\n","[11004, 11159, 4842, 6467, 9525, 224, 3744, 6958]\n","[414, 10696, 5950, 10361, 11379, 6573, 1920, 4205]\n","[9084, 3757, 2045, 4643, 7929, 4965, 8552, 8083]\n","[3338, 1963, 4673, 5077, 1728, 8643, 11003, 11071]\n","[10415, 72, 8294, 4909, 2731, 4260, 383, 1571]\n","[10703, 4283, 8536, 1329, 6508, 1325, 5006, 6659]\n","[7751, 7472, 7810, 11063, 2369, 2484, 8473, 11095]\n","[8184, 7476, 3648, 159, 10201, 3033, 5388, 11333]\n","[2758, 2409, 11980, 7785, 8244, 8444, 386, 8896]\n","[8384, 156, 10928, 9932, 1641, 6501, 8394, 3600]\n","[5073, 10720, 7316, 10063, 7083, 9177, 10217, 765]\n","[4038, 8292, 11470, 11893, 4510, 10325, 5025, 7582]\n","[10965, 3140, 9689, 2287, 4030, 10774, 10135, 2828]\n","[10865, 3812, 8250, 3656, 9941, 10637, 241, 7824]\n","[7819, 8581, 888, 8658, 11564, 11656, 4675, 7575]\n","[4647, 6169, 7069, 6360, 4677, 10734, 2448, 7430]\n","[4608, 11632, 4628, 10514, 10566, 830, 3780, 8348]\n","[3498, 3582, 8192, 6571, 11444, 8135, 8443, 8746]\n","[9827, 7583, 11118, 10906, 5610, 11678, 6536, 1970]\n","[9329, 8036, 5057, 1214, 11611, 8392, 11200, 5471]\n","[121, 3693, 11328, 6594, 5621, 4463, 8302, 5739]\n","[11921, 10274, 878, 628, 6783, 6153, 7759, 10435]\n","[242, 10453, 3146, 7855, 1822, 6465, 5442, 11052]\n","[7193, 4840, 4440, 7456, 10151, 4905, 6059, 400]\n","[2124, 3001, 555, 5209, 9685, 8925, 1222, 5731]\n","[2164, 8760, 2413, 6693, 1704, 4630, 1797, 10911]\n","[5795, 9751, 7823, 6959, 8742, 6686, 5153, 7572]\n","[4378, 8905, 3200, 7946, 5766, 9367, 3414, 4281]\n","[1776, 743, 4562, 11150, 8489, 8069, 5540, 5174]\n","[4496, 1588, 1649, 10473, 4804, 10105, 4252, 8904]\n","[4389, 9829, 3225, 7251, 2397, 9085, 5886, 9164]\n","[8264, 1171, 4606, 10624, 8917, 7562, 80, 2665]\n","[4441, 3153, 5763, 11670, 8301, 1112, 2783, 2999]\n","[11291, 10586, 3829, 5475, 6667, 10719, 4392, 4070]\n","[11723, 7403, 6949, 2378, 9797, 9999, 9529, 5683]\n","[9851, 10348, 9823, 5245, 11435, 4098, 2753, 7048]\n","[5505, 4156, 2851, 6060, 9812, 134, 7319, 655]\n","[11877, 3518, 11673, 3501, 10519, 8869, 33, 11905]\n","[2844, 8772, 5265, 5644, 11202, 4192, 10847, 44]\n","[11486, 4927, 2294, 4435, 6152, 9558, 3328, 11927]\n","[517, 8725, 11675, 1896, 1479, 2128, 5133, 3457]\n","[1256, 10062, 10898, 6197, 9362, 11944, 10651, 7078]\n","[10811, 6176, 1530, 11892, 2138, 6370, 3128, 2282]\n","[9948, 6656, 4096, 9610, 1724, 10309, 240, 8799]\n","[11563, 1268, 9955, 3324, 11041, 8944, 8006, 10143]\n","[6706, 10495, 9638, 9554, 57, 4122, 11831, 2994]\n","[10553, 5218, 9422, 2319, 10436, 2750, 4633, 11280]\n","[9169, 7143, 594, 8272, 1082, 7345, 11551, 6221]\n","[5021, 3673, 5400, 1150, 429, 6631, 8613, 7233]\n","[776, 10665, 11654, 5524, 3290, 10252, 10038, 2711]\n","[5443, 7098, 10352, 6287, 4900, 6403, 10975, 2115]\n","[11910, 5779, 9183, 4307, 411, 1766, 3906, 3303]\n","[2199, 10695, 5800, 1701, 10215, 7767, 424, 11784]\n","[591, 11768, 480, 7221, 5272, 3786, 6381, 3533]\n","[2125, 10961, 4565, 7752, 11210, 2084, 10871, 6597]\n","[9977, 10900, 4688, 10983, 9, 7291, 5594, 7934]\n","[8464, 5604, 9648, 8410, 1676, 8567, 5936, 8730]\n","[7270, 8366, 1872, 9990, 1236, 8951, 2801, 6033]\n","[4037, 5362, 271, 8847, 2959, 5888, 2523, 1011]\n","[9755, 3919, 8789, 5212, 8279, 343, 4743, 1778]\n","[2071, 1063, 10186, 11880, 2964, 9452, 3087, 2713]\n","[1116, 7772, 4370, 11058, 10064, 3331, 11182, 11390]\n","[3305, 10089, 7412, 6157, 10022, 11915, 3496, 7786]\n","[10020, 22, 3864, 8721, 2710, 10032, 1700, 4494]\n","[5672, 10590, 4765, 7814, 10568, 4438, 8191, 2491]\n","[6306, 4681, 1993, 8688, 225, 3158, 9070, 2898]\n","[11713, 162, 8010, 3405, 6350, 419, 10251, 2396]\n","[7064, 586, 7729, 768, 231, 11979, 2681, 2093]\n","[11050, 6699, 8018, 5825, 5618, 1867, 11928, 3188]\n","[8402, 3742, 10511, 3822, 9193, 9077, 3353, 3858]\n","[8884, 5993, 1959, 7676, 1668, 8644, 289, 2569]\n","[8098, 4512, 229, 8888, 4035, 8585, 8142, 2589]\n","[6319, 4383, 450, 5859, 9518, 2026, 4134, 1047]\n","[6123, 4832, 1594, 1593, 3449, 6871, 5736, 2563]\n","[11796, 6334, 3562, 5401, 9192, 7656, 635, 8762]\n","[2547, 5677, 5074, 10488, 3490, 7374, 1264, 365]\n","[6617, 7984, 1542, 2277, 5195, 416, 5539, 6431]\n","[1174, 3987, 7391, 8588, 4962, 8759, 1863, 10923]\n","[9778, 527, 6094, 1957, 1731, 8009, 3851, 4850]\n","[2756, 5093, 6315, 9132, 3543, 9254, 3098, 5116]\n","[11423, 4720, 974, 2008, 1908, 11991, 1493, 2666]\n","[8163, 10537, 4680, 10047, 4530, 964, 11783, 8883]\n","[4718, 5058, 8382, 2454, 10704, 1287, 1187, 7936]\n","[3630, 9791, 5714, 4875, 3702, 9617, 2465, 11733]\n","[804, 2060, 6765, 193, 4299, 6325, 7016, 5222]\n","[4660, 6270, 2790, 3810, 11085, 5223, 4503, 9432]\n","[8253, 1843, 3675, 834, 8584, 2508, 1938, 8573]\n","[7303, 9431, 8236, 8137, 158, 1775, 6546, 2063]\n","[307, 4155, 9301, 9087, 2414, 8465, 10117, 1200]\n","[7726, 9930, 7523, 7962, 10362, 5747, 228, 1540]\n","[9104, 10914, 7540, 5123, 10237, 2177, 2541, 6114]\n","[7831, 1233, 3865, 1933, 11233, 2336, 690, 5570]\n","[8695, 3776, 3542, 1060, 9053, 7511, 4939, 7643]\n","[6635, 1280, 5949, 5698, 1849, 2035, 5530, 5927]\n","[5125, 5255, 6186, 6506, 6813, 4846, 11488, 1136]\n","[7328, 9503, 10262, 7945, 824, 4315, 184, 7512]\n","[6080, 4781, 810, 9137, 5685, 2971, 7398, 6446]\n","[688, 11185, 9337, 8416, 8239, 6318, 2324, 11663]\n","[1506, 8190, 4746, 2447, 67, 1623, 5701, 7848]\n","[10913, 2762, 8019, 5320, 8433, 8075, 3867, 423]\n","[1980, 532, 4684, 434, 10194, 4425, 8180, 6552]\n","[9390, 928, 715, 2344, 6649, 10801, 9245, 3062]\n","[5291, 9809, 9158, 8417, 9828, 6178, 1609, 7239]\n","[4581, 7390, 2939, 10320, 10831, 11808, 9673, 6775]\n","[174, 10092, 6931, 1967, 8481, 7486, 4426, 1627]\n","[678, 3262, 3735, 11814, 11049, 5854, 4902, 5274]\n","[6661, 5095, 7941, 9717, 10239, 11603, 5041, 1254]\n","[4133, 9732, 1004, 4538, 9966, 6399, 11044, 7960]\n","[8005, 11192, 8321, 4041, 4334, 5845, 7646, 9088]\n","[6560, 8266, 5326, 1281, 5022, 10846, 7961, 8541]\n","[1391, 7652, 11460, 483, 8281, 6248, 2993, 385]\n","[9378, 3529, 7457, 9737, 11160, 10178, 8037, 3372]\n","[11580, 4293, 6973, 579, 10310, 6986, 10551, 6559]\n","[11901, 10794, 1711, 2390, 8484, 4228, 11353, 11539]\n","[8255, 8507, 11026, 5066, 2550, 4048, 11162, 5143]\n","[9071, 10359, 342, 5233, 11413, 512, 10713, 862]\n","[5374, 6608, 1220, 6833, 9543, 11500, 4442, 5240]\n","[5150, 1516, 4851, 801, 2749, 7266, 2326, 5898]\n","[7309, 544, 1407, 2005, 7209, 11094, 4986, 10588]\n","[5421, 1596, 3534, 9207, 8755, 5490, 11961, 6345]\n","[4363, 9537, 7256, 1463, 7783, 4123, 2219, 4479]\n","[8113, 5036, 3519, 5134, 9494, 4943, 2664, 7788]\n","[2728, 6548, 282, 2830, 3644, 7920, 18, 6149]\n","[2970, 1425, 9859, 7181, 11780, 3045, 81, 4545]\n","[170, 9740, 10048, 11698, 1148, 10736, 7425, 9407]\n","[5517, 7028, 9457, 2278, 7035, 5790, 10690, 3127]\n","[11357, 8129, 814, 5857, 575, 10386, 6257, 2795]\n","[11685, 10932, 6523, 5631, 8451, 8709, 191, 7145]\n","[4614, 6923, 8017, 52, 3614, 1042, 8414, 8482]\n","[4036, 735, 9264, 4932, 5979, 7813, 10023, 1678]\n","[5129, 4926, 6392, 10347, 10268, 9049, 4604, 9490]\n","[8914, 11432, 11359, 5913, 7745, 9037, 7537, 7369]\n","[2987, 2403, 4464, 4753, 9424, 11268, 6803, 6385]\n","[3109, 10316, 2215, 7195, 10318, 10599, 183, 11749]\n","[7622, 6210, 1725, 7312, 5891, 8874, 6630, 4157]\n","[5051, 6254, 3384, 2823, 6712, 7728, 8678, 8306]\n","[9391, 7077, 5925, 11024, 4150, 763, 11581, 8162]\n","[433, 7696, 5793, 5708, 7659, 7446, 3094, 11595]\n","[6037, 7918, 4961, 6442, 1853, 3593, 5085, 2886]\n","[8995, 6974, 6012, 2191, 8419, 8580, 2404, 1223]\n","[4040, 4112, 8511, 3705, 10033, 3241, 11671, 8889]\n","[11846, 4518, 564, 4694, 9358, 511, 10078, 9287]\n","[5304, 10597, 3632, 4857, 9280, 2743, 7815, 7551]\n","[10281, 9093, 3017, 9984, 10868, 3404, 10656, 8679]\n","[11230, 1756, 11204, 1735, 7366, 8413, 9041, 7304]\n","[10107, 7087, 2925, 11394, 6750, 10275, 9974, 3385]\n","[5473, 5213, 2386, 11518, 2183, 3645, 6941, 10338]\n","[6880, 6642, 665, 7627, 8311, 2894, 10850, 9501]\n","[7124, 8591, 10951, 11985, 7253, 6619, 833, 3820]\n","[6496, 9967, 8031, 6730, 4616, 41, 9263, 10926]\n","[3288, 1997, 11645, 7470, 4238, 1816, 650, 2469]\n","[5351, 4826, 10546, 4004, 4839, 3984, 6909, 11187]\n","[805, 5417, 4958, 3051, 10317, 458, 6879, 3468]\n","[4716, 1036, 4127, 1032, 2374, 11585, 1777, 1975]\n","[4609, 8280, 3162, 11512, 6004, 8631, 10164, 9545]\n","[5912, 6085, 3677, 10662, 491, 2188, 11788, 5804]\n","[11652, 3205, 4017, 7084, 10371, 10582, 10664, 3629]\n","[3186, 3646, 4499, 5055, 8690, 10973, 1934, 3298]\n","[3266, 4183, 9637, 6936, 11463, 2110, 11561, 8342]\n","[9184, 3343, 5963, 5772, 1053, 8655, 8149, 6444]\n","[2029, 6068, 1868, 8463, 9020, 9445, 10368, 3362]\n","[5004, 1755, 11143, 7526, 4881, 1051, 9465, 585]\n","[5002, 5094, 845, 4005, 10464, 4795, 4599, 10614]\n","[3424, 2280, 4302, 2458, 10756, 2061, 4737, 1814]\n","[853, 6582, 9444, 6645, 2453, 11837, 1477, 4095]\n","[8207, 1428, 10463, 10995, 3446, 127, 11153, 11167]\n","[10560, 1397, 11473, 9080, 9566, 6942, 7036, 3504]\n","[5883, 7736, 2192, 5307, 9668, 2149, 2354, 5271]\n","[10994, 11234, 7747, 5397, 7153, 2193, 3816, 8350]\n","[10170, 8211, 6076, 8379, 8, 8554, 236, 8257]\n","[7993, 9691, 499, 8618, 7995, 2686, 1750, 8032]\n","[3806, 5329, 2494, 9616, 4166, 2769, 10433, 11042]\n","[11047, 10505, 1915, 4141, 11091, 6127, 7184, 11277]\n","[2632, 5182, 5333, 1157, 2001, 7315, 4823, 8468]\n","[1230, 4290, 8627, 3807, 5987, 10694, 1154, 11469]\n","[11640, 8161, 1517, 7780, 531, 7956, 11622, 10242]\n","[11951, 4601, 7360, 10649, 3096, 5301, 5128, 2430]\n","[6491, 2906, 1696, 8051, 10960, 2622, 11982, 10606]\n","[11522, 10655, 9951, 7340, 10279, 172, 3347, 145]\n","[7017, 6417, 2304, 10755, 1301, 9749, 3119, 417]\n","[11462, 10585, 3374, 6422, 8225, 5543, 3655, 148]\n","[6280, 901, 11384, 5645, 1460, 329, 11550, 7904]\n","[10978, 6724, 10945, 11553, 8660, 8808, 7241, 3635]\n","[4750, 2220, 5349, 5096, 5849, 6819, 817, 1655]\n","[3895, 2106, 9756, 5476, 3884, 1651, 1873, 11105]\n","[2602, 7426, 9294, 8561, 8461, 9628, 4297, 2953]\n","[4355, 8065, 8728, 6326, 1318, 4388, 4554, 6946]\n","[5951, 7494, 8167, 757, 10006, 10617, 10858, 2760]\n","[5207, 11340, 2370, 9567, 6206, 2674, 8343, 8648]\n","[9410, 8589, 5462, 9862, 7538, 10256, 7385, 5177]\n","[7557, 453, 2996, 407, 4316, 631, 1380, 1458]\n","[2154, 1585, 11156, 5981, 1313, 10830, 10687, 722]\n","[5976, 5030, 5065, 9693, 5571, 9168, 4982, 7972]\n","[7662, 8900, 2667, 11943, 11424, 541, 1348, 2065]\n","[5974, 4873, 11720, 11490, 2085, 4957, 9138, 9346]\n","[3081, 3991, 5921, 1633, 1345, 9913, 4950, 11147]\n","[2234, 157, 9710, 2007, 6835, 4977, 2804, 5298]\n","[3650, 11074, 10226, 553, 7743, 5496, 5588, 7718]\n","[4354, 10408, 149, 441, 4380, 3392, 11735, 7605]\n","[2619, 11764, 8513, 9259, 8330, 7963, 9214, 3164]\n","[8983, 5214, 989, 4364, 5794, 5230, 9674, 7381]\n","[6286, 2330, 3598, 7263, 3507, 11324, 949, 11725]\n","[4230, 6827, 1671, 7615, 2634, 3658, 3980, 3280]\n","[8285, 780, 815, 4549, 2659, 4135, 4216, 11833]\n","[6972, 2429, 7400, 7373, 5827, 8551, 2707, 1604]\n","[3201, 2813, 6175, 9848, 9413, 10462, 2015, 8947]\n","[368, 8879, 11368, 8523, 11428, 7611, 6823, 25]\n","[5957, 3624, 11066, 4695, 11662, 8136, 10558, 10134]\n","[6141, 9960, 2107, 826, 8978, 4357, 9861, 2140]\n","[4427, 11712, 4241, 2013, 9246, 5350, 4309, 11266]\n","[667, 11421, 4424, 5210, 1979, 8146, 100, 10809]\n","[10520, 64, 8538, 8081, 10039, 641, 9784, 2656]\n","[9550, 9102, 4488, 9588, 4612, 2880, 10271, 9794]\n","[659, 4797, 4553, 7038, 4534, 4893, 10104, 8357]\n","[6124, 3574, 7844, 10085, 8091, 4602, 5931, 4830]\n","[2526, 2256, 9813, 5550, 283, 11956, 11216, 1762]\n","[5829, 8774, 5469, 11630, 1351, 11109, 2559, 3355]\n","[10176, 4152, 5824, 9744, 4890, 7686, 6484, 11440]\n","[6049, 1276, 955, 2214, 3875, 4063, 10351, 9135]\n","[7700, 8391, 4117, 6814, 5864, 3817, 3579, 6005]\n","[4769, 1307, 5710, 7463, 7419, 1527, 7415, 8788]\n","[4838, 5907, 4084, 2151, 11106, 2286, 10066, 6488]\n","[9123, 1531, 7674, 11395, 5199, 6607, 1107, 29]\n","[3160, 606, 6613, 7877, 8377, 4910, 8793, 327]\n","[4397, 1494, 6359, 2884, 1130, 4146, 4891, 11297]\n","[8298, 7797, 3439, 958, 1799, 5978, 4803, 4815]\n","[9232, 693, 3145, 8185, 4805, 2169, 7115, 5718]\n","[9027, 1659, 6299, 8579, 8785, 11925, 2787, 10276]\n","[11410, 284, 10732, 8054, 4176, 6289, 7379, 11941]\n","[2895, 9601, 6498, 9223, 3996, 5263, 819, 10454]\n","[10986, 11015, 5893, 11938, 10784, 8459, 6697, 6807]\n","[2892, 11867, 2643, 4564, 10659, 8488, 147, 6267]\n","[4547, 6374, 7487, 8310, 6486, 3957, 2560, 6720]\n","[5166, 2189, 4102, 2210, 4172, 8063, 7402, 8147]\n","[4678, 11454, 8359, 3470, 3870, 4867, 1942, 960]\n","[8087, 4773, 3703, 11635, 10668, 4229, 6561, 9201]\n","[139, 2623, 11362, 3793, 6032, 379, 9945, 10793]\n","[9606, 4068, 7644, 6704, 9891, 10741, 5038, 11501]\n","[9122, 5410, 3325, 8158, 829, 1118, 5497, 7685]\n","[10726, 758, 3792, 1228, 10295, 5126, 7578, 10163]\n","[2899, 5625, 82, 4362, 5332, 2418, 7896, 683]\n","[11924, 31, 4184, 10646, 11466, 9655, 1582, 9878]\n","[5439, 5112, 8331, 3057, 7421, 10626, 11361, 970]\n","[2805, 6256, 2375, 4296, 7764, 3079, 8393, 3312]\n","[2833, 6406, 5296, 6804, 3474, 10108, 9914, 5314]\n","[6569, 1306, 10214, 10915, 2470, 6600, 983, 6296]\n","[11705, 9351, 1945, 94, 8629, 2070, 4719, 8656]\n","[4705, 11641, 614, 10331, 2186, 4860, 7382, 1987]\n","[4836, 9734, 2522, 3299, 3873, 7854, 5254, 4459]\n","[3263, 3122, 7148, 3425, 330, 5225, 6194, 11895]\n","[8068, 10017, 6142, 11660, 382, 4210, 6054, 7067]\n","[8082, 930, 8672, 9415, 783, 7856, 3177, 10667]\n","[9317, 3011, 4632, 6789, 1989, 5003, 5294, 8694]\n","[8768, 5408, 807, 3676, 6866, 5652, 11260, 3553]\n","[11909, 6393, 3878, 7635, 988, 5977, 2814, 3914]\n","[11289, 9819, 9904, 5660, 3258, 3769, 5412, 4514]\n","[6951, 5481, 395, 10181, 4268, 11613, 3318, 2557]\n","[2937, 4286, 10114, 9339, 3061, 5031, 11014, 1089]\n","[3613, 6129, 1677, 2754, 3860, 8840, 11482, 3084]\n","[10173, 6179, 2002, 2449, 11142, 2831, 8771, 8962]\n","[1043, 1682, 8206, 11567, 11375, 1262, 5311, 4747]\n","[9846, 346, 3367, 1158, 3930, 5702, 8262, 1893]\n","[7393, 6516, 2555, 3484, 1640, 3236, 9924, 11664]\n","[6794, 3077, 7059, 3000, 11948, 11583, 4816, 11465]\n","[7621, 1726, 11497, 5873, 1869, 1587, 9487, 9739]\n","[10493, 376, 8661, 4582, 5568, 5341, 7164, 3420]\n","[3845, 812, 8738, 3714, 10881, 5809, 5757, 1818]\n","[571, 10068, 1374, 7903, 3309, 332, 11119, 10160]\n","[1815, 11107, 1385, 3167, 10340, 2064, 7207, 8935]\n","[101, 7465, 8633, 1487, 10821, 994, 7227, 525]\n","[4916, 5070, 10305, 11620, 4074, 4277, 618, 6079]\n","[6507, 4236, 10901, 5, 3472, 11319, 2240, 9224]\n","[8216, 11059, 2461, 1072, 8673, 9112, 7552, 7306]\n","[4969, 6977, 4064, 5699, 5426, 7947, 11590, 5273]\n","[7461, 1567, 8767, 8515, 11760, 9821, 1251, 9742]\n","[4782, 8460, 3781, 9170, 10357, 7401, 75, 507]\n","[6756, 2701, 2305, 8795, 2307, 7450, 831, 1206]\n","[6499, 117, 11717, 7008, 8074, 4492, 4646, 2105]\n","[2082, 11278, 1048, 7158, 6073, 8965, 4908, 2761]\n","[4092, 5923, 3680, 10822, 9451, 6056, 10205, 7285]\n","[7025, 5648, 9130, 5755, 7363, 11099, 4994, 5586]\n","[1718, 10330, 3998, 1857, 10156, 968, 1198, 11828]\n","[2180, 4717, 6993, 11851, 7214, 7178, 8442, 10621]\n","[10549, 6337, 494, 7231, 784, 1601, 6681, 1282]\n","[10333, 6356, 9282, 972, 2530, 11668, 5201, 3169]\n","[9892, 4652, 3811, 10800, 8353, 6078, 1981, 7618]\n","[6912, 4069, 1244, 4137, 3243, 4637, 1289, 1246]\n","[9005, 777, 6159, 4644, 6721, 7584, 7550, 3763]\n","[8996, 11699, 2936, 1007, 2158, 11493, 10893, 11548]\n","[669, 7812, 5461, 2241, 8986, 5159, 2327, 2341]\n","[5260, 4249, 8230, 9372, 4466, 11365, 2916, 8599]\n","[566, 2211, 704, 8776, 265, 5486, 8105, 6914]\n","[6455, 6701, 2997, 8344, 5268, 5863, 8335, 1344]\n","[9157, 10197, 813, 11217, 10028, 2532, 8491, 4075]\n","[1475, 3784, 4697, 8855, 349, 7009, 1033, 4023]\n","[1431, 11616, 11472, 8011, 3488, 1035, 5081, 5063]\n","[11962, 3450, 3465, 5638, 2147, 6623, 9379, 10752]\n","[7097, 10513, 4386, 2824, 3184, 3938, 4165, 4099]\n","[5477, 6053, 3755, 10013, 5336, 8318, 8364, 6847]\n","[1740, 196, 7197, 4198, 2103, 2083, 9316, 8706]\n","[5287, 9602, 5371, 6917, 9120, 6967, 2059, 11507]\n","[7500, 5997, 524, 3754, 9108, 5603, 9297, 3005]\n","[1780, 10671, 8187, 797, 1080, 7932, 4144, 7971]\n","[5929, 3723, 4358, 5840, 10884, 11477, 9086, 6503]\n","[4861, 3575, 3213, 7762, 9963, 1783, 2252, 11281]\n","[4142, 5816, 3883, 9147, 2301, 513, 7992, 10735]\n","[10912, 7399, 354, 11736, 9103, 1763, 17, 60]\n","[7040, 7182, 1554, 5435, 10542, 4469, 1216, 7950]\n","[10223, 8677, 3717, 4382, 4605, 9724, 10141, 98]\n","[1935, 4595, 1387, 4634, 3133, 7480, 5305, 6549]\n","[5838, 2910, 9793, 7964, 2998, 10683, 767, 7835]\n","[6371, 10883, 5946, 2575, 4482, 10342, 6204, 8079]\n","[10142, 10315, 9998, 7468, 364, 1562, 9252, 6988]\n","[4043, 1551, 2703, 4607, 1686, 11037, 1877, 11374]\n","[9463, 9785, 150, 3652, 7388, 3594, 11414, 6729]\n","[6682, 1556, 5563, 6202, 10940, 963, 2022, 5106]\n","[4408, 1774, 5414, 4033, 4852, 5599, 11208, 5050]\n","[11146, 2552, 4968, 2835, 10483, 4313, 3276, 2174]\n","[5507, 4967, 7704, 5988, 10042, 5786, 11511, 3320]\n","[2986, 1579, 1719, 7707, 7841, 8186, 8214, 4449]\n","[3926, 9672, 5541, 9562, 5151, 10841, 6453, 4103]\n","[6405, 8519, 4578, 7787, 943, 4623, 5868, 7506]\n","[5279, 6489, 6382, 5684, 9209, 5675, 2452, 4700]\n","[1715, 3363, 7521, 35, 10583, 2740, 3441, 2712]\n","[3981, 503, 7085, 2285, 7925, 8295, 102, 7409]\n","[3228, 195, 6779, 4993, 2094, 4067, 9774, 8743]\n","[3607, 8735, 4784, 4105, 11817, 435, 1630, 1635]\n","[8452, 660, 207, 4980, 10760, 1135, 6250, 7230]\n","[6402, 11809, 4571, 9818, 4086, 8985, 8527, 11148]\n","[1500, 2323, 5447, 9205, 11434, 5406, 12, 5552]\n","[8049, 11827, 6894, 6220, 2262, 7851, 10644, 5335]\n","[4278, 1181, 7670, 7068, 10418, 8372, 3479, 4484]\n","[489, 9327, 7354, 7192, 3174, 6255, 9919, 7641]\n","[5743, 11722, 11766, 691, 6116, 3977, 6440, 1646]\n","[10387, 9191, 1122, 9750, 1092, 10936, 7880, 4132]\n","[2439, 8797, 1839, 5297, 3215, 10416, 6224, 3837]\n","[10157, 3544, 9133, 5122, 7372, 6483, 8540, 11082]\n","[8972, 11864, 10449, 8569, 2887, 1549, 8332, 716]\n","[7311, 4199, 9796, 10112, 11254, 843, 128, 9274]\n","[8446, 7900, 1038, 3283, 1422, 5680, 7687, 4113]\n","[5286, 1120, 8901, 7959, 616, 11587, 5784, 4325]\n","[4876, 661, 2524, 11144, 4749, 1153, 3108, 891]\n","[5889, 9165, 634, 1990, 319, 11679, 11798, 8576]\n","[8866, 5673, 10093, 9584, 10818, 11889, 9972, 5745]\n","[5040, 890, 318, 10559, 6458, 4655, 8247, 8555]\n","[3032, 7161, 8984, 11885, 1202, 4253, 5404, 36]\n","[9048, 1466, 670, 2877, 1197, 2614, 840, 8862]\n","[7876, 5992, 5629, 2810, 9660, 8199, 470, 11459]\n","[3049, 5633, 8155, 1625, 5663, 6145, 9204, 3214]\n","[11331, 7998, 7433, 7424, 388, 5605, 10859, 4707]\n","[3962, 8418, 5826, 3896, 5015, 9480, 4829, 6670]\n","[5740, 451, 6903, 609, 11068, 4790, 6557, 1319]\n","[10437, 10400, 9615, 3203, 7274, 8590, 10019, 8385]\n","[3719, 3560, 1947, 363, 6151, 2605, 623, 6655]\n","[189, 9500, 165, 7634, 5175, 1905, 10666, 10982]\n","[5091, 3249, 5459, 5071, 11471, 2384, 4250, 6537]\n","[2528, 7464, 5186, 4179, 5650, 8715, 4206, 11344]\n","[3091, 6586, 11232, 8963, 10693, 5667, 10236, 5394]\n","[6456, 10489, 5969, 6379, 5796, 9991, 8705, 4225]\n","[7892, 10450, 7534, 472, 3433, 10660, 708, 10981]\n","[4367, 7232, 6383, 1390, 5664, 5846, 8380, 2235]\n","[6199, 280, 3928, 3863, 8915, 2946, 8145, 9641]\n","[10855, 2040, 3393, 2038, 5617, 3285, 6317, 7895]\n","[1991, 475, 2539, 2358, 4560, 7352, 9866, 4619]\n","[8164, 9757, 2571, 8275, 5528, 11478, 1794, 2075]\n","[629, 466, 6862, 8682, 11607, 11485, 6457, 9988]\n","[1835, 10398, 6689, 2299, 11859, 533, 3221, 4348]\n","[5516, 4261, 6749, 10423, 3573, 4416, 9241, 6615]\n","[11529, 11393, 10592, 8351, 3292, 2108, 5084, 5527]\n","[7196, 4121, 8997, 5600, 1312, 2870, 4055, 6480]\n","[10620, 589, 11772, 3114, 1845, 9799, 4462, 11005]\n","[6541, 8033, 3805, 969, 2554, 6077, 9855, 9982]\n","[7893, 6679, 791, 11358, 9798, 8566, 10836, 2759]\n","[10358, 7715, 6128, 1848, 8117, 10864, 8880, 10175]\n","[2284, 2766, 1021, 8400, 8945, 8143, 3485, 4337]\n","[4338, 9237, 5681, 9105, 7389, 6217, 9009, 4665]\n","[3246, 10820, 10220, 8936, 9058, 8328, 10241, 8570]\n","[9298, 5256, 6144, 10004, 9950, 9064, 7346, 10235]\n","[1238, 4178, 8801, 7825, 625, 247, 1217, 1451]\n","[3527, 10661, 113, 5353, 5267, 557, 1090, 3559]\n","[727, 1927, 2650, 4631, 8304, 8423, 6244, 4371]\n","[11381, 3657, 569, 1121, 11290, 3009, 4218, 11547]\n","[9519, 4535, 6926, 2606, 8156, 10976, 1535, 10332]\n","[1846, 6660, 192, 11137, 1723, 645, 8911, 4483]\n","[905, 3170, 2841, 2499, 10930, 4431, 3172, 2720]\n","[1838, 3641, 11706, 1309, 7666, 3536, 9709, 4577]\n","[4611, 5504, 9642, 2581, 1805, 3823, 6547, 600]\n","[601, 7149, 4009, 6146, 4062, 173, 10925, 2861]\n","[6651, 1612, 9038, 2058, 11355, 5219, 6115, 1669]\n","[5910, 2744, 714, 5860, 4517, 3736, 6026, 5283]\n","[10468, 841, 5726, 1179, 4985, 754, 7525, 7875]\n","[5499, 9467, 8421, 11241, 2903, 8708, 3493, 6873]\n","[7991, 6173, 7146, 9968, 7333, 1404, 10446, 3871]\n","[5762, 7868, 7022, 5967, 563, 9314, 5869, 3113]\n","[11506, 9551, 11953, 8176, 9520, 6226, 11132, 9946]\n","[11309, 7159, 2072, 6298, 695, 4691, 9824, 8440]\n","[1162, 1023, 5170, 679, 6885, 11532, 2359, 8634]\n","[2153, 1408, 497, 7693, 7223, 6415, 2478, 3551]\n","[3400, 7642, 3619, 6708, 6478, 1552, 7103, 3416]\n","[11016, 1643, 3552, 11700, 9940, 4116, 187, 6845]\n","[10131, 7695, 8249, 146, 562, 6285, 10506, 11342]\n","[10852, 3751, 4082, 21, 10579, 1320, 11579, 251]\n","[2693, 10916, 460, 3411, 6793, 5160, 11356, 1784]\n","[8849, 3796, 10222, 11969, 6518, 8556, 2228, 4899]\n","[852, 10832, 9363, 6420, 297, 5292, 5867, 3034]\n","[11364, 6588, 4139, 11634, 4053, 5249, 7505, 160]\n","[11651, 3307, 2143, 9387, 10798, 1194, 5243, 1384]\n","[10339, 6785, 9957, 4349, 4405, 8229, 9109, 5971]\n","[6734, 5179, 945, 5991, 9897, 3683, 9682, 2255]\n","[8592, 789, 10484, 8315, 3364, 6997, 1879, 9111]\n","[11618, 6876, 11869, 10480, 11510, 10103, 10195, 10119]\n","[3489, 2488, 2500, 1930, 3970, 773, 8494, 6304]\n","[5546, 7288, 5339, 3963, 7441, 8838, 10100, 6830]\n","[11904, 4481, 9435, 5188, 9589, 7377, 1229, 6475]\n","[5076, 3037, 9738, 2236, 3956, 8698, 3888, 8546]\n","[299, 4586, 6898, 7003, 6452, 7517, 6177, 2146]\n","[4827, 1946, 11220, 308, 1538, 10584, 8189, 45]\n","[7829, 3940, 778, 199, 4458, 5165, 9156, 993]\n","[8213, 3252, 1705, 9116, 11543, 11315, 7000, 7847]\n","[3255, 587, 9688, 4955, 8638, 6860, 4556, 2514]\n","[11879, 4735, 3377, 6411, 10874, 6626, 11157, 8820]\n","[2596, 264, 6989, 9395, 986, 7990, 5391, 6020]\n","[2051, 10539, 6102, 11601, 2435, 3916, 6690, 5198]\n","[7045, 2702, 8288, 7874, 1650, 2, 8650, 5392]\n","[5791, 10724, 11022, 9905, 10573, 10080, 10580, 6759]\n","[9922, 10402, 5016, 9258, 11912, 6636, 4954, 6407]\n","[4423, 1435, 742, 4551, 10641, 827, 11644, 11923]\n","[8763, 2048, 5190, 5010, 2562, 6963, 7664, 2090]\n","[2688, 5248, 11628, 9906, 7821, 11589, 7547, 6971]\n","[8496, 6673, 7283, 3340, 11989, 2777, 9418, 3016]\n","[721, 8003, 9066, 6088, 11997, 10300, 1940, 9867]\n","[3233, 5020, 11795, 1880, 2126, 5839, 6943, 9549]\n","[5187, 1106, 1115, 5756, 219, 10465, 5616, 1464]\n","[980, 551, 10482, 6695, 7804, 6466, 8587, 16]\n","[1057, 9047, 10341, 4853, 5480, 11750, 1240, 3563]\n","[932, 8504, 6292, 8891, 8798, 9060, 9535, 9705]\n","[7420, 5023, 3092, 11287, 1336, 1653, 5485, 6665]\n","[7047, 11574, 7395, 6283, 4703, 8390, 3316, 11857]\n","[11520, 8073, 6520, 3080, 5939, 997, 5706, 1932]\n","[255, 5705, 917, 3020, 1123, 3512, 610, 10989]\n","[8934, 8474, 10290, 3640, 3269, 7096, 10772, 3610]\n","[4981, 7138, 8775, 4016, 10070, 509, 5277, 10814]\n","[1015, 11860, 619, 1828, 9587, 9230, 884, 2962]\n","[7657, 8086, 10636, 9386, 3969, 9012, 6098, 7313]\n","[6875, 3850, 6492, 11352, 3636, 11658, 11476, 1765]\n","[1870, 818, 11691, 5729, 5942, 1215, 8299, 5495]\n","[7587, 5935, 1009, 11308, 10896, 7702, 11829, 9095]\n","[9163, 3194, 3800, 11206, 6047, 2050, 2696, 10575]\n","[565, 6238, 1558, 6776, 2290, 10902, 209, 3764]\n","[7019, 2315, 7976, 373, 9837, 2695, 2893, 7081]\n","[1592, 5834, 11378, 11773, 5534, 1143, 249, 7746]\n","[4350, 10404, 9200, 7123, 6910, 5068, 6818, 233]\n","[10708, 2049, 6550, 11602, 5577, 4294, 548, 2517]\n","[5562, 581, 7541, 560, 5944, 1878, 4641, 11606]\n","[9173, 377, 4679, 272, 9718, 10324, 7205, 8436]\n","[9018, 11774, 8254, 1103, 712, 2185, 7128, 9321]\n","[1842, 11075, 4059, 1751, 1994, 1813, 961, 11873]\n","[2321, 10405, 9895, 8323, 6030, 350, 7922, 4164]\n","[7100, 10623, 734, 404, 9925, 2965, 9979, 5760]\n","[3365, 43, 2929, 9001, 5312, 8088, 9342, 303]\n","[7011, 4541, 7801, 8970, 7134, 4835, 6791, 8520]\n","[10627, 9291, 8922, 9903, 7252, 1192, 10363, 9548]\n","[7741, 4539, 143, 7405, 4711, 6887, 9814, 1353]\n","[485, 2016, 8608, 7079, 5989, 1453, 5493, 703]\n","[9894, 3995, 125, 1491, 3369, 1804, 8061, 1261]\n","[8265, 295, 2935, 9019, 9775, 10625, 4913, 6138]\n","[133, 6817, 9595, 9366, 1534, 7180, 10111, 10069]\n","[11152, 10547, 10297, 6604, 6001, 1829, 9242, 914]\n","[11763, 11608, 10591, 1156, 8975, 5047, 3432, 9918]\n","[2912, 3508, 8072, 11786, 2092, 6639, 8669, 8221]\n","[2233, 4843, 4901, 2019, 6575, 10773, 10470, 11267]\n","[3771, 546, 5171, 5363, 1949, 504, 5114, 5847]\n","[2511, 2385, 2218, 1998, 6572, 1438, 1159, 8282]\n","[9504, 8347, 5914, 338, 3505, 2335, 9853, 3975]\n","[8974, 11231, 2968, 11911, 2561, 9405, 9650, 6685]\n","[11389, 10954, 8498, 6616, 3284, 521, 7862, 873]\n","[6995, 7953, 3368, 11451, 10739, 7711, 437, 11621]\n","[1096, 8305, 9715, 5284, 328, 7037, 432, 2264]\n","[7258, 8217, 6544, 1134, 11165, 8447, 92, 3986]\n","[6668, 9421, 1199, 6893, 8779, 8502, 4061, 11754]\n","[3952, 6160, 10304, 10962, 2027, 7865, 9269, 4453]\n","[8564, 402, 8861, 3869, 7749, 2941, 10139, 3790]\n","[2383, 4931, 1124, 2990, 5658, 1802, 5738, 2205]\n","[1629, 7295, 211, 8624, 275, 3894, 3115, 8809]\n","[8800, 3261, 8711, 9790, 9172, 11103, 6627, 7187]\n","[2838, 11703, 10890, 3958, 1114, 8340, 4406, 2793]\n","[7771, 5905, 4372, 5553, 8409, 8933, 11596, 10152]\n","[11701, 6777, 4778, 10065, 857, 1020, 8960, 5821]\n","[10980, 11753, 6740, 3002, 6322, 5479, 4825, 4267]\n","[4365, 7006, 11778, 2857, 10072, 9619, 2417, 1819]\n","[2156, 4329, 10569, 1574, 10963, 9010, 9167, 7531]\n","[7139, 2956, 547, 7536, 2331, 6927, 3696, 6558]\n","[1455, 7808, 6568, 7112, 2638, 9040, 1439, 9417]\n","[5180, 11056, 306, 3418, 1078, 1734, 3899, 8505]\n","[203, 10849, 1260, 6687, 2145, 11575, 11738, 7698]\n","[2506, 8360, 10866, 86, 5348, 4027, 8927, 5376]\n","[378, 9032, 9659, 7658, 5709, 10498, 8575, 2942]\n","[2104, 1399, 10263, 11647, 1746, 334, 849, 9076]\n","[1961, 3502, 11812, 10941, 50, 3068, 5895, 7569]\n","[5877, 6148, 5247, 6140, 6388, 1748, 5691, 9909]\n","[186, 1982, 4794, 7784, 5835, 1232, 2989, 4999]\n","[1801, 4243, 6543, 8639, 7102, 5734, 3993, 10993]\n","[11380, 6028, 7597, 3911, 7190, 9073, 8363, 10322]\n","[8892, 3014, 9288, 11908, 8562, 561, 5611, 481]\n","[2380, 1721, 278, 4919, 5253, 1334, 4091, 9916]\n","[1786, 152, 3336, 6850, 3454, 2057, 7130, 1378]\n","[9408, 10717, 1070, 10428, 5086, 4093, 8991, 8531]\n","[7607, 3056, 11604, 4589, 6634, 8906, 1599, 10645]\n","[8961, 8100, 3747, 11093, 2642, 5764, 9033, 1196]\n","[3018, 8646, 5246, 3947, 6436, 7136, 3023, 1561]\n","[1732, 10971, 11350, 11659, 9604, 1363, 2251, 7723]\n","[5583, 2260, 8457, 3804, 5814, 6100, 4167, 4319]\n","[10892, 142, 11819, 2582, 4740, 6727, 8458, 1189]\n","[8534, 348, 7386, 8697, 5346, 7689, 2055, 1691]\n","[10602, 10427, 1468, 10574, 10577, 603, 4921, 10512]\n","[11826, 1862, 9875, 2392, 359, 749, 5424, 4470]\n","[8270, 8971, 5206, 7336, 6449, 1800, 3667, 5595]\n","[495, 2705, 1910, 2497, 7721, 2311, 756, 1785]\n","[1840, 11422, 500, 457, 1974, 4603, 1248, 3254]\n","[6195, 9198, 1357, 10057, 4821, 10737, 1133, 2825]\n","[4390, 8734, 11803, 1372, 59, 3973, 3971, 1175]\n","[3004, 10979, 6603, 5556, 4207, 10750, 11175, 2194]\n","[1037, 7447, 6277, 8401, 5887, 2213, 10327, 5721]\n","[263, 2349, 3661, 2515, 2400, 10935, 7475, 2405]\n","[730, 10578, 10129, 5831, 2434, 10639, 9129, 358]\n","[10856, 3694, 8753, 592, 2675, 9068, 10126, 8378]\n","[5789, 10210, 8752, 4345, 422, 11931, 1010, 7099]\n","[4138, 7268, 5627, 11296, 1485, 10944, 8099, 7908]\n","[2212, 677, 10776, 10521, 2645, 6602, 10753, 11110]\n","[11347, 10321, 8231, 3123, 9776, 542, 1480, 8469]\n","[8560, 2046, 7218, 4762, 11441, 7326, 2259, 9786]\n","[10715, 1370, 4130, 5918, 9442, 8169, 8001, 8863]\n","[9512, 2668, 238, 9835, 4245, 7559, 4596, 3192]\n","[2699, 11248, 11186, 4434, 5792, 4527, 6904, 7481]\n","[4473, 9286, 7778, 855, 1146, 540, 6733, 11966]\n","[7107, 4419, 9840, 4185, 7023, 9441, 3525, 5194]\n","[2538, 572, 2933, 10716, 4729, 7916, 9050, 3344]\n","[1235, 10633, 8704, 2097, 6787, 3296, 5208, 11907]\n","[4590, 11372, 4772, 8242, 4318, 9890, 2466, 10819]\n","[2492, 9802, 615, 5098, 1962, 11792, 7049, 9443]\n","[811, 5777, 7954, 838, 10723, 4006, 3357, 3601]\n","[5587, 6167, 711, 469, 11890, 9807, 6125, 11751]\n","[8568, 10604, 8510, 1459, 9944, 5700, 6261, 4696]\n","[5451, 5193, 8219, 270, 262, 11884, 3430, 11246]\n","[9478, 2122, 9759, 2314, 4414, 10259, 266, 11615]\n","[6553, 4193, 1928, 2913, 7653, 6490, 11343, 1424]\n","[10244, 333, 7066, 6672, 9969, 9811, 5715, 977]\n","[9758, 10434, 11759, 5817, 10689, 7852, 6006, 9981]\n","[10229, 5547, 11726, 2778, 5612, 10727, 11136, 10635]\n","[11139, 9368, 153, 6022, 4366, 5438, 6447, 11688]\n","[9820, 3627, 9100, 2244, 792, 2924, 10607, 10710]\n","[10527, 3843, 7119, 7532, 9430, 11329, 9626, 2444]\n","[10090, 5782, 7261, 2490, 8476, 1621, 952, 3151]\n","[7942, 9277, 3129, 5852, 8668, 7090, 4531, 7663]\n","[6240, 9199, 2496, 3064, 11544, 6538, 8148, 11636]\n","[3859, 2618, 7014, 140, 10675, 4574, 11212, 3302]\n","[3521, 4956, 8509, 10124, 9959, 10642, 1622, 10455]\n","[5203, 339, 6231, 2809, 8349, 4760, 487, 7478]\n","[445, 311, 922, 1983, 6957, 6050, 3265, 3571]\n","[7905, 1027, 1205, 598, 11952, 5575, 6362, 4524]\n","[1418, 935, 5746, 10372, 8094, 2399, 10123, 11593]\n","[10524, 7237, 215, 5806, 10658, 1432, 7738, 9453]\n","[8021, 1939, 9025, 9148, 413, 11427, 3206, 1792]\n","[2017, 10461, 9849, 2200, 6119, 2914, 3464, 4714]\n","[9893, 8140, 6113, 7879, 1489, 5202, 7968, 7502]\n","[2729, 5135, 8659, 7342, 9760, 4295, 5386, 1569]\n","[3709, 9965, 11917, 1237, 9414, 8320, 4558, 7692]\n","[10851, 4944, 8193, 599, 6084, 9273, 9485, 78]\n","[8160, 6412, 2031, 2820, 9175, 9507, 8733, 8953]\n","[9179, 3476, 2984, 4738, 7282, 3314, 8526, 7667]\n","[10509, 3134, 7422, 6232, 9643, 5626, 10768, 11168]\n","[10762, 7392, 9152, 11872, 5750, 11436, 4848, 4831]\n","[3715, 4755, 7033, 3327, 10306, 4692, 4081, 2519]\n","[7210, 7296, 3545, 5325, 7694, 10787, 3297, 7793]\n","[4330, 9470, 860, 8640, 5457, 11648, 8683, 2687]\n","[720, 6554, 7293, 6826, 4106, 6919, 10431, 10299]\n","[5478, 6013, 1434, 10075, 4788, 3753, 6472, 10059]\n","[9865, 9385, 6579, 5380, 1056, 7709, 6419, 6987]\n","[4543, 10286, 3271, 9735, 1426, 6089, 10670, 9698]\n","[5014, 7018, 3175, 261, 2598, 6723, 1894, 11861]\n","[8396, 9961, 4651, 10999, 3273, 479, 1354, 10920]\n","[5926, 10115, 1565, 10600, 652, 285, 942, 1203]\n","[5500, 3768, 4410, 109, 6259, 4819, 5722, 9898]\n","[8754, 1330, 3386, 939, 1871, 4849, 957, 9996]\n","[4242, 6351, 7050, 7617, 10425, 5231, 9745, 1648]\n","[4904, 3242, 7556, 4585, 2428, 11972, 9324, 9662]\n","[2350, 8466, 9544, 4002, 10863, 2992, 8356, 10879]\n","[6831, 6870, 3156, 3517, 7200, 534, 662, 10034]\n","[9456, 5145, 3509, 4432, 9971, 467, 8243, 2905]\n","[9045, 11177, 3828, 5251, 6316, 9092, 9015, 948]\n","[10429, 9947, 397, 1836, 8000, 463, 4758, 9174]\n","[5285, 8503, 9311, 486, 3701, 11215, 3308, 6273]\n","[559, 3615, 3275, 11894, 751, 6323, 936, 10840]\n","[2603, 1976, 2842, 1291, 2423, 3435, 9182, 9658]\n","[10397, 11521, 10346, 2587, 8909, 3785, 10264, 5104]\n","[3120, 8707, 3021, 10196, 6258, 5454, 6391, 3438]\n","[837, 10373, 10517, 9666, 702, 7982, 1040, 3548]\n","[3917, 6848, 5119, 9596, 2802, 4247, 9438, 2221]\n","[6269, 2651, 8467, 9447, 1000, 11303, 6482, 4292]\n","[5028, 7310, 11848, 1907, 8120, 9151, 7167, 9054]\n","[4083, 508, 5321, 2161, 8822, 2253, 2558, 9765]\n","[622, 10714, 3949, 10294, 394, 3802, 8549, 11243]\n","[476, 6784, 4834, 5474, 6918, 389, 5836, 2708]\n","[5132, 7915, 9479, 8012, 11366, 2131, 11902, 2171]\n","[8479, 9578, 8407, 882, 4015, 11301, 2276, 11643]\n","[10116, 3403, 4214, 11128, 3304, 4540, 5053, 5059]\n","[8832, 281, 8716, 11430, 8358, 6118, 505, 8201]\n","[5508, 8116, 7141, 11852, 9189, 2095, 3260, 6757]\n","[8209, 11536, 4898, 482, 4196, 2629, 8680, 1161]\n","[9927, 8226, 4276, 9923, 1125, 4182, 5358, 8165]\n","[1787, 1436, 7672, 11199, 11588, 8308, 11452, 4057]\n","[11351, 7681, 2433, 3857, 854, 1971, 8352, 6851]\n","[11653, 9921, 10688, 1169, 10349, 2873, 6928, 10873]\n","[2456, 7917, 5812, 9679, 7063, 6662, 7891, 4966]\n","[7589, 1619, 9377, 3541, 2954, 726, 9983, 11334]\n","[2227, 8383, 10500, 4892, 5754, 7838, 8425, 4279]\n","[1420, 2948, 8403, 9178, 4258, 8622, 10757, 11134]\n","[11863, 1258, 5630, 6044, 1502, 11480, 2367, 11369]\n","[7734, 2407, 4726, 8868, 4672, 2952, 8857, 10766]\n","[8438, 9310, 10478, 6643, 3437, 7579, 3555, 3557]\n","[3390, 8993, 4579, 96, 5390, 11069, 9763, 1395]\n","[10392, 1717, 2958, 10378, 7803, 9728, 11261, 120]\n","[3346, 10795, 110, 11300, 8472, 4941, 1875, 1796]\n","[2441, 9934, 4887, 903, 5418, 1352, 9293, 5753]\n","[4477, 4344, 3638, 6658, 8408, 3443, 409, 6276]\n","[8029, 5879, 2510, 5317, 7697, 923, 4088, 2014]\n","[8606, 574, 3766, 3237, 11262, 5154, 11264, 3235]\n","[10180, 8376, 3966, 141, 2111, 9375, 6718, 11456]\n","[7565, 7305, 2724, 7185, 11235, 6043, 3136, 4508]\n","[1501, 9234, 11404, 2123, 2943, 3990, 11088, 5103]\n","[8287, 1409, 3767, 9687, 8004, 10001, 4759, 523]\n","[8293, 10931, 7052, 10632, 9454, 7407, 3277, 4495]\n","[2733, 1890, 9912, 11171, 4763, 4065, 4995, 9915]\n","[3564, 1083, 6650, 5319, 1758, 3408, 4724, 47]\n","[371, 7802, 4220, 7497, 5995, 9579, 3257, 7479]\n","[427, 2043, 7906, 11120, 8667, 5560, 1577, 4872]\n","[5415, 8487, 6262, 493, 795, 7101, 11492, 2222]\n","[9577, 4052, 1773, 194, 8179, 2044, 3826, 4447]\n","[5052, 9227, 447, 3725, 2340, 7410, 3173, 6895]\n","[3989, 2966, 4399, 8497, 11155, 4745, 1296, 6792]\n","[1689, 7383, 2265, 11284, 9858, 11079, 5713, 4964]\n","[1290, 4335, 3819, 3678, 11967, 4799, 6260, 1419]\n","[5377, 7911, 11775, 11637, 3547, 11513, 1108, 3750]\n","[5720, 1017, 7930, 596, 11702, 5765, 11312, 9356]\n","[1097, 2513, 4402, 9059, 6158, 11293, 5389, 10312]\n","[9475, 154, 5654, 668, 3941, 7518, 2507, 2157]\n","[11930, 5152, 10853, 7882, 1909, 10702, 5345, 10609]\n","[2671, 4455, 6328, 3756, 10106, 1462, 6120, 8615]\n","[1295, 9069, 821, 10946, 7175, 502, 9743, 2206]\n","[8200, 3886, 9526, 8123, 7927, 11582, 2495, 10875]\n","[4736, 10581, 10611, 9185, 10010, 3663, 3877, 7943]\n","[9203, 6683, 10076, 2024, 5896, 11453, 26, 1360]\n","[9711, 4559, 8528, 4674, 9576, 5928, 1416, 9585]\n","[4266, 1166, 11815, 4310, 11311, 11571, 4569, 8630]\n","[10109, 696, 2690, 5924, 9419, 7796, 1046, 2190]\n","[10618, 9772, 1568, 11866, 9343, 6533, 2572, 2468]\n","[5900, 8830, 4311, 5034, 4173, 7716, 6107, 220]\n","[2700, 8084, 3945, 6253, 3526, 2165, 9841, 8586]\n","[2268, 1885, 6264, 6266, 10267, 9561, 3578, 7434]\n","[1137, 5396, 3380, 2032, 7628, 1798, 3604, 8050]\n","[11502, 6664, 1576, 11897, 5564, 2300, 1941, 6307]\n","[2960, 3834, 442, 6844, 4593, 8558, 1544, 10360]\n","[9228, 77, 3144, 4509, 11360, 4024, 9664, 3452]\n","[11843, 9880, 5472, 6196, 7857, 2900, 7030, 7265]\n","[1956, 104, 3229, 5781, 7768, 6243, 1690, 250]\n","[9822, 4108, 1190, 9498, 10503, 632, 8594, 962]\n","[7884, 2574, 9524, 6034, 7909, 3576, 9510, 6535]\n","[428, 11194, 9295, 2856, 8327, 6045, 7365, 4792]\n","[5725, 8374, 11060, 5802, 3044, 9275, 7248, 8002]\n","[11133, 8597, 10009, 11224, 6117, 2395, 7595, 5338]\n","[1944, 4264, 1470, 452, 11806, 9107, 11249, 2498]\n","[1195, 5865, 1186, 6877, 6263, 3110, 8449, 10854]\n","[6855, 11129, 5769, 8044, 7329, 9328, 4407, 246]\n","[9222, 8578, 4361, 6947, 11305, 2406, 5622, 9647]\n","[11755, 8326, 2086, 6418, 4240, 11870, 2401, 2646]\n","[8814, 7324, 8818, 1183, 7528, 6590, 7542, 733]\n","[11073, 9499, 904, 9590, 1417, 2742, 5157, 5344]\n","[6441, 11729, 6438, 8559, 6041, 10808, 2416, 7183]\n","[11055, 9255, 9072, 62, 1837, 7499, 4880, 11385]\n","[5861, 8386, 6290, 5637, 3918, 4800, 2679, 10534]\n","[3892, 9632, 9389, 7247, 5061, 9271, 9305, 3019]\n","[19, 1423, 6349, 5744, 10266, 8346, 3220, 9614]\n","[4671, 1151, 300, 8517, 5302, 7406, 3245, 3238]\n","[7471, 11936, 4159, 325, 516, 6964, 85, 10413]\n","[10496, 3067, 1454, 9046, 2047, 4989, 933, 9181]\n","[6395, 3135, 380, 2911, 6065, 1002, 8836, 8130]\n","[9272, 6067, 950, 11054, 10203, 7118, 4709, 11747]\n","[8565, 1644, 7327, 6638, 11959, 2356, 8395, 2917]\n","[6891, 9118, 1789, 4450, 5635, 828, 5487, 90]\n","[2977, 9552, 6040, 8747, 3423, 2037, 5185, 439]\n","[1523, 2888, 10749, 1638, 8233, 6980, 10867, 4937]\n","[8686, 11102, 4983, 4124, 10442, 11971, 744, 11161]\n","[3027, 6235, 1706, 11716, 8181, 10992, 2983, 8577]\n","[7075, 9657, 356, 6099, 9352, 7840, 2568, 5832]\n","[5787, 5138, 9534, 6191, 5506, 3211, 1699, 6003]\n","[3065, 8685, 10844, 1866, 11569, 2584, 4818, 5858]\n","[11183, 779, 6108, 4529, 3352, 9003, 8794, 1583]\n","[7120, 8939, 1076, 7287, 796, 5501, 7105, 5904]\n","[6072, 9341, 1591, 169, 4021, 872, 4014, 9644]\n","[7648, 3093, 4761, 1142, 10947, 7843, 3100, 6504]\n","[7290, 4234, 9690, 7938, 931, 11406, 8919, 1497]\n","[3409, 10162, 6822, 9908, 3190, 8628, 925, 7629]\n","[11188, 7043, 2421, 9869, 4613, 4522, 1854, 8115]\n","[6976, 11256, 3974, 11145, 8865, 2908, 2279, 6539]\n","[6358, 1101, 2420, 84, 6291, 6913, 5252, 7717]\n","[8980, 10680, 10673, 2175, 5703, 9801, 7163, 8533]\n","[3422, 8843, 11649, 6968, 5120, 10987, 1727, 3358]\n","[9374, 996, 8941, 10003, 106, 83, 8182, 11391]\n","[4787, 8887, 9171, 10219, 97, 11995, 6647, 6565]\n","[1440, 782, 10541, 11021, 6409, 4308, 9353, 1603]\n","[443, 11965, 10257, 10303, 6122, 6614, 11816, 2639]\n","[9911, 10990, 7573, 10556, 2516, 1584, 7548, 171]\n","[5892, 7238, 2363, 11225, 9933, 11807, 790, 9460]\n","[7492, 11765, 10323, 11169, 8894, 1953, 1086, 3813]\n","[105, 1327, 7725, 5956, 8060, 292, 3729, 9523]\n","[2195, 8652, 7162, 11672, 4513, 10555, 10966, 2868]\n","[10206, 2653, 2736, 1811, 7021, 5366, 4321, 3737]\n","[3310, 2751, 7631, 4263, 3124, 10742, 6675, 4208]\n","[4235, 8955, 6671, 9726, 4201, 1747, 6960, 9684]\n","[2504, 312, 425, 2757, 6293, 4507, 1912, 4104]\n","[8761, 9396, 7869, 4274, 2615, 2691, 3131, 9564]\n","[3197, 4049, 4047, 7213, 5367, 8141, 10507, 302]\n","[11213, 1273, 7886, 7093, 8524, 11173, 15, 11025]\n","[5526, 5191, 10628, 10767, 180, 9696, 7748, 8138]\n","[10833, 2431, 4947, 1662, 1906, 6985, 8765, 883]\n","[9210, 5642, 1929, 6174, 9665, 10133, 5897, 6644]\n","[1469, 3104, 7842, 5584, 3612, 2631, 8539, 10825]\n","[6097, 11205, 7606, 10701, 7544, 8223, 2799, 11516]\n","[5932, 1430, 1520, 136, 7594, 5009, 755, 9663]\n","[8512, 6519, 971, 6092, 11842, 7758, 8337, 9335]\n","[4317, 11934, 498, 2716, 9021, 286, 11568, 6024]\n","[10007, 6874, 4401, 11629, 3179, 4882, 4706, 6245]\n","[9160, 2039, 7889, 3291, 835, 7836, 2940, 11437]\n","[4597, 7530, 9939, 9149, 5878, 8959, 5330, 3218]\n","[3954, 2209, 11847, 6494, 4877, 7527, 3361, 4525]\n","[2610, 2472, 9306, 9267, 7384, 2463, 5855, 4742]\n","[3499, 1164, 916, 7981, 11062, 2004, 10190, 2657]\n","[2890, 11509, 7596, 8048, 9208, 4811, 3402, 4224]\n","[2637, 5632, 5466, 9565, 6275, 7449, 3568, 10747]\n","[7616, 3868, 9345, 1508, 1303, 10759, 6485, 9155]\n","[11495, 8827, 10678, 1113, 11238, 4841, 11933, 11913]\n","[6134, 4145, 61, 10144, 6477, 10907, 1709, 3202]\n","[11955, 99, 3847, 2533, 10407, 7056, 684, 8807]\n","[2345, 7495, 5759, 7404, 3799, 91, 9436, 3475]\n","[1128, 6310, 2248, 8092, 7074, 11970, 391, 794]\n","[7679, 6343, 10399, 8290, 6741, 9935, 9094, 701]\n","[1177, 10161, 24, 7020, 3716, 7483, 7951, 8339]\n","[7110, 4858, 11072, 11475, 6346, 6091, 7811, 9631]\n","[10008, 6938, 5032, 2243, 8361, 987, 9514, 11031]\n","[10526, 10692, 9843, 1288, 8235, 699, 7719, 11484]\n","[1054, 8381, 10908, 2250, 4175, 10200, 7104, 8274]\n","[5797, 998, 5689, 1366, 10528, 4728, 2566, 7949]\n","[1512, 1058, 7897, 8870, 1421, 5261, 7639, 3319]\n","[10894, 2302, 1184, 7766, 6911, 3887, 5651, 10081]\n","[316, 1193, 3595, 11039, 3880, 3773, 2976, 9496]\n","[1400, 3730, 9028, 2698, 7121, 10525, 11976, 11100]\n","[4845, 11727, 11779, 11825, 10565, 5453, 9800, 7539]\n","[8131, 10828, 5529, 9411, 4859, 1474, 4140, 10948]\n","[4870, 11408, 5593, 1820, 1882, 8492, 5842, 3649]\n","[7792, 10113, 6722, 5452, 11721, 10036, 5998, 4715]\n","[5606, 323, 9006, 5716, 5012, 4346, 7307, 5431]\n","[6761, 976, 7320, 5646, 258, 3187, 2931, 2859]\n","[11370, 4515, 10619, 2957, 6081, 6106, 11957, 9985]\n","[1095, 6743, 321, 9654, 7094, 9832, 1052, 9075]\n","[8605, 1632, 3587, 1809, 4051, 1473, 5843, 3407]\n","[4262, 3088, 9276, 6637, 9340, 11565, 11400, 6460]\n","[1093, 11191, 567, 10088, 1155, 1973, 9661, 2178]\n","[1573, 9973, 4126, 4764, 1119, 1396, 8518, 2521]\n","[2207, 8878, 6213, 8924, 6998, 5470, 5306, 2527]\n","[10025, 3089, 3451, 11693, 4914, 7279, 556, 8994]\n","[1921, 9639, 4618, 3968, 9323, 2565, 2328, 1310]\n","[5200, 879, 7581, 3332, 4394, 8367, 1772, 1104]\n","[11787, 5069, 6131, 10903, 4974, 10777, 6161, 3846]\n","[11922, 3039, 3166, 1522, 3025, 6806, 10587, 123]\n","[2387, 4256, 10490, 8303, 1892, 1713, 3111, 471]\n","[11865, 5778, 6633, 6042, 4588, 4511, 3107, 6111]\n","[2443, 4472, 1484, 8609, 4100, 11320, 1102, 5590]\n","[5163, 9803, 9161, 6029, 4516, 4186, 9538, 4976]\n","[11449, 1557, 9266, 3063, 3204, 978, 1978, 5046]\n","[3943, 4727, 10761, 7822, 612, 11776, 7249, 3289]\n","[4111, 412, 7442, 10077, 2829, 3389, 4768, 7356]\n","[8812, 3513, 11896, 4326, 9428, 5704, 1532, 2995]\n","[3427, 4046, 6574, 11623, 7699, 1279, 11790, 10149]\n","[1683, 2281, 1253, 7980, 2800, 7733, 3198, 3852]\n","[7620, 11127, 694, 5043, 9611, 6353, 8420, 4661]\n","[4992, 1636, 8121, 6373, 10876, 10, 7504, 6133]\n","[2975, 11711, 937, 6010, 3668, 8687, 9239, 5733]\n","[8110, 1234, 5360, 10554, 366, 4922, 8626, 8856]\n","[1613, 9029, 9900, 5592, 7060, 396, 3803, 6899]\n","[10486, 11275, 2534, 8992, 1937, 10269, 3434, 10933]\n","[10051, 8948, 3461, 11247, 7671, 3671, 582, 4855]\n","[1201, 7777, 1560, 3528, 2578, 6367, 1886, 3301]\n","[698, 10886, 11599, 5276, 1716, 7958, 6829, 1030]\n","[7834, 1165, 2649, 3410, 5513, 8928, 11598, 2852]\n","[6763, 1984, 2752, 201, 9872, 4168, 10564, 1044]\n","[8317, 11996, 5581, 9126, 11326, 4430, 10816, 8877]\n","[10458, 7341, 681, 11682, 7586, 1226, 8499, 1674]\n","[7914, 10700, 8289, 8897, 11211, 10018, 3669, 6564]\n","[11405, 748, 6404, 11650, 11396, 1986, 3406, 9910]\n","[11981, 6225, 11181, 11625, 7220, 10770, 1483, 1895]\n","[11824, 6838, 6311, 8454, 870, 8702, 4269, 5948]\n","[6725, 2837, 9636, 2127, 5498, 5139, 664, 8490]\n","[6629, 10401, 6580, 6802, 5409, 2867, 4653, 3774]\n","[3447, 8076, 11841, 3985, 3085, 8455, 7351, 5724]\n","[1446, 5281, 1610, 9044, 1227, 6170, 8651, 11719]\n","[10189, 5303, 6611, 8881, 9309, 871, 3681, 6798]\n","[9215, 9580, 6251, 7885, 3814, 5520, 5001, 3349]\n","[1182, 9096, 11530, 9874, 9677, 8202, 6700, 10293]\n","[5308, 2518, 5758, 9768, 4624, 3955, 1687, 8354]\n","[214, 8834, 10000, 259, 9530, 1003, 9599, 8780]\n","[9425, 2176, 4828, 7155, 4731, 7577, 6842, 11918]\n","[9942, 644, 9754, 3383, 5761, 5049, 10169, 11932]\n","[2773, 3046, 8168, 576, 3925, 5607, 344, 10997]\n","[2883, 237, 9313, 3126, 1069, 549, 5288, 9090]\n","[11734, 1476, 5884, 9522, 3580, 7948, 4704, 2973]\n","[267, 9926, 7041, 353, 7250, 4451, 4271, 7979]\n","[8268, 2725, 5742, 8432, 3026, 10179, 10122, 11737]\n","[6896, 7881, 7853, 3749, 11619, 2274, 5375, 9002]\n","[10540, 6218, 10084, 3586, 6344, 9078, 2704, 10860]\n","[10663, 6369, 4636, 2860, 4897, 11190, 11, 10786]\n","[6083, 8039, 4625, 11009, 4305, 1504, 10934, 8722]\n","[1697, 269, 3566, 2393, 4028, 6062, 10184, 4622]\n","[9808, 9381, 2875, 3789, 506, 11545, 3378, 7202]\n","[7863, 3721, 5532, 4642, 1673, 11756, 4058, 11282]\n","[1722, 9462, 8500, 115, 11514, 9694, 2545, 2069]\n","[5289, 1191, 11043, 5434, 355, 2100, 6922, 3791]\n","[8803, 8611, 4928, 6901, 4949, 6837, 9723, 10174]\n","[3979, 8773, 5204, 11086, 5537, 639, 7763, 10570]\n","[5364, 863, 8717, 2402, 4610, 7807, 2640, 4200]\n","[4868, 799, 7413, 5299, 3752, 11028, 1661, 9713]\n","[5441, 11694, 6527, 7131, 2148, 1377, 5636, 5751]\n","[10443, 2388, 3611, 5694, 8529, 8132, 1634, 459]\n","[2866, 9412, 697, 9888, 7314, 8537, 6982, 1547]\n","[1972, 95, 8057, 5060, 3722, 5970, 5448, 9731]\n","[5354, 410, 3695, 1922, 5555, 3639, 9767, 9583]\n","[3345, 7516, 6591, 10451, 3897, 11646, 9667, 1006]\n","[6886, 6774, 10974, 7608, 2033, 1666, 10365, 155]\n","[10207, 1349, 9195, 5197, 6135, 5340, 6924, 4734]\n","[7576, 2273, 6294, 926, 809, 9308, 10073, 4615]\n","[5808, 10807, 4847, 6640, 1914, 5686, 1049, 1305]\n","[1448, 11537, 1919, 2611, 9954, 10781, 1790, 3727]\n","[4020, 10422, 7555, 10917, 2216, 8766, 10504, 3417]\n","[11180, 4865, 2988, 6932, 11519, 5578, 6355, 4620]\n","[11794, 5130, 398, 274, 6865, 7898, 11744, 10313]\n","[4566, 4400, 745, 8108, 3532, 2549, 1405, 8522]\n","[3182, 5510, 5647, 2597, 11667, 11397, 3117, 7198]\n","[11116, 6869, 11745, 7937, 709, 2076, 4272, 11761]\n","[1948, 8405, 1617, 5774, 6948, 1793, 10910, 5403]\n","[919, 1211, 449, 2878, 2501, 10712, 7839, 6182]\n","[9850, 10050, 10336, 2030, 8854, 3360, 10596, 11023]\n","[8445, 7625, 462, 3323, 11820, 11742, 10640, 1394]\n","[6188, 889, 3660, 1160, 10282, 920, 2052, 10681]\n","[7169, 2792, 7065, 8398, 11090, 2310, 1145, 11769]\n","[6534, 8041, 10110, 8276, 7243, 9026, 10015, 11135]\n","[1088, 8368, 7080, 2018, 4154, 11916, 4125, 2450]\n","[7344, 6070, 1664, 7678, 2119, 7866, 8938, 7443]\n","[2166, 7362, 11741, 4975, 4428, 4291, 8713, 1580]\n","[2471, 9699, 93, 5011, 9370, 7820, 4814, 331]\n","[5749, 10824, 6605, 9344, 8089, 10918, 11655, 8689]\n","[8224, 680, 1481, 7301, 11797, 2815, 7779, 9531]\n","[8607, 10657, 6211, 5649, 9952, 529, 11341, 6338]\n","[11677, 4287, 5503, 4312, 9581, 2364, 8232, 4194]\n","[8028, 8635, 5173, 6849, 11012, 7485, 9303, 9449]\n","[519, 7850, 6143, 8245, 6101, 2509, 4180, 11531]\n","[9128, 1598, 9057, 3832, 7455, 408, 3726, 3932]\n","[2718, 4452, 1761, 6858, 11631, 4521, 3540, 4347]\n","[3684, 9226, 3664, 2836, 3101, 867, 2827, 2505]\n","[8977, 6735, 2249, 10128, 6372, 1812, 3653, 11279]\n","[2938, 4115, 6036, 11327, 3500, 6773, 1575, 1039]\n","[2412, 4054, 11468, 6214, 3053, 7416, 4699, 4396]\n","[1856, 6861, 2479, 5423, 6023, 7088, 5430, 1753]\n","[9573, 7619, 8428, 1452, 7760, 1180, 7983, 7032]\n","[5628, 6890, 2348, 1855, 7335, 7997, 4395, 2427]\n","[5579, 2034, 1081, 10535, 3279, 2455, 7789, 9355]\n","[1680, 6320, 7899, 7722, 1926, 9065, 9011, 6305]\n","[7206, 5671, 5730, 6302, 1286, 953, 6430, 8008]\n","[8899, 10603, 2882, 4285, 11141, 2630, 3387, 4537]\n","[11314, 6314, 1429, 2811, 1694, 10381, 4984, 8989]\n","[842, 10228, 9623, 10231, 11166, 5156, 276, 7529]\n","[7466, 3313, 9016, 6563, 3556, 9770, 2232, 10872]\n","[7665, 6526, 9753, 2112, 5090, 7510, 4415, 324]\n","[6401, 8437, 2949, 624, 11002, 11184, 9091, 7489]\n","[9748, 8424, 6166, 3759, 6336, 4461, 9781, 2486]\n","[3239, 4754, 124, 7086, 5870, 5580, 10967, 4273]\n","[9553, 11273, 1337, 11178, 10861, 3606, 10198, 4445]\n","[5582, 9427, 4446, 2459, 6781, 1398, 3827, 6884]\n","[6878, 5379, 7630, 1685, 4025, 3734, 10459, 1779]\n","[2476, 2926, 5643, 10479, 1297, 5657, 8748, 3099]\n","[6423, 5598, 6168, 2613, 301, 1752, 7708, 2662]\n","[9024, 3931, 8252, 2548, 798, 5337, 7490, 5574]\n","[5613, 1324, 7638, 5937, 3171, 7688, 7775, 1299]\n","[1931, 10246, 7588, 3797, 2371, 3710, 3577, 1379]\n","[5596, 11627, 9455, 7062, 9764, 7654, 1099, 1806]\n","[1141, 3371, 4259, 2297, 5244, 4007, 9953, 2318]\n","[9533, 8107, 1823, 10374, 3176, 7273, 5908, 11666]\n","[5107, 6340, 4923, 10344, 5237, 10061, 6332, 8284]\n","[7668, 6935, 293, 9190, 5158, 252, 4920, 7710]\n","[4583, 2150, 3337, 3069, 8307, 2376, 4151, 7276]\n","[6425, 2680, 5551, 9257, 543, 8821, 5799, 5955]\n","[8663, 2950, 6940, 4282, 9521, 7370, 8426, 7411]\n","[5853, 6038, 2162, 6021, 597, 1411, 8412, 1213]\n","[7024, 5331, 2136, 11626, 488, 1995, 2011, 6622]\n","[10779, 1742, 1830, 1536, 392, 2343, 7438, 10414]\n","[10288, 11920, 5958, 1257, 4322, 3137, 4973, 10183]\n","[1067, 10356, 4776, 6229, 5980, 8867, 8649, 3189]\n","[1782, 1321, 3893, 10622, 4265, 7975, 9376, 5973]\n","[1255, 3395, 1539, 9062, 4202, 6696, 4791, 6920]\n","[3908, 5211, 8664, 11707, 2726, 2101, 570, 10292]\n","[3672, 9994, 357, 10969, 9393, 5162, 9725, 6799]\n","[6820, 9433, 1825, 1952, 49, 718, 5518, 10250]\n","[6228, 11032, 7215, 6801, 1795, 1570, 4723, 2907]\n","[865, 4810, 11409, 552, 10086, 3473, 6330, 5525]\n","[2056, 10187, 9219, 6207, 885, 5538, 6031, 8674]\n","[9782, 4377, 1901, 1913, 9416, 4457, 10296, 9729]\n","[6592, 2333, 2670, 5522, 11197, 944, 2798, 6136]\n","[10255, 11131, 11386, 3234, 9216, 8218, 51, 7872]\n","[5037, 3142, 5693, 287, 6907, 7318, 10154, 10280]\n","[8583, 2818, 4598, 5270, 4721, 9704, 179, 7849]\n","[11542, 4879, 8078, 844, 11036, 10055, 7031, 3366]\n","[5398, 465, 6063, 1537, 8858, 10838, 8619, 6435]\n","[337, 4468, 1292, 5372, 273, 5324, 607, 11138]\n","[5885, 846, 10738, 11527, 40, 11523, 10806, 663]\n","[2979, 5965, 2767, 11690, 5484, 4465, 11534, 1960]\n","[2735, 7827, 9976, 910, 11546, 5723, 46, 5393]\n","[1891, 1884, 9863, 9360, 11349, 10771, 3903, 10837]\n","[2855, 8322, 10758, 7257, 5735, 6390, 9127, 3967]\n","[4433, 10957, 1393, 6426, 9290, 9591, 8319, 11954]\n","[10697, 3936, 965, 8949, 9509, 2626, 5464, 1533]\n","[4563, 6583, 5131, 8525, 5269, 11020, 116, 6017]\n","[6760, 1663, 7969, 10096, 4575, 1176, 9495, 114]\n","[4429, 9987, 6966, 2483, 7423, 7051, 5458, 10221]\n","[2489, 11035, 3779, 1413, 4391, 2355, 3487, 1999]\n","[1524, 2982, 2573, 4741, 2588, 11813, 8908, 3775]\n","[3960, 3082, 2036, 3591, 5205, 10939, 4031, 3286]\n","[8542, 4895, 9886, 9437, 2275, 7477, 438, 8987]\n","[4341, 7129, 204, 8976, 6525, 4233, 10593, 1528]\n","[5357, 2118, 11891, 7225, 7568, 4774, 6747, 9542]\n","[2678, 5027, 4003, 393, 11802, 7260, 3876, 8263]\n","[4820, 732, 10216, 10029, 4493, 9727, 1529, 5975]\n","[1247, 11257, 10270, 4659, 9211, 705, 6717, 759]\n","[6846, 2897, 2822, 7055, 7281, 8837, 6461, 1670]\n","[7106, 10594, 2184, 10823, 5894, 966, 3155, 3927]\n","[4996, 461, 649, 2601, 2672, 685, 9448, 8027]\n","[5620, 7462, 9484, 6945, 9248, 2655, 5990, 7609]\n","[5118, 8902, 1410, 6312, 8910, 11017, 7706, 10079]\n","[11348, 3250, 9261, 2706, 9622, 484, 1545, 4171]\n","[3585, 1488, 11174, 8835, 2141, 8034, 3523, 4771]\n","[5411, 6641, 7809, 766, 2179, 10444, 7640, 11398]\n","[2570, 10958, 11614, 1, 10249, 7308, 1791, 3520]\n","[1860, 8471, 3982, 7488, 3953, 10343, 5488, 5875]\n","[5862, 9508, 7720, 6424, 10775, 11999, 4650, 260]\n","[11515, 11555, 7350, 1771, 4645, 10684, 3743, 2163]\n","[3478, 7013, 984, 724, 3821, 10796, 8493, 8851]\n","[2771, 4222, 832, 4398, 4504, 9035, 11503, 8314]\n","[11533, 908, 7116, 4548, 5844, 2313, 10532, 3961]\n","[11242, 642, 10533, 3481, 5567, 4420, 2467, 4332]\n","[6596, 2477, 10380, 1698, 4520, 13, 2717, 1720]\n","[1647, 8171, 6716, 2271, 750, 11124, 11576, 9681]\n","[89, 9708, 9630, 1427, 8811, 6364, 11407, 7790]\n","[9856, 4177, 9119, 909, 9847, 464, 8030, 11799]\n","[7137, 10012, 10788, 5669, 10396, 8404, 4676, 3855]\n","[1077, 5818, 3522, 5954, 9527, 27, 5427, 9202]\n","[6625, 6443, 11710, 6203, 1656, 1628, 2337, 2087]\n","[4301, 2480, 1079, 4490, 2739, 5670, 6711, 8365]\n","[9031, 2239, 2098, 11821, 9559, 10510, 4933, 2159]\n","[9721, 7127, 5124, 9196, 4942, 7347, 6532, 5602]\n","[11988, 577, 7154, 6192, 9792, 2382, 3728, 11269]\n","[1810, 3253, 8269, 10354, 2652, 3833, 7830, 9333]\n","[8718, 2372, 1139, 2564, 11330, 590, 9476, 1031]\n","[6992, 4918, 3121, 6198, 7989, 4073, 9426, 4555]\n","[1679, 4474, 6944, 9039, 7071, 5788, 9051, 7026]\n","[11007, 8122, 6684, 5115, 6184, 5717, 2242, 3163]\n","[1373, 5492, 2389, 4667, 5089, 7070, 6183, 719]\n","[10412, 11302, 6495, 8848, 5220, 8389, 5674, 3530]\n","[7683, 8198, 243, 2806, 4246, 1335, 6770, 2078]\n","[8532, 11318, 10393, 2357, 3741, 5054, 1608, 3674]\n","[10799, 4668, 1013, 6578, 6522, 2230, 5067, 3497]\n","[11853, 232, 8623, 6589, 7244, 3707, 9612, 11098]\n","[3910, 4654, 8462, 10487, 2980, 3511, 1065, 11029]\n","[1467, 216, 11170, 7592, 10921, 1173, 6187, 8483]\n","[9949, 1859, 10630, 6999, 3654, 5871, 7208, 7571]\n","[362, 1550, 5511, 11087, 10562, 8097, 8387, 11051]\n","[4226, 1511, 111, 11758, 1639, 11001, 568, 4148]\n","[4026, 8062, 8956, 3720, 202, 3662, 9383, 5005]\n","[3815, 1242, 5678, 787, 126, 5624, 706, 10130]\n","[5767, 6868, 9752, 6448, 2473, 10634, 1259, 4552]\n","[8620, 8080, 5359, 8157, 10153, 2789, 10571, 3429]\n","[5238, 2794, 11669, 341, 4097, 1441, 2021, 3219]\n","[10810, 5953, 1132, 3618, 11612, 11557, 8152, 8261]\n","[11316, 2974, 4320, 1614, 7970, 8817, 1447, 1657]\n","[3704, 3264, 6090, 10298, 10953, 5712, 11704, 10877]\n","[8258, 5934, 1461, 5665, 10740, 4550, 6096, 7883]\n","[9450, 11038, 4045, 5828, 9380, 5155, 7174, 6163]\n","[2293, 2446, 9371, 5996, 2840, 4656, 3168, 2617]\n","[6780, 7612, 5146, 4162, 5383, 9159, 3030, 10394]\n","[1249, 1437, 3946, 10370, 11008, 3460, 10191, 1265]\n","[3282, 3959, 8907, 4528, 4682, 6979, 9816, 4421]\n","[8778, 9336, 2748, 9022, 11578, 1061, 6015, 5623]\n","[9815, 11263, 2746, 9844, 10243, 3659, 8712, 9854]\n","[2493, 6925, 5082, 9145, 5999, 3597, 7179, 1221]\n","[8958, 7005, 7673, 6751, 3983, 8647, 7111, 11438]\n","[11639, 5659, 7212, 10552, 3689, 3379, 2577, 4938]\n","[5168, 4071, 3462, 11875, 3326, 9780, 10909, 10469]\n","[9571, 6510, 2487, 3240, 9771, 9928, 8582, 7890]\n","[9697, 5422, 4988, 10718, 4239, 8693, 4131, 129]\n","[4251, 9423, 6854, 927, 8375, 6970, 1834, 8016]\n","[4284, 7194, 190, 2544, 1631, 3905, 9486, 212]\n","[5576, 5228, 8665, 7216, 4443, 8598, 658, 2283]\n","[5676, 7713, 11638, 2612, 11339, 2028, 995, 700]\n","[10448, 2258, 1616, 3692, 1412, 11696, 5402, 7298]\n","[210, 626, 3161, 9434, 648, 8813, 10467, 9506]\n","[6061, 6462, 9146, 5848, 2755, 5968, 7845, 3270]\n","[1482, 5000, 2360, 2088, 8133, 10472, 5382, 4413]\n","[9247, 10733, 11053, 9882, 5986, 10289, 10764, 4971]\n","[2627, 8736, 7044, 9354, 7514, 5026, 1509, 6753]\n","[868, 4304, 372, 8952, 11218, 9762, 4544, 3455]\n","[1992, 10964, 9635, 11740, 7427, 9074, 4752, 9646]\n","[9468, 7414, 851, 2540, 3531, 188, 602, 2023]\n","[10158, 384, 11964, 6767, 6678, 2204, 1316, 3565]\n","[6329, 1167, 9680, 8918, 1016, 322, 2919, 7912]\n","[11464, 6450, 11322, 10899, 10682, 7913, 4336, 10924]\n","[1472, 48, 8238, 9570, 3412, 8056, 6039, 3295]\n","[9281, 752, 9852, 8043, 9620, 6969, 11883, 7944]\n","[8831, 7742, 1465, 1401, 3333, 2600, 5342, 1239]\n","[7600, 2460, 7940, 9055, 1555, 3315, 3322, 1566]\n","[10955, 8839, 103, 550, 3739, 4417, 6502, 10996]\n","[3042, 11030, 8040, 8681, 7058, 770, 6105, 2738]\n","[8508, 279, 6902, 6252, 2068, 6511, 672, 10576]\n","[3035, 3036, 7469, 4626, 4409, 11149, 5250, 9986]\n","[10676, 5591, 56, 5328, 938, 2850, 8684, 7259]\n","[7396, 8042, 11335, 7157, 9023, 3697, 2410, 6109]\n","[9956, 7765, 9701, 1759, 10202, 2062, 10927, 8095]\n","[11388, 399, 9556, 7601, 5682, 10403, 11906, 924]\n","[6505, 11445, 4664, 208, 9992, 6916, 6246, 7429]\n","[5557, 8208, 5387, 7939, 6939, 11429, 5017, 10233]\n","[5531, 1188, 3183, 1958, 8215, 822, 11323, 6514]\n","[2237, 2928, 7773, 6758, 8719, 3698, 10379, 7798]\n","[7359, 1457, 954, 8999, 11227, 728, 6954, 746]\n","[426, 8183, 2422, 7535, 4936, 6018, 7907, 9493]\n","[4340, 6468, 11770, 2316, 9188, 3031, 6764, 4120]\n","[10949, 1471, 5087, 5641, 5813, 5169, 7375, 11810]\n","[7524, 6978, 4924, 5144, 7417, 6057, 2116, 2788]\n","[7816, 7460, 9392, 3718, 3889, 10014, 11570, 5316]\n","[2457, 9125, 7864, 5192, 9624, 4786, 10091, 4078]\n","[8571, 5460, 1109, 2074, 9625, 2168, 11499, 10499]\n","[197, 3670, 4211, 9464, 5044, 1525, 3248, 11123]\n","[3375, 8872, 11065, 5640, 1367, 8636, 6397, 3459]\n","[3029, 11084, 3503, 3622, 1618, 5178, 8045, 9114]\n","[11223, 3882, 7522, 6025, 5565, 1675, 1127, 2099]\n","[3394, 10441, 7264, 38, 8969, 10132, 6934, 774]\n","[6610, 3700, 1375, 7509, 4991, 5823, 1597, 9121]\n","[2858, 11974, 4917, 3230, 9826, 11504, 3923, 3311]\n","[2009, 3471, 6953, 11179, 9716, 1917, 8144, 9446]\n","[1911, 4327, 4343, 1293, 959, 11201, 3227, 2133]\n","[2202, 7560, 5773, 5437, 6215, 5217, 6950, 11746]\n","[2503, 1339, 3801, 1543, 8787, 3274, 7860, 9318]\n","[1369, 10041, 3999, 6055, 2381, 6008, 478, 7368]\n","[11259, 10439, 5544, 5420, 2269, 8726, 4381, 9997]\n","[6530, 8177, 5909, 1024, 8700, 7453, 2130, 1091]\n","[8023, 3978, 4217, 222, 10937, 3281, 6087, 8246]\n","[1433, 1059, 1245, 8516, 10101, 403, 4789, 178]\n","[10460, 2776, 4076, 7791, 1185, 5365, 2366, 144]\n","[9225, 3561, 10024, 8109, 10011, 2772, 213, 2594]\n","[8871, 1589, 11081, 3853, 1371, 11804, 6272, 9384]\n","[4934, 10516, 11973, 654, 5385, 1085, 9300, 6095]\n","[6663, 4576, 8329, 11926, 5315, 10897, 8973, 277]\n","[11450, 6587, 7966, 11724, 4686, 8388, 10780, 10052]\n","[6669, 5876, 1355, 4878, 8758, 3444, 8930, 5915]\n","[9488, 5078, 7957, 6301, 3849, 7610, 8434, 10245]\n","[1996, 8920, 39, 5467, 8723, 2625, 4712, 2592]\n","[6201, 9330, 4475, 1864, 2955, 9249, 10834, 518]\n","[7122, 6469, 7135, 10452, 11586, 11299, 10477, 10711]\n","[6331, 88, 6576, 11258, 5943, 5983, 3902, 580]\n","[10021, 3934, 6680, 8102, 10887, 2542, 7437, 10283]\n","[8071, 7637, 1283, 2854, 4418, 9978, 11718, 1140]\n","[1294, 3024, 3066, 3861, 4907, 3809, 1760, 7561]\n","[11338, 2556, 4505, 10230, 5807, 6811, 2683, 11376]\n","[345, 8134, 8125, 10366, 8926, 9936, 2826, 8744]\n","[915, 1005, 5719, 7730, 5176, 9719, 3373, 2531]\n","[6222, 6857, 9221, 4460, 4889, 11540, 10744, 4328]\n","[6413, 10998, 3972, 2551, 9083, 769, 234, 7817]\n","[4640, 5509, 1300, 8324, 1918, 5801, 2676, 6738]\n","[2849, 7859, 3603, 9176, 107, 2223, 5906, 1381]\n","[5395, 8047, 9124, 8781, 1267, 11415, 5227, 11762]\n","[4306, 4587, 10417, 2445, 2593, 9608, 7677, 1526]\n","[880, 10159, 10030, 2137, 9136, 1343, 2779, 736]\n","[3748, 11325, 10942, 6836, 9459, 3637, 221, 11990]\n","[5662, 7727, 7113, 10608, 7188, 1702, 477, 1861]\n","[4373, 3732, 10421, 11560, 8013, 1311, 5811, 3306]\n","[4219, 6368, 10005, 8937, 5692, 537, 7660, 1503]\n","[9613, 1749, 8333, 7632, 9319, 5741, 11947, 11195]\n","[866, 6856, 9746, 11209, 70, 3388, 6698, 11113]\n","[2096, 5959, 10743, 10053, 9995, 5039, 6790, 2196]\n","[9350, 6531, 490, 4303, 3881, 1692, 3901, 951]\n","[9477, 3047, 9736, 446, 34, 10706, 10430, 979]\n","[3848, 3268, 4369, 8475, 4215, 10862, 967, 7224]\n","[6737, 2411, 991, 2715, 3055, 5666, 317, 11383]\n","[1342, 5445, 5819, 7073, 9825, 6271, 9474, 9331]\n","[9250, 638, 530, 3558, 10199, 2832, 3691, 8373]\n","[3060, 2296, 6731, 10213, 4997, 6454, 6126, 3150]\n","[3278, 7782, 1204, 7590, 9962, 5512, 3329, 800]\n","[6414, 10792, 4119, 3835, 4837, 793, 3838, 3620]\n","[5554, 8159, 4387, 7996, 9603, 11498, 7682, 9532]\n","[4809, 4044, 5136, 4911, 4635, 2583, 2869, 11793]\n","[11040, 8543, 9779, 54, 4779, 1665, 3515, 1887]\n","[6562, 11373, 4090, 6112, 1252, 10456, 4945, 20]\n","[5293, 4884, 11549, 1490, 8729, 4533, 520, 9795]\n","[9747, 10177, 1645, 7053, 1602, 2741, 8739, 1693]\n","[2266, 4775, 1277, 10411, 335, 8979, 3112, 7029]\n","[11494, 11418, 206, 11474, 7878, 1225, 205, 1586]\n","[9876, 9270, 6324, 7440, 10031, 3842, 4411, 8864]\n","[10956, 6300, 6171, 1147, 4798, 7240, 1564, 8286]\n","[9574, 646, 6601, 3514, 8844, 10046, 9081, 2817]\n","[1362, 9197, 5347, 473, 3904, 2803, 9212, 8035]\n","[10857, 10054, 5938, 2839, 788, 10530, 8932, 4683]\n","[1322, 2512, 130, 6180, 2257, 74, 1548, 7126]\n","[11455, 738, 1365, 3746, 7189, 6398, 374, 6427]\n","[8203, 10027, 3740, 1900, 11929, 1129, 2481, 4244]\n","[7602, 3950, 10492, 3772, 11945, 9289, 686, 8957]\n","[3516, 9889, 5161, 1600, 3256, 1904, 3782, 2845]\n","[42, 3159, 11010, 887, 4087, 10471, 554, 4080]\n","[11092, 6459, 11457, 6233, 8205, 4437, 8227, 8112]\n","[11858, 6812, 3758, 633, 11642, 1066, 8841, 58]\n","[11250, 10984, 8572, 4506, 9540, 5964, 2408, 5798]\n","[3831, 7533, 6715, 4000, 9958, 3342, 166, 8313]\n","[2291, 11244, 9017, 7598, 10095, 8312, 2862, 11940]\n","[3070, 4368, 9106, 6155, 1803, 893, 9312, 8786]\n","[4871, 9292, 6223, 10083, 7151, 9481, 5105, 3492]\n","[10291, 1831, 10508, 6707, 5521, 5727, 2224, 2644]\n","[1055, 10355, 3074, 1022, 6955, 10285, 6086, 10869]\n","[11876, 2120, 10802, 1514, 8616, 10188, 5728, 10016]\n","[5572, 4948, 6375, 6348, 6093, 10647, 9873, 9879]\n","[11130, 6513, 7133, 1178, 3948, 11541, 9810, 1897]\n","[3818, 3073, 2424, 1105, 1356, 405, 10722, 1001]\n","[9634, 3195, 9115, 636, 1541, 2272, 11801, 5266]\n","[3745, 8777, 666, 10494, 10383, 2003, 9398, 4783]\n","[11117, 9325, 7039, 8988, 1808, 9279, 5601, 7436]\n","[11538, 4403, 5378, 5922, 877, 6014, 257, 2245]\n","[11676, 8913, 9706, 7973, 4478, 7371, 2816, 11019]\n","[2353, 8291, 1014, 10060, 10729, 4903, 3874, 881]\n","[3795, 9929, 5370, 3293, 5841, 11000, 2745, 8942]\n","[8397, 8845, 10419, 10922, 11508, 8267, 6648, 1168]\n","[9730, 1850, 7222, 5785, 3616, 6048, 8981, 256]\n","[3431, 5536, 10247, 1684, 5514, 2981, 8602, 11307]\n","[8940, 1271, 3733, 3666, 6795, 7002, 1754, 1358]\n","[10056, 3348, 3570, 6268, 8796, 2308, 6, 6147]\n","[2902, 3222, 10782, 7800, 336, 11321, 4436, 4270]\n","[10140, 11840, 8967, 7795, 4801, 1414, 7496, 3825]\n","[2722, 11823, 3321, 7142, 6692, 4448, 7203, 4019]\n","[7211, 11731, 6389, 4223, 9461, 6915, 921, 11403]\n","[7191, 5278, 6872, 6840, 3788, 8550, 9373, 1955]\n","[10376, 5109, 9993, 11288, 848, 11715, 3643, 9609]\n","[10445, 9836, 2620, 1492, 803, 11122, 4690, 1654]\n","[2624, 11728, 2775, 8111, 1272, 3251, 5810, 7474]\n","[135, 436, 9063, 7376, 10375, 6400, 10610, 3458]\n","[5184, 3915, 7999, 9881, 10643, 2379, 8769, 418]\n","[11221, 8273, 2963, 1442, 1317, 8126, 9007, 3862]\n","[268, 676, 11732, 1826, 573, 6281, 956, 4412]\n","[6172, 10182, 1445, 8823, 6052, 1415, 7482, 5097]\n","[11018, 9150, 4698, 8228, 9896, 1308, 6284, 4638]\n","[1250, 5258, 11862, 7147, 6074, 6515, 3209, 10545]\n","[3550, 9304, 1450, 10307, 4275, 10804, 1744, 9243]\n","[112, 9134, 3105, 6308, 10826, 3783, 76, 7452]\n","[5770, 7012, 6657, 10972, 1743, 4011, 11096, 6834]\n","[5440, 10812, 2135, 3912, 8277, 4568, 7684, 10121]\n","[8506, 1688, 10843, 10168, 7503, 522, 5780, 122]\n","[10395, 2325, 11419, 713, 11881, 9236, 5707, 11207]\n","[288, 7228, 7549, 3330, 2298, 7921, 9931, 7168]\n","[5732, 4255, 5035, 8448, 9399, 2628, 9014, 4970]\n","[717, 3398, 2692, 4648, 11752, 9180, 10653, 8731]\n","[4209, 6321, 9640, 6493, 10905, 5264, 6154, 2721]\n","[10406, 9975, 934, 3798, 2365, 2474, 11714, 7623]\n","[10044, 3609, 6471, 4702, 6815, 3267, 3922, 9669]\n","[2546, 2658, 5323, 10369, 5080, 9783, 6309, 11830]\n","[9582, 11265, 11633, 5226, 6653, 3590, 8297, 2737]\n","[5688, 11097, 9097, 11781, 4101, 10232, 1519, 6771]\n","[2295, 7170, 309, 9206, 5482, 8495, 10686, 4342]\n","[10515, 7614, 1326, 8271, 6570, 4323, 5972, 11689]\n","[11899, 739, 9256, 11354, 1045, 11592, 7448, 9187]\n","[876, 5917, 10705, 6394, 1298, 421, 3442, 7321]\n","[9401, 7650, 7246, 2160, 7177, 9218, 10751, 5697]\n","[9901, 10615, 3839, 6279, 6800, 7776, 1658, 8701]\n","[5309, 10725, 3008, 2339, 1881, 8478, 7348, 2853]\n","[10049, 740, 8316, 7732, 2201, 11115, 7691, 304]\n","[2198, 1714, 3180, 4885, 1075, 11771, 5890, 11594]\n","[2969, 11270, 7332, 10208, 10669, 7007, 3682, 5142]\n","[4393, 6487, 7599, 604, 5468, 7467, 11993, 6150]\n","[5656, 5446, 6824, 1741, 11114, 30, 6755, 8241]\n","[296, 4136, 1578, 8876, 8806, 9260, 11336, 7286]\n","[492, 340, 9322, 4812, 8654, 9695, 5083, 3223]\n","[9594, 2920, 9653, 10685, 9409, 5433, 2848, 4951]\n","[8824, 8645, 8020, 4454, 4072, 2774, 10265, 2436]\n","[3191, 2225, 7978, 4925, 6181, 11111, 4542, 6994]\n","[11298, 1028, 2714, 2819, 8429, 168, 10337, 975]\n","[2077, 1745, 7267, 1350, 1507, 8170, 1064, 7299]\n","[1817, 5783, 7867, 10652, 2685, 2170, 3397, 11838]\n","[4833, 9142, 8127, 11868, 1703, 1071, 1456, 254]\n","[1950, 2967, 1876, 10601, 7570, 3713, 3898, 10350]\n","[5494, 11874, 4592, 8175, 9676, 4777, 4929, 4979]\n","[558, 7166, 2591, 11552, 2419, 9347, 4670, 2437]\n","[3028, 9707, 1707, 11900, 2909, 2451, 3354, 6705]\n","[10167, 9652, 10698, 4946, 11089, 347, 7125, 6906]\n","[545, 151, 2694, 4094, 11245, 8007, 3224, 6853]\n","[10377, 3, 7781, 1847, 9568, 5805, 6064, 7655]\n","[7753, 3778, 7714, 8022, 7680, 2719, 4813, 3572]\n","[5830, 7826, 11346, 3891, 10485, 3381, 7805, 310]\n","[5407, 6265, 6386, 7176, 6434, 7603, 9629, 2641]\n","[707, 6432, 621, 7498, 7794, 11285, 2132, 10273]\n","[5148, 4757, 9052, 9877, 444, 1382, 11443, 8764]\n","[4806, 10067, 6728, 7967, 10410, 7150, 7428, 10474]\n","[6445, 4744, 5127, 10287, 11524, 315, 3686, 1333]\n","[9528, 526, 2872, 73, 8055, 4203, 8064, 4567]\n","[9868, 1019, 6473, 8334, 1018, 454, 11387, 7985]\n","[4231, 6816, 605, 4627, 11584, 1376, 8819, 5491]\n","[10650, 762, 4385, 3708, 1730, 6234, 6103, 9348]\n","[11033, 3207, 9089, 9117, 2865, 9361, 11791, 10074]\n","[8545, 9268, 8574, 9845, 2041, 946, 7262, 11448]\n","[8895, 8439, 9806, 2425, 9082, 5042, 10616, 1607]\n","[2520, 9034, 1841, 218, 11886, 5920, 8750, 1209]\n","[2727, 4444, 10968, 10523, 6809, 6691, 7323, 11597]\n","[253, 10165, 3086, 9285, 6996, 595, 11286, 6599]\n","[11080, 9013, 8595, 8355, 8604, 6162, 5880, 5413]\n","[10147, 2636, 5614, 4953, 3506, 3965, 11271, 375]\n","[5369, 10118, 8815, 10238, 10314, 298, 8153, 3885]\n","[7651, 11193, 2595, 1968, 2247, 1988, 1903, 9917]\n","[10166, 1899, 11528, 6517, 4298, 4118, 1865, 175]\n","[10885, 320, 9700, 4221, 7109, 8096, 11196, 8101]\n","[9217, 4314, 1389, 28, 2197, 4802, 4822, 7828]\n","[10880, 737, 32, 3335, 6742, 4793, 11535, 9831]\n","[4807, 9547, 8720, 1050, 11306, 3625, 11748, 7144]\n","[4959, 2054, 2334, 1111, 6889, 6710, 11416, 9513]\n","[10420, 6975, 4456, 2846, 11845, 4339, 9539, 4591]\n","[431, 5463, 6282, 7737, 2915, 6104, 6342, 2576]\n","[7380, 3143, 164, 6387, 11800, 2764, 7027, 6121]\n","[7236, 9804, 1062, 291, 11789, 10382, 5866, 3840]\n","[11743, 6208, 6810, 9560, 10185, 8671, 9592, 8710]\n","[747, 10612, 8210, 5310, 5275, 4147, 9397, 2361]\n","[1302, 4546, 9036, 11844, 5172, 9471, 4649, 710]\n","[1513, 6219, 7269, 9004, 1340, 2807, 1126, 11994]\n","[8058, 6540, 10679, 468, 9154, 6905, 6528, 3059]\n","[7546, 6768, 8792, 7484, 4181, 367, 2080, 3841]\n","[8026, 7334, 10308, 7754, 8703, 2351, 8430, 7701]\n","[8544, 10389, 1149, 11739, 4866, 5117, 9970, 9703]\n","[5428, 3466, 5833, 11304, 6205, 11228, 6852, 7343]\n","[912, 1266, 3102, 6908, 4471, 4896, 11681, 8732]\n","[6621, 2394, 8477, 5502, 5919, 4536, 8563, 6347]\n","[3477, 1858, 9349, 3130, 11078, 6463, 4594, 8453]\n","[7199, 6242, 3341, 6132, 239, 4501, 2442, 7633]\n","[6239, 3456, 7435, 10550, 3426, 5108, 5768, 6752]\n","[7357, 5064, 10211, 10040, 3058, 6726, 11447, 11777]\n","[10985, 2254, 9307, 9597, 6609, 11479, 6839, 11975]\n","[5933, 2673, 3071, 9675, 4204, 11882, 11310, 5984]\n","[4557, 692, 3486, 4526, 4657, 4379, 6632, 11083]\n","[7165, 7545, 1406, 5196, 8370, 1029, 7444, 8139]\n","[9670, 5960, 11811, 11708, 2000, 11481, 11683, 8612]\n","[6075, 11483, 2904, 3546, 6189, 4572, 4756, 5573]\n","[6796, 4486, 8341, 1757, 4972, 6900, 7887, 8014]\n","[9420, 10790, 7858, 2978, 861, 3359, 10561, 8114]\n","[8829, 8641, 360, 6027, 3050, 6035, 3038, 3076]\n","[10839, 2864, 864, 5941, 6512, 1152, 7278, 8093]\n","[528, 3469, 5962, 2398, 7832, 2129, 4708, 10827]\n","[3436, 3596, 3208, 1951, 11730, 9153, 11402, 3317]\n","[5902, 2320, 2352, 2663, 11377, 4170, 3777, 4519]\n","[8399, 5639, 10302, 2231, 2226, 8990, 8195, 7705]\n","[11251, 3226, 2502, 4739, 2780, 11805, 326, 6416]\n","[8882, 9302, 5137, 9497, 10253, 5489, 2797, 10353]\n","[9887, 3765, 9563, 6378, 3090, 9761, 1769, 3247]\n","[11617, 7769, 10522, 5597, 4480, 10803, 2309, 163]\n","[9131, 9101, 2482, 6185, 1824, 223, 7010, 11960]\n","[4497, 10026, 772, 11526, 9766, 10058, 5429, 9720]\n","[753, 2464, 5102, 5619, 671, 9686, 2585, 6058]\n","[7219, 6509, 11067, 1505, 9359, 14, 9338, 7604]\n","[2677, 588, 535, 6551, 11935, 6754, 2599, 7613]\n","[7, 6376, 11984, 1626, 6883, 6929, 8826, 235]\n","[9605, 2322, 2173, 5899, 2896, 9621, 10631, 8805]\n","[181, 3178, 11154, 892, 2991, 7507, 7515, 9769]\n","[10037, 6606, 4189, 947, 6354, 11878, 539, 3711]\n","[9466, 7690, 1284, 2553, 6408, 2346, 1883, 1606]\n","[6007, 10746, 6933, 11709, 8220, 8336, 2440, 7015]\n","[7585, 5183, 5737, 6082, 7331, 351, 5432, 10672]\n","[2238, 2089, 973, 2536, 2972, 10538, 2117, 11856]\n","[9067, 6365, 1733, 10204, 6797, 6241, 4056, 4844]\n","[10045, 8890, 11121, 6476, 11425, 3118, 9864, 5229]\n","[4439, 1163, 10102, 2607, 8204, 5110, 8740, 4780]\n","[11048, 11101, 8968, 9502, 10193, 1977, 2796, 1966]\n","[4158, 7626, 10171, 8553, 8248, 6341, 9061, 6762]\n","[6956, 2377, 2109, 7275, 3824, 10709, 1315, 5668]\n","[4906, 4888, 2529, 10391, 4300, 9008, 7902, 1510]\n","[10988, 11903, 4034, 8485, 4487, 9649, 5585, 11992]\n","[674, 1074, 8982, 9788, 10481, 9030, 9162, 9860]\n","[1304, 1012, 3589, 8260, 8278, 9817, 3083, 11600]\n","[9833, 11214, 1844, 3494, 3287, 7234, 7493, 6542]\n","[7735, 1708, 3992, 6881, 5856, 1615, 1275, 3491]\n","[1827, 6567, 370, 5653, 5515, 4163, 10043, 4376]\n","[10329, 9403, 1449, 4722, 11577, 2362, 2167, 6745]\n","[4701, 6451, 6782, 5545, 6584, 4600, 23, 11591]\n","[6864, 3879, 11834, 10817, 4114, 1943, 985, 6377]\n","[11399, 4915, 7284, 1672, 5748, 55, 37, 8757]\n","[3554, 11392, 4032, 10137, 9777, 1278, 1821, 8470]\n","[4128, 8234, 7046, 9229, 3964, 9166, 6624, 7358]\n","[2791, 6481, 8521, 7117, 8415, 3041, 1624, 11112]\n","[7114, 6555, 11332, 7337, 11467, 3844, 8912, 6825]\n","[10707, 9842, 9546, 7649, 651, 2770, 895, 6778]\n","[1087, 2932, 4523, 3510, 7986, 11061, 3480, 10763]\n","[3854, 1851, 7952, 10882, 11070, 10783, 8362, 2292]\n","[11272, 859, 1170, 1611, 2616, 9885, 2338, 4886]\n","[10648, 2261, 1117, 9365, 990, 9515, 9902, 6433]\n","[9489, 6888, 10082, 6521, 8727, 6598, 4874, 3152]\n","[8923, 10125, 5100, 10097, 4356, 1642, 5559, 8038]\n","[5262, 2025, 538, 5425, 4663, 7861, 5661, 5945]\n","[11045, 8296, 8119, 2918, 6069, 761, 5113, 3244]\n","[4254, 7057, 3467, 9388, 3495, 9805, 5901, 8422]\n","[10950, 10071, 1341, 5216, 3448, 1368, 11692, 7226]\n","[10654, 4129, 2604, 4384, 858, 11411, 5903, 3125]\n","[9283, 10240, 4584, 3731, 11363, 9980, 3095, 6230]\n","[7987, 3339, 627, 7201, 10929, 11104, 53, 8124]\n","[3584, 2073, 11176, 9262, 653, 5079, 352, 725]\n","[1681, 11431, 6366, 8480, 2217, 11198, 8151, 3217]\n","[816, 7108, 7272, 138, 5181, 1546, 11785, 8886]\n","[786, 4498, 9633, 10127, 5282, 6581, 2246, 6991]\n","[8614, 5343, 9056, 9458, 9943, 5140, 1231, 3149]\n","[11572, 8441, 1965, 8237, 4476, 3147, 11034, 4352]\n","[9830, 3413, 9472, 4785, 11950, 1383, 1712, 6984]\n","[3942, 9240, 6786, 6396, 5373, 4174, 7254, 687]\n","[11983, 11822, 8782, 3633, 5259, 2889, 2537, 3929]\n","[7235, 11274, 448, 6961, 11126, 2579, 1026, 4191]\n","[10572, 3419, 7156, 9113, 2684, 3043, 7740, 6674]\n","[6593, 4188, 4042, 802, 5045, 3415, 894, 11849]\n","[1084, 1131, 8456, 785, 10319, 11686, 8309, 6327]\n","[8724, 217, 3421, 1314, 7445, 3762, 8106, 10218]\n","[3453, 7317, 10699, 11610, 6694, 8929, 3836, 6805]\n","[7933, 7580, 808, 9857, 3690, 4, 1620, 11219]\n","[4751, 496, 4883, 11767, 10501, 3015, 185, 10120]\n","[11295, 4573, 11836, 6863, 7931, 10842, 2786, 630]\n","[2081, 850, 8178, 4658, 8625, 11292, 9139, 4010]\n","[2747, 2985, 1274, 9651, 918, 11057, 9627, 836]\n","[7955, 4662, 3483, 8966, 731, 8450, 10260, 2923]\n","[3907, 6832, 6821, 3602, 11446, 10099, 5523, 3040]\n","[3567, 290, 11835, 8435, 5679, 5147, 6937, 2263]\n","[7204, 611, 10745, 8617, 8070, 583, 8046, 9516]\n","[4257, 10595, 406, 8603, 6677, 7901, 2763, 9334]\n","[5966, 3259, 6212, 3097, 7277, 227, 6585, 3013]\n","[10254, 5072, 4580, 8745, 5533, 69, 7355, 8875]\n","[11697, 161, 10491, 7091, 2901, 5384, 3621, 6421]\n","[8692, 1338, 10447, 8783, 682, 71, 6930, 7919]\n","[11252, 11958, 7675, 4324, 10848, 9231, 992, 2723]\n","[10815, 2113, 7186, 6867, 6628, 10518, 4077, 3935]\n","[6335, 11236, 7799, 415, 8852, 2730, 1138, 7173]\n","[514, 5241, 4085, 3212, 1331, 9140, 11839, 8791]\n","[578, 6410, 8610, 11125, 2373, 9233, 5561, 11887]\n","[8802, 10769, 0, 1034, 8325, 8666, 7757, 8406]\n","[3165, 9839, 7458, 3012, 8025, 3997, 7004, 11426]\n","[9678, 9938, 7132, 9235, 6654, 68, 8194, 11345]\n","[10529, 7001, 3921, 723, 2567, 10192, 3605, 6497]\n","[4089, 4195, 9492, 8653, 2669, 2347, 4685, 10155]\n","[2709, 8015, 4359, 1094, 10364, 10345, 3106, 10466]\n","[3651, 4280, 5092, 6990, 875, 7519, 6736, 8259]\n","[11832, 9194, 11818, 1888, 9541, 4766, 7089, 294]\n","[6439, 1764, 2067, 2609, 2654, 1923, 9733, 10148]\n","[1392, 6190, 4079, 1388, 4212, 9505, 9920, 9406]\n","[7042, 6357, 430, 5982, 4489, 5295, 245, 9220]\n","[4666, 8150, 1269, 6882, 8427, 2661, 5535, 3924]\n","[7543, 7712, 10209, 5483, 10278, 8345, 8196, 3588]\n","[8675, 369, 643, 3787, 4374, 3157, 7744, 11163]\n","[3445, 7054, 5837, 9482, 9440, 10384, 4213, 6897]\n","[1496, 5416, 6130, 8853, 6744, 5033, 7322, 4990]\n","[3951, 7367, 1359, 900, 10977, 10605, 8103, 11077]\n","[8535, 8737, 11226, 10385, 2187, 7339, 5235, 4978]\n","[5189, 5882, 10904, 6828, 10563, 6577, 11939, 9671]\n","[8066, 6333, 5444, 6156, 10531, 8632, 5056, 4669]\n","[4725, 5776, 6566, 11566, 7431, 7229, 9598, 2155]\n","[2633, 3185, 2682, 2697, 6529, 119, 6428, 2142]\n","[1073, 1025, 806, 6556, 10543, 6137, 5327, 3939]\n","[3890, 11229, 11505, 10475, 4693, 1495, 8548, 10785]\n","[896, 11294, 897, 2784, 3139, 2580, 10224, 11151]\n","[2871, 7378, 1969, 11665, 2415, 1605, 6746, 4894]\n","[1110, 7082, 1218, 7833, 11998, 7364, 3738, 9569]\n","[7567, 6500, 9186, 3913, 7739, 1924, 1737, 3900]\n","[2485, 248, 63, 10638, 7271, 9557, 2079, 9773]\n","[6788, 2689, 6618, 1770, 1781, 617, 9326, 9000]\n","[584, 4502, 1361, 3699, 6009, 10172, 1224, 3356]\n","[11382, 9315, 8885, 8052, 4227, 131, 226, 9402]\n","[7924, 5569, 9702, 8600, 8411, 8943, 7160, 3193]\n","[10272, 8784, 8601, 4629, 11158, 9369, 5257, 3856]\n","[8431, 11977, 6429, 5850, 5029, 8810, 608, 10145]\n","[7873, 906, 5820, 7574, 6702, 10813, 10613, 10497]\n","[7965, 673, 7818, 5164, 11496, 9741, 7394, 5167]\n","[6066, 11255, 8657, 3647, 11937, 390, 6464, 6237]\n","[3272, 2821, 7245, 9098, 4689, 5519, 6748, 6313]\n","[4333, 5615, 9284, 8741, 5449, 1332, 10778, 3830]\n","[10476, 5007, 764, 981, 8338, 2921, 9400, 6470]\n","[3976, 7928, 1241, 10589, 4018, 11367, 3920, 7140]\n","[9491, 5381, 7774, 9394, 3010, 6297, 10146, 11461]\n","[6772, 6965, 9907, 2152, 7558, 620, 6595, 3712]\n","[11253, 7894, 8174, 4730, 7076, 5690, 2922, 5436]\n","[982, 11657, 689, 5687, 9884, 1212, 7217, 6288]\n","[1098, 8077, 4143, 3944, 11695, 9253, 6676, 1270]\n","[6688, 4732, 1402, 8833, 1985, 9600, 1219, 3196]\n","[1518, 4817, 230, 9332, 5355, 6236, 11573, 6193]\n","[1207, 2930, 1916, 9575, 4237, 3054, 2332, 1936]\n","[5242, 10248, 420, 1768, 5019, 4153, 6666, 8676]\n","[3539, 2768, 2208, 3760, 7871, 10728, 8593, 1667]\n","[3048, 8104, 9079, 9607, 5111, 5952, 9511, 1736]\n","[8371, 8946, 8662, 4351, 6380, 11850, 9110, 3794]\n","[7624, 2525, 613, 9299, 8749, 10952, 7292, 823]\n","[2091, 6216, 10388, 7756, 1444, 7566, 5947, 10390]\n","[440, 361, 1515, 2781, 3350, 5313, 9645, 1729]\n","[7755, 132, 5985, 8053, 4029, 6739, 8154, 2042]\n","[3642, 898, 2010, 7491, 11609, 4869, 1346, 7724]\n","[10919, 10136, 11674, 2812, 9144, 2927, 4110, 3072]\n","[7870, 8166, 6769, 10335, 6479, 3382, 8804, 6139]\n","[6719, 2808, 7289, 10098, 3399, 4862, 4824, 7846]\n","[2012, 640, 2317, 1172, 7171, 8557, 5290, 10409]\n","[3103, 4713, 9989, 8954, 510, 4109, 5655, 9722]\n","[1590, 9714, 1833, 999, 7095, 8197, 11942, 6110]\n","[3428, 7669, 3583, 8751, 2834, 5940, 1563, 2182]\n","[6808, 4854, 4485, 8256, 8696, 825, 10829, 11968]\n","[8173, 4190, 7397, 10502, 5236, 10754, 9883, 9870]\n","[9871, 3232, 9838, 8222, 7072, 7300, 3022, 5221]\n","[4039, 387, 911, 10598, 4532, 10938, 5239, 1553]\n","[11189, 10891, 4422, 2590, 9213, 2114, 5334, 1041]\n","[771, 6714, 10326, 11140, 2945, 2329, 4331, 6002]\n","[2881, 177, 167, 5356, 1710, 5450, 8059, 5368]\n","[3538, 869, 3231, 4050, 1852, 4952, 5911, 4360]\n","[5549, 7152, 3116, 456, 11027, 3688, 3007, 6165]\n","[6164, 6000, 5088, 4491, 10878, 11558, 1695, 7302]\n","[675, 7647, 4960, 200, 6652, 11276, 455, 2847]\n","[8024, 65, 5280, 5149, 6046, 5018, 3617, 2621]\n","[3761, 5711, 1889, 647, 6952, 4013, 11458, 2475]\n","[4107, 305, 8825, 8369, 9787, 4008, 874, 11222]\n","[4187, 4710, 314, 3994, 1652, 2289, 6200, 10328]\n","[2288, 9296, 2181, 11412, 11487, 11064, 10334, 79]\n","[9278, 5916, 7294, 4767, 4288, 3006, 8950, 5822]\n","[2660, 176, 7770, 381, 11401, 9382, 1008, 7387]\n","[6474, 3003, 10225, 10959, 4912, 2391, 847, 3300]\n","[137, 11433, 8596, 7508, 6278, 313, 9593, 5930]\n","[11489, 2144, 9555, 7520, 7280, 1637, 3933, 1323]\n","[198, 1486, 5696, 6703, 11556, 6363, 899, 4500]\n","[1263, 2782, 1572, 913, 3770, 8067, 6524, 3463]\n","[5851, 6843, 7338, 87, 3535, 8670, 7761, 10424]\n","[593, 3628, 244, 501, 3937, 5008, 10440, 5121]\n","[0, 1, 2, 3, 4, 5, 6, 7]\n","[8, 9, 10, 11, 12, 13, 14, 15]\n","[16, 17, 18, 19, 20, 21, 22, 23]\n","[24, 25, 26, 27, 28, 29, 30, 31]\n","[32, 33, 34, 35, 36, 37, 38, 39]\n","[40, 41, 42, 43, 44, 45, 46, 47]\n","[48, 49, 50, 51, 52, 53, 54, 55]\n","[56, 57, 58, 59, 60, 61, 62, 63]\n","[64, 65, 66, 67, 68, 69, 70, 71]\n","[72, 73, 74, 75, 76, 77, 78, 79]\n","[80, 81, 82, 83, 84, 85, 86, 87]\n","[88, 89, 90, 91, 92, 93, 94, 95]\n","[96, 97, 98, 99, 100, 101, 102, 103]\n","[104, 105, 106, 107, 108, 109, 110, 111]\n","[112, 113, 114, 115, 116, 117, 118, 119]\n","[120, 121, 122, 123, 124, 125, 126, 127]\n","[128, 129, 130, 131, 132, 133, 134, 135]\n","[136, 137, 138, 139, 140, 141, 142, 143]\n","[144, 145, 146, 147, 148, 149, 150, 151]\n","[152, 153, 154, 155, 156, 157, 158, 159]\n","[160, 161, 162, 163, 164, 165, 166, 167]\n","[168, 169, 170, 171, 172, 173, 174, 175]\n","[176, 177, 178, 179, 180, 181, 182, 183]\n","[184, 185, 186, 187, 188, 189, 190, 191]\n","[192, 193, 194, 195, 196, 197, 198, 199]\n","[200, 201, 202, 203, 204, 205, 206, 207]\n","[208, 209, 210, 211, 212, 213, 214, 215]\n","[216, 217, 218, 219, 220, 221, 222, 223]\n","[224, 225, 226, 227, 228, 229, 230, 231]\n","[232, 233, 234, 235, 236, 237, 238, 239]\n","[240, 241, 242, 243, 244, 245, 246, 247]\n","[248, 249, 250, 251, 252, 253, 254, 255]\n","[256, 257, 258, 259, 260, 261, 262, 263]\n","[264, 265, 266, 267, 268, 269, 270, 271]\n","[272, 273, 274, 275, 276, 277, 278, 279]\n","[280, 281, 282, 283, 284, 285, 286, 287]\n","[288, 289, 290, 291, 292, 293, 294, 295]\n","[296, 297, 298, 299, 300, 301, 302, 303]\n","[304, 305, 306, 307, 308, 309, 310, 311]\n","[312, 313, 314, 315, 316, 317, 318, 319]\n","[320, 321, 322, 323, 324, 325, 326, 327]\n","[328, 329, 330, 331, 332, 333, 334, 335]\n","[336, 337, 338, 339, 340, 341, 342, 343]\n","[344, 345, 346, 347, 348, 349, 350, 351]\n","[352, 353, 354, 355, 356, 357, 358, 359]\n","[360, 361, 362, 363, 364, 365, 366, 367]\n","[368, 369, 370, 371, 372, 373, 374, 375]\n","[376, 377, 378, 379, 380, 381, 382, 383]\n","[384, 385, 386, 387, 388, 389, 390, 391]\n","[392, 393, 394, 395, 396, 397, 398, 399]\n","[400, 401, 402, 403, 404, 405, 406, 407]\n","[408, 409, 410, 411, 412, 413, 414, 415]\n","[416, 417, 418, 419, 420, 421, 422, 423]\n","[424, 425, 426, 427, 428, 429, 430, 431]\n","[432, 433, 434, 435, 436, 437, 438, 439]\n","[440, 441, 442, 443, 444, 445, 446, 447]\n","[448, 449, 450, 451, 452, 453, 454, 455]\n","[456, 457, 458, 459, 460, 461, 462, 463]\n","[464, 465, 466, 467, 468, 469, 470, 471]\n","[472, 473, 474, 475, 476, 477, 478, 479]\n","[480, 481, 482, 483, 484, 485, 486, 487]\n","[488, 489, 490, 491, 492, 493, 494, 495]\n","[496, 497, 498, 499, 500, 501, 502, 503]\n","[504, 505, 506, 507, 508, 509, 510, 511]\n","[512, 513, 514, 515, 516, 517, 518, 519]\n","[520, 521, 522, 523, 524, 525, 526, 527]\n","[528, 529, 530, 531, 532, 533, 534, 535]\n","[536, 537, 538, 539, 540, 541, 542, 543]\n","[544, 545, 546, 547, 548, 549, 550, 551]\n","[552, 553, 554, 555, 556, 557, 558, 559]\n","[560, 561, 562, 563, 564, 565, 566, 567]\n","[568, 569, 570, 571, 572, 573, 574, 575]\n","[576, 577, 578, 579, 580, 581, 582, 583]\n","[584, 585, 586, 587, 588, 589, 590, 591]\n","[592, 593, 594, 595, 596, 597, 598, 599]\n","[600, 601, 602, 603, 604, 605, 606, 607]\n","[608, 609, 610, 611, 612, 613, 614, 615]\n","[616, 617, 618, 619, 620, 621, 622, 623]\n","[624, 625, 626, 627, 628, 629, 630, 631]\n","[632, 633, 634, 635, 636, 637, 638, 639]\n","[640, 641, 642, 643, 644, 645, 646, 647]\n","[648, 649, 650, 651, 652, 653, 654, 655]\n","[656, 657, 658, 659, 660, 661, 662, 663]\n","[664, 665, 666, 667, 668, 669, 670, 671]\n","[672, 673, 674, 675, 676, 677, 678, 679]\n","[680, 681, 682, 683, 684, 685, 686, 687]\n","[688, 689, 690, 691, 692, 693, 694, 695]\n","[696, 697, 698, 699, 700, 701, 702, 703]\n","[704, 705, 706, 707, 708, 709, 710, 711]\n","[712, 713, 714, 715, 716, 717, 718, 719]\n","[720, 721, 722, 723, 724, 725, 726, 727]\n","[728, 729, 730, 731, 732, 733, 734, 735]\n","[736, 737, 738, 739, 740, 741, 742, 743]\n","[744, 745, 746, 747, 748, 749, 750, 751]\n","[752, 753, 754, 755, 756, 757, 758, 759]\n","[760, 761, 762, 763, 764, 765, 766, 767]\n","[768, 769, 770, 771, 772, 773, 774, 775]\n","[776, 777, 778, 779, 780, 781, 782, 783]\n","[784, 785, 786, 787, 788, 789, 790, 791]\n","[792, 793, 794, 795, 796, 797, 798, 799]\n","[800, 801, 802, 803, 804, 805, 806, 807]\n","[808, 809, 810, 811, 812, 813, 814, 815]\n","[816, 817, 818, 819, 820, 821, 822, 823]\n","[824, 825, 826, 827, 828, 829, 830, 831]\n","[832, 833, 834, 835, 836, 837, 838, 839]\n","[840, 841, 842, 843, 844, 845, 846, 847]\n","[848, 849, 850, 851, 852, 853, 854, 855]\n","[856, 857, 858, 859, 860, 861, 862, 863]\n","[864, 865, 866, 867, 868, 869, 870, 871]\n","[872, 873, 874, 875, 876, 877, 878, 879]\n","[880, 881, 882, 883, 884, 885, 886, 887]\n","[888, 889, 890, 891, 892, 893, 894, 895]\n","[896, 897, 898, 899, 900, 901, 902, 903]\n","[904, 905, 906, 907, 908, 909, 910, 911]\n","[912, 913, 914, 915, 916, 917, 918, 919]\n","[920, 921, 922, 923, 924, 925, 926, 927]\n","[928, 929, 930, 931, 932, 933, 934, 935]\n","[936, 937, 938, 939, 940, 941, 942, 943]\n","[944, 945, 946, 947, 948, 949, 950, 951]\n","[952, 953, 954, 955, 956, 957, 958, 959]\n","[960, 961, 962, 963]\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 3.5974\n","Epoch 1 train accuracy: 0.1821\n","Epoch 1 dev loss: 2.7488\n","Epoch 1 dev accuracy: 0.3719\n","[10659, 10234, 5964, 9675, 787, 2797, 8476, 9132]\n","[11412, 7593, 3776, 255, 9746, 683, 9914, 3048]\n","[494, 5628, 399, 7835, 8182, 2352, 11538, 9626]\n","[5338, 9781, 6500, 3571, 10076, 10726, 8341, 569]\n","[10644, 6572, 413, 1128, 9950, 10200, 219, 5668]\n","[7073, 1542, 8153, 10604, 7115, 11731, 307, 8744]\n","[11771, 8996, 4098, 3015, 3893, 1927, 3164, 639]\n","[11570, 10417, 4387, 3986, 1131, 2916, 4078, 10919]\n","[6459, 2699, 11388, 303, 11375, 991, 5479, 11663]\n","[10518, 735, 5434, 7720, 4987, 197, 4124, 8760]\n","[1695, 4996, 6955, 11817, 3092, 1878, 2305, 3741]\n","[8598, 6787, 7502, 10992, 8198, 6517, 11211, 5870]\n","[8381, 3121, 1088, 9000, 1770, 11069, 1215, 11008]\n","[5380, 5057, 6781, 6971, 1366, 4180, 1149, 3678]\n","[9138, 11603, 4452, 6056, 1261, 5985, 10599, 6544]\n","[6280, 5997, 11432, 1396, 8523, 2650, 7974, 10794]\n","[8967, 3517, 6508, 9805, 6678, 8348, 5053, 7186]\n","[5932, 9976, 7671, 4169, 7104, 9904, 4131, 11995]\n","[11187, 8884, 8869, 3724, 7228, 9196, 9757, 6744]\n","[6269, 2667, 11186, 5983, 9168, 2105, 9722, 11065]\n","[8282, 250, 4228, 10754, 2292, 5899, 7557, 5478]\n","[5746, 1962, 9611, 8318, 8425, 10523, 5995, 2719]\n","[3721, 7285, 2309, 2143, 709, 5855, 10884, 10291]\n","[11926, 1555, 1997, 8738, 3798, 4454, 1514, 1613]\n","[10836, 3882, 1586, 889, 5956, 1867, 8325, 4480]\n","[10150, 11105, 10268, 8921, 2030, 8101, 2021, 9421]\n","[2946, 3923, 2468, 7002, 3183, 1259, 2232, 4154]\n","[3536, 8761, 9817, 8915, 7535, 662, 2542, 7466]\n","[10637, 8462, 2736, 3438, 2362, 3565, 7451, 1280]\n","[5496, 5359, 266, 9389, 2623, 655, 11950, 874]\n","[10288, 4792, 2480, 1531, 4836, 11039, 2206, 798]\n","[3267, 353, 4799, 10695, 11214, 3361, 7359, 433]\n","[9338, 2794, 817, 6290, 7819, 9736, 416, 11831]\n","[1101, 7527, 6515, 10995, 5312, 1590, 10693, 582]\n","[3673, 6974, 2128, 3277, 960, 4, 8092, 11108]\n","[6799, 5955, 5715, 2785, 7307, 3221, 3920, 46]\n","[1606, 128, 5612, 11479, 7912, 1558, 1072, 7042]\n","[6161, 10537, 11234, 4376, 1375, 2056, 7599, 9219]\n","[3668, 11109, 10939, 4737, 2878, 8969, 8053, 616]\n","[6229, 10217, 3928, 6557, 11346, 11843, 9311, 4198]\n","[9266, 6835, 4159, 4879, 2200, 8984, 10791, 11237]\n","[5311, 1676, 6530, 4902, 2003, 4833, 7872, 6887]\n","[285, 2547, 7049, 4052, 2573, 9112, 2472, 11585]\n","[10137, 4338, 6506, 5949, 9411, 537, 11118, 8014]\n","[10423, 9702, 6907, 6645, 6532, 5488, 6585, 5375]\n","[11945, 809, 10857, 7594, 8234, 7646, 3229, 9755]\n","[9999, 2929, 3448, 10960, 4963, 10954, 3226, 11049]\n","[263, 11550, 8290, 8326, 4997, 7375, 4355, 5988]\n","[7452, 2812, 2654, 6326, 2326, 11953, 789, 9516]\n","[7239, 6203, 2351, 7426, 637, 1490, 5808, 7666]\n","[738, 9321, 7585, 3111, 1252, 795, 1885, 6943]\n","[2646, 808, 11397, 4334, 2215, 6298, 7978, 4134]\n","[8339, 1309, 9286, 883, 8051, 11875, 5930, 10581]\n","[8111, 10681, 7529, 7438, 3772, 4330, 5863, 9387]\n","[2121, 135, 5047, 2308, 6049, 4527, 2633, 5067]\n","[8716, 10248, 1781, 754, 630, 10875, 805, 10740]\n","[6391, 10526, 9973, 8704, 8299, 8667, 737, 5472]\n","[4399, 6953, 10470, 8994, 8700, 3753, 1196, 4005]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-ac7af5c6a030>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtv_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-50-af122d0aeb47>\u001b[0m in \u001b[0;36mtv_run\u001b[0;34m(epochs, model, lr, alpha, max_accuracy, path, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# call training and validation functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-43-8b0ba3d92481>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_train_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-4da0f0d9bbe3>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, inds)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# return the required inds (The inds are the sampes and the active flag dictates relatively if that sample should be counted)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0msampled_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_neighborhood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# get the input for the required inds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-82a59c1dade3>\u001b[0m in \u001b[0;36msample_neighborhood\u001b[0;34m(primary_inds, input, adj, distance, neighbor_max)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlevel_1_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlevel_1_neighbors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mlevel_2_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_closest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_1_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mlevel_2_activation_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlevel_2_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0msampled_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_2_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-82a59c1dade3>\u001b[0m in \u001b[0;36m_get_closest_neighbors\u001b[0;34m(ind)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mcandidate_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mcandidate_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprimary_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0msorted_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneighbor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_neighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mneighbor_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#### $\\color{red}{Run:}$"],"metadata":{"id":"ZBHJn5V8mIDu"}},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs =\n","max_accuracy = 0\n","path = \"class/models/GNN.4.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -4\n","lr_high = -3\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -3\n","alpha_range = alpha_high - alpha_low\n","\n","d = 768\n","h = 400\n","c = 70\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(3):\n","  # debug\n","  print(\"\\n################\\n\")\n","  print(f'round: {i}')\n","  # print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  # print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print('max', max_accuracy)\n","  print(\"\\n################\\n\")\n","\n","\n","  for j in range(4):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha = gen_config(lr_low, lr_high, alpha_low, alpha_high)\n","    # define model\n","    model = GNNModel(d, h, c)\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range)\n","  lr_low, lr_high, alpha_low, alpha_high = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fSA1uTMSaN_g","outputId":"0e516047-82be-4d57-e1bd-95742844a66f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","################\n","\n","round: 0\n","max 0\n","\n","################\n","\n","1\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 4.2382\n","Epoch 1 train accuracy: 0.0793\n","Epoch 1 dev loss: 3.9854\n","Epoch 1 dev accuracy: 0.1307\n","\n"," --------- \n","Epoch: 2\n","\n","Epoch 2 train loss: 3.8650\n","Epoch 2 train accuracy: 0.1430\n","Epoch 2 dev loss: 3.6485\n","Epoch 2 dev accuracy: 0.1815\n","\n"," --------- \n","Epoch: 3\n","\n","Epoch 3 train loss: 3.6622\n","Epoch 3 train accuracy: 0.1682\n","Epoch 3 dev loss: 3.4355\n","Epoch 3 dev accuracy: 0.2168\n","\n"," --------- \n","Epoch: 4\n","\n","Epoch 4 train loss: 3.4748\n","Epoch 4 train accuracy: 0.1940\n","Epoch 4 dev loss: 3.2958\n","Epoch 4 dev accuracy: 0.2158\n","\n"," --------- \n","Epoch: 5\n","\n","Epoch 5 train loss: 3.3187\n","Epoch 5 train accuracy: 0.2140\n","Epoch 5 dev loss: 3.1096\n","Epoch 5 dev accuracy: 0.2552\n","\n"," --------- \n","Epoch: 6\n","\n","Epoch 6 train loss: 3.1599\n","Epoch 6 train accuracy: 0.2343\n","Epoch 6 dev loss: 3.0127\n","Epoch 6 dev accuracy: 0.2656\n","\n"," --------- \n","Epoch: 7\n","\n","Epoch 7 train loss: 3.0315\n","Epoch 7 train accuracy: 0.2520\n","Epoch 7 dev loss: 2.8960\n","Epoch 7 dev accuracy: 0.2832\n","\n"," --------- \n","Epoch: 8\n","\n","Epoch 8 train loss: 2.9114\n","Epoch 8 train accuracy: 0.2673\n","Epoch 8 dev loss: 2.7777\n","Epoch 8 dev accuracy: 0.3050\n","\n"," --------- \n","Epoch: 9\n","\n","Epoch 9 train loss: 2.8148\n","Epoch 9 train accuracy: 0.2829\n","Epoch 9 dev loss: 2.6819\n","Epoch 9 dev accuracy: 0.3247\n","\n"," --------- \n","Epoch: 10\n","\n","Epoch 10 train loss: 2.7157\n","Epoch 10 train accuracy: 0.3000\n","Epoch 10 dev loss: 2.6857\n","Epoch 10 dev accuracy: 0.3309\n","\n"," --------- \n","Epoch: 11\n","\n","Epoch 11 train loss: 2.6456\n","Epoch 11 train accuracy: 0.3165\n","Epoch 11 dev loss: 2.5631\n","Epoch 11 dev accuracy: 0.3278\n","\n"," --------- \n","Epoch: 12\n","\n","Epoch 12 train loss: 2.5762\n","Epoch 12 train accuracy: 0.3223\n","Epoch 12 dev loss: 2.4693\n","Epoch 12 dev accuracy: 0.3610\n","\n"," --------- \n","Epoch: 13\n","\n","Epoch 13 train loss: 2.5015\n","Epoch 13 train accuracy: 0.3421\n","Epoch 13 dev loss: 2.4489\n","Epoch 13 dev accuracy: 0.3527\n","\n"," --------- \n","Epoch: 14\n","\n","Epoch 14 train loss: 2.4501\n","Epoch 14 train accuracy: 0.3488\n","Epoch 14 dev loss: 2.4016\n","Epoch 14 dev accuracy: 0.3537\n","\n"," --------- \n","Epoch: 15\n","\n","Epoch 15 train loss: 2.3913\n","Epoch 15 train accuracy: 0.3616\n","Epoch 15 dev loss: 2.3202\n","Epoch 15 dev accuracy: 0.4046\n","\n"," --------- \n","Epoch: 16\n","\n","Epoch 16 train loss: 2.3498\n","Epoch 16 train accuracy: 0.3723\n","Epoch 16 dev loss: 2.2804\n","Epoch 16 dev accuracy: 0.4046\n","\n"," --------- \n","Epoch: 17\n","\n","Epoch 17 train loss: 2.2962\n","Epoch 17 train accuracy: 0.3864\n","Epoch 17 dev loss: 2.2661\n","Epoch 17 dev accuracy: 0.3900\n","\n"," --------- \n","Epoch: 18\n","\n","Epoch 18 train loss: 2.2477\n","Epoch 18 train accuracy: 0.3922\n","Epoch 18 dev loss: 2.2289\n","Epoch 18 dev accuracy: 0.4046\n","\n"," --------- \n","Epoch: 19\n","\n","Epoch 19 train loss: 2.2051\n","Epoch 19 train accuracy: 0.4034\n","Epoch 19 dev loss: 2.1652\n","Epoch 19 dev accuracy: 0.4191\n","\n"," --------- \n","Epoch: 20\n","\n","Epoch 20 train loss: 2.1751\n","Epoch 20 train accuracy: 0.4119\n","Epoch 20 dev loss: 2.1345\n","Epoch 20 dev accuracy: 0.4139\n","\n"," --------- \n","Epoch: 21\n","\n","Epoch 21 train loss: 2.1229\n","Epoch 21 train accuracy: 0.4194\n","Epoch 21 dev loss: 2.0987\n","Epoch 21 dev accuracy: 0.4305\n","\n"," --------- \n","Epoch: 22\n","\n","Epoch 22 train loss: 2.0956\n","Epoch 22 train accuracy: 0.4211\n","Epoch 22 dev loss: 2.1209\n","Epoch 22 dev accuracy: 0.4429\n","\n"," --------- \n","Epoch: 23\n","\n","Epoch 23 train loss: 2.0648\n","Epoch 23 train accuracy: 0.4348\n","Epoch 23 dev loss: 2.0507\n","Epoch 23 dev accuracy: 0.4419\n","\n"," --------- \n","Epoch: 24\n","\n","Epoch 24 train loss: 2.0193\n","Epoch 24 train accuracy: 0.4489\n","Epoch 24 dev loss: 2.0493\n","Epoch 24 dev accuracy: 0.4357\n","\n"," --------- \n","Epoch: 25\n","\n","Epoch 25 train loss: 1.9976\n","Epoch 25 train accuracy: 0.4458\n","Epoch 25 dev loss: 2.0192\n","Epoch 25 dev accuracy: 0.4627\n","\n"," --------- \n","Epoch: 26\n","\n","Epoch 26 train loss: 1.9658\n","Epoch 26 train accuracy: 0.4513\n","Epoch 26 dev loss: 1.9913\n","Epoch 26 dev accuracy: 0.4865\n","\n"," --------- \n","Epoch: 27\n","\n","Epoch 27 train loss: 1.9354\n","Epoch 27 train accuracy: 0.4623\n","Epoch 27 dev loss: 1.9579\n","Epoch 27 dev accuracy: 0.4544\n","\n"," --------- \n","Epoch: 28\n","\n","Epoch 28 train loss: 1.9120\n","Epoch 28 train accuracy: 0.4689\n","Epoch 28 dev loss: 1.9512\n","Epoch 28 dev accuracy: 0.4803\n","\n"," --------- \n","Epoch: 29\n","\n","Epoch 29 train loss: 1.8760\n","Epoch 29 train accuracy: 0.4806\n","Epoch 29 dev loss: 1.9286\n","Epoch 29 dev accuracy: 0.4544\n","\n"," --------- \n","Epoch: 30\n","\n","Epoch 30 train loss: 1.8647\n","Epoch 30 train accuracy: 0.4779\n","Epoch 30 dev loss: 1.9168\n","Epoch 30 dev accuracy: 0.4751\n","\n"," ######## \n","\n","lr:0.000124, alpha:4.6e-05 @ epoch 26.\n","TL:1.9658316931826003, TA:0.45128466945288753.\n","DL:1.9913439750671387, DA:0.48651452282157676\n","2\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 3.7373\n","Epoch 1 train accuracy: 0.1608\n","Epoch 1 dev loss: 3.5373\n","Epoch 1 dev accuracy: 0.2106\n"]}]},{"cell_type":"code","source":["alpha = 0.000046\n","lr = 0.000124\n","epochs = 30\n","model = GNNModel(d,h,c)\n","model = model.to(device)\n","max_accuracy = 0.5156\n","path = \"class/models/GNN.4.1.pt\"\n","model.load_state_dict(torch.load(path))\n","path = \"class/models/GNN.4.1.pt\"\n","tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUufLi33EdPf","executionInfo":{"status":"ok","timestamp":1737212736668,"user_tz":-60,"elapsed":23108748,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9db97fe1-ab2f-4a3c-d990-b6b3b229f59b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-30-280edc2dd513>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(path))\n"]},{"output_type":"stream","name":"stdout","text":["\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 1.6146\n","Epoch 1 train accuracy: 0.5366\n","Epoch 1 dev loss: 1.7683\n","Epoch 1 dev accuracy: 0.5031\n","\n"," --------- \n","Epoch: 2\n","\n","Epoch 2 train loss: 1.6030\n","Epoch 2 train accuracy: 0.5387\n","Epoch 2 dev loss: 1.7540\n","Epoch 2 dev accuracy: 0.5073\n","\n"," --------- \n","Epoch: 3\n","\n","Epoch 3 train loss: 1.5757\n","Epoch 3 train accuracy: 0.5441\n","Epoch 3 dev loss: 1.7486\n","Epoch 3 dev accuracy: 0.5093\n","\n"," --------- \n","Epoch: 4\n","\n","Epoch 4 train loss: 1.5531\n","Epoch 4 train accuracy: 0.5550\n","Epoch 4 dev loss: 1.7675\n","Epoch 4 dev accuracy: 0.4761\n","\n"," --------- \n","Epoch: 5\n","\n","Epoch 5 train loss: 1.5441\n","Epoch 5 train accuracy: 0.5548\n","Epoch 5 dev loss: 1.7297\n","Epoch 5 dev accuracy: 0.4969\n","\n"," --------- \n","Epoch: 6\n","\n","Epoch 6 train loss: 1.5326\n","Epoch 6 train accuracy: 0.5573\n","Epoch 6 dev loss: 1.7417\n","Epoch 6 dev accuracy: 0.5000\n","\n"," --------- \n","Epoch: 7\n","\n","Epoch 7 train loss: 1.5161\n","Epoch 7 train accuracy: 0.5588\n","Epoch 7 dev loss: 1.7574\n","Epoch 7 dev accuracy: 0.4834\n","\n"," --------- \n","Epoch: 8\n","\n","Epoch 8 train loss: 1.5222\n","Epoch 8 train accuracy: 0.5588\n","Epoch 8 dev loss: 1.7473\n","Epoch 8 dev accuracy: 0.5073\n","\n"," --------- \n","Epoch: 9\n","\n","Epoch 9 train loss: 1.4827\n","Epoch 9 train accuracy: 0.5658\n","Epoch 9 dev loss: 1.6992\n","Epoch 9 dev accuracy: 0.5114\n","\n"," --------- \n","Epoch: 10\n","\n","Epoch 10 train loss: 1.4835\n","Epoch 10 train accuracy: 0.5701\n","Epoch 10 dev loss: 1.6821\n","Epoch 10 dev accuracy: 0.5021\n","\n"," --------- \n","Epoch: 11\n","\n","Epoch 11 train loss: 1.4639\n","Epoch 11 train accuracy: 0.5750\n","Epoch 11 dev loss: 1.7070\n","Epoch 11 dev accuracy: 0.4959\n","\n"," --------- \n","Epoch: 12\n","\n","Epoch 12 train loss: 1.4575\n","Epoch 12 train accuracy: 0.5703\n","Epoch 12 dev loss: 1.7236\n","Epoch 12 dev accuracy: 0.4886\n","\n"," --------- \n","Epoch: 13\n","\n","Epoch 13 train loss: 1.4430\n","Epoch 13 train accuracy: 0.5768\n","Epoch 13 dev loss: 1.6857\n","Epoch 13 dev accuracy: 0.5166\n","\n"," --------- \n","Epoch: 14\n","\n","Epoch 14 train loss: 1.4286\n","Epoch 14 train accuracy: 0.5819\n","Epoch 14 dev loss: 1.6906\n","Epoch 14 dev accuracy: 0.5104\n","\n"," --------- \n","Epoch: 15\n","\n","Epoch 15 train loss: 1.4171\n","Epoch 15 train accuracy: 0.5860\n","Epoch 15 dev loss: 1.7132\n","Epoch 15 dev accuracy: 0.5041\n","\n"," --------- \n","Epoch: 16\n","\n","Epoch 16 train loss: 1.4190\n","Epoch 16 train accuracy: 0.5850\n","Epoch 16 dev loss: 1.7000\n","Epoch 16 dev accuracy: 0.5031\n","\n"," --------- \n","Epoch: 17\n","\n","Epoch 17 train loss: 1.3984\n","Epoch 17 train accuracy: 0.5879\n","Epoch 17 dev loss: 1.6704\n","Epoch 17 dev accuracy: 0.5000\n","\n"," --------- \n","Epoch: 18\n","\n","Epoch 18 train loss: 1.3959\n","Epoch 18 train accuracy: 0.5901\n","Epoch 18 dev loss: 1.6688\n","Epoch 18 dev accuracy: 0.5249\n","\n"," --------- \n","Epoch: 19\n","\n","Epoch 19 train loss: 1.3753\n","Epoch 19 train accuracy: 0.5940\n","Epoch 19 dev loss: 1.6631\n","Epoch 19 dev accuracy: 0.5083\n","\n"," --------- \n","Epoch: 20\n","\n","Epoch 20 train loss: 1.3564\n","Epoch 20 train accuracy: 0.6009\n","Epoch 20 dev loss: 1.6624\n","Epoch 20 dev accuracy: 0.5207\n","\n"," --------- \n","Epoch: 21\n","\n","Epoch 21 train loss: 1.3560\n","Epoch 21 train accuracy: 0.6029\n","Epoch 21 dev loss: 1.6308\n","Epoch 21 dev accuracy: 0.5498\n","\n"," --------- \n","Epoch: 22\n","\n","Epoch 22 train loss: 1.3430\n","Epoch 22 train accuracy: 0.6016\n","Epoch 22 dev loss: 1.6723\n","Epoch 22 dev accuracy: 0.5270\n","\n"," --------- \n","Epoch: 23\n","\n","Epoch 23 train loss: 1.3320\n","Epoch 23 train accuracy: 0.6079\n","Epoch 23 dev loss: 1.6789\n","Epoch 23 dev accuracy: 0.5166\n","\n"," --------- \n","Epoch: 24\n","\n","Epoch 24 train loss: 1.3182\n","Epoch 24 train accuracy: 0.6119\n","Epoch 24 dev loss: 1.6570\n","Epoch 24 dev accuracy: 0.5145\n","\n"," --------- \n","Epoch: 25\n","\n","Epoch 25 train loss: 1.3226\n","Epoch 25 train accuracy: 0.6056\n","Epoch 25 dev loss: 1.6727\n","Epoch 25 dev accuracy: 0.5239\n","\n"," --------- \n","Epoch: 26\n","\n","Epoch 26 train loss: 1.3058\n","Epoch 26 train accuracy: 0.6168\n","Epoch 26 dev loss: 1.6558\n","Epoch 26 dev accuracy: 0.5207\n","\n"," --------- \n","Epoch: 27\n","\n","Epoch 27 train loss: 1.3097\n","Epoch 27 train accuracy: 0.6141\n","Epoch 27 dev loss: 1.6637\n","Epoch 27 dev accuracy: 0.5259\n","\n"," ######## \n","\n","lr:0.000124, alpha:4.6e-05 @ epoch 21.\n","TL:1.3559853447244523, TA:0.6029397796352584.\n","DL:1.6307920217514038, DA:0.549792531120332\n"]},{"output_type":"execute_result","data":{"text/plain":["Stats(train_loss=1.3559853447244523, train_accuracy=0.6029397796352584, dev_loss=1.6307920217514038, dev_accuracy=0.549792531120332, epoch=21, lr=0.000124, alpha=4.6e-05, max_accuracy=0.549792531120332)"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["# change batch size\n","# sparse metrices\n","# mixed precision training\n","# memory pinning"],"metadata":{"id":"SOuKhUBtDtNj"}}]}