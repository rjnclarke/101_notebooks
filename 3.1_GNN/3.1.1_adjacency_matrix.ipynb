{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMTyb1Ed0ZoKe/vfleiaP+1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text Classification - Adjaceny Matrix\n"],"metadata":{"id":"Kd-XjP0gwMtN"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","1.   Admin\n","2.   Data\n","3.   Adjacency Matrix\n","4.   Save\n"],"metadata":{"id":"XpDfZeyawOzQ"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","The representation of our graph is central to any graph neiral network.\n","\n","In this notebook we create the adjacency matricies that will be central to all GNN approaches."],"metadata":{"id":"gIcqWWrjyNC6"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"r9yEXb60y2to"}},{"cell_type":"code","source":["import openai\n","import re\n","import pandas as pd\n","from google.colab import drive\n","from google.colab import userdata\n","import os"],"metadata":{"id":"ZWq8zjDty0My","executionInfo":{"status":"ok","timestamp":1734608026611,"user_tz":-60,"elapsed":2688,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data to a string"],"metadata":{"id":"AwIP9QfMwO6j"}},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgYEuZwkzCRY","executionInfo":{"status":"ok","timestamp":1734608047529,"user_tz":-60,"elapsed":20924,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"dd2268b1-81ae-4367-a45e-1e86deb89c93"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train')\n","df_dev = pd.read_pickle(path + 'df_dev')\n","df_test = pd.read_pickle(path + 'df_test')"],"metadata":{"id":"yrc-v_INzGXG","executionInfo":{"status":"ok","timestamp":1734608062790,"user_tz":-60,"elapsed":15270,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df_test.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3As_gzMfzMqc","executionInfo":{"status":"ok","timestamp":1734608062794,"user_tz":-60,"elapsed":11,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"8ce30f89-ee90-4e2f-8bc6-17ab845be13d"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['index', 'master', 'book_idx', 'book', 'chapter_idx', 'chapter',\n","       'author', 'content', 'vanilla_embedding', 'vanilla_embedding.1',\n","       'ft_embedding', 'ft_embedding_pal', 'ner_responses'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["for el in df_train['ner_responses'][0:5]:\n","  print(el)\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNwgWCrtsdPZ","executionInfo":{"status":"ok","timestamp":1734608177176,"user_tz":-60,"elapsed":374,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"e68b1cf8-1a4b-4a93-c486-629983939ab9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["“Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”   “@@John of Tuam##Person ,” repeated @@Mr Cunningham##Person , “was the man.”   He drank and the other gentlemen followed his lead.\n","\n","sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","\n","@@Stephen##Person , who was trying his dead best to yawn if he could, suffering from lassitude generally, replied:   —To fill the ear of a cow elephant. They were haggling over money.   —Is that so? @@Mr Bloom##Person asked.\n","\n","Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","\n","The harmonies which you mean are the mixed or tenor @@Lydian##Person , and the full-toned or bass @@Lydian##Person , and such like.   These then, I said, must be banished; even to women who have a character to maintain they are of no use, and much less to men.   Certainly.\n","\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Adjacency-Matrix}$\n"],"metadata":{"id":"WIAbvqsLzNbU"}},{"cell_type":"code","source":["def get_entities(df):\n","\n","  # Extract entities\n","  pattern = r\"@@([^#]*)##(\\w+\\b)\\S*\"\n","  all_entities = [re.findall(pattern, text) for text in df['ner_responses']]\n","\n","  #hold entities\n","  people = [None] * df.shape[0]\n","  locations = [None] * df.shape[0]\n","  entities = [None] * df.shape[0]\n","\n","  count = 0\n","  # populate entity holders\n","  for i in range(len(entities)):\n","\n","    people_holder = []\n","    locations_holder = []\n","    entity_holder = []\n","\n","    for entity, label in all_entities[i]:\n","      if (label == 'Person') or (label == 'person'):\n","        person_input = entity.lower()\n","        pattern = r'\\b(dr\\.?|mr\\.?|mrs\\.?|miss)\\b'\n","        person_clean = re.sub(pattern, '', person_input, flags=re.IGNORECASE)\n","        people_holder.append(person_clean.strip())\n","        entity_holder.append(person_clean.strip())\n","      elif (label == 'Location') or (label == 'location'):\n","        locations_holder.append(entity.lower().strip())\n","        entity_holder.append(entity.lower().strip())\n","\n","    if people_holder:\n","      people[i] = people_holder\n","    if locations_holder:\n","      locations[i] = locations_holder\n","    if entity_holder:\n","      entities[i] = entity_holder\n","\n","  return people, locations, entities"],"metadata":{"id":"uDHpX7uG6D2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_people, train_locations, train_entities = get_entities(df_train)\n","dev_people, dev_locations, dev_entities = get_entities(df_dev)\n","test_people, test_locations, test_entities = get_entities(df_test)"],"metadata":{"id":"zRIyLVuH7p2T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make adjacency of train + dev nodes\n","df1 = df_train[['index', 'ner_responses']]\n","df2 = df_dev[['index', 'ner_responses']]\n","df_val = pd.concat([df1,df2])\n","val_people, val_locations, val_entities = get_entities(df_val)"],"metadata":{"id":"YRN6tKI1pJXs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WWiL9yfEqsym"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","def create_adjacency(lstr):\n","  n = len(lstr)\n","  matrix = torch.zeros((n, n))\n","  for i in range(n):\n","    for j in range(n):\n","      if (i != j) and (lstr[i] != None) and (lstr[j] != None):\n","        for entity in lstr[i]:\n","          if entity in lstr[j]:\n","            matrix[i,j] = 1\n","  return matrix\n"],"metadata":{"id":"p0VsNJwYGWWx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Save}$\n"],"metadata":{"id":"ycs_hmCzNafG"}},{"cell_type":"code","source":["path = 'class/tensors/adj_{}.pt'"],"metadata":{"id":"4WUIjRE5IF_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train\n","train_people_adj = create_adjacency(train_people)\n","torch.save(train_people_adj, path.format('train_people'))\n","\n","train_locations_adj = create_adjacency(train_locations)\n","torch.save(train_locations_adj, path.format('train_locations'))\n","\n","train_entities_adj = create_adjacency(train_entities)\n","torch.save(train_entities_adj, path.format('train_entities'))\n"],"metadata":{"id":"SwwpbFKKI1Rx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dev\n","dev_people_adj = create_adjacency(dev_people)\n","torch.save(dev_people_adj, path.format('dev_people'))\n","\n","dev_locations_adj = create_adjacency(dev_locations)\n","torch.save(dev_locations_adj, path.format('dev_locations'))\n","\n","dev_entities_adj = create_adjacency(dev_entities)\n","torch.save(dev_entities_adj, path.format('dev_entities'))"],"metadata":{"id":"znhu4Af5MLrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test\n","test_people_adj = create_adjacency(test_people)\n","torch.save(test_people_adj, path.format('test_people'))\n","\n","test_locations_adj = create_adjacency(test_locations)\n","torch.save(test_locations_adj, path.format('test_locations'))\n","\n","test_entities_adj = create_adjacency(test_entities)\n","torch.save(test_entities_adj, path.format('test_entities'))\n"],"metadata":{"id":"sv3MuqJYJzyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train\n","val_people_adj = create_adjacency(val_people)\n","torch.save(val_people_adj, path.format('val_people'))\n","\n","val_locations_adj = create_adjacency(val_locations)\n","torch.save(val_locations_adj, path.format('val_locations'))\n","\n","val_entities_adj = create_adjacency(val_entities)\n","torch.save(val_entities_adj, path.format('val_entities'))"],"metadata":{"id":"D1zzS50bq5t-"},"execution_count":null,"outputs":[]}]}