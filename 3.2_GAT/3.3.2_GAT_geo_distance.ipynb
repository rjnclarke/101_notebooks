{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wKb6fcWLQnAkhJRDJdSYtB6XpSudUcVQ","timestamp":1738752195668},{"file_id":"1fauEpas49JIK1vWh9s10XJwX_rn5wLTU","timestamp":1737991271114}],"gpuType":"T4","toc_visible":true,"collapsed_sections":["NIT-f4xaaHAN","5h6V_IS4aUHE","7gHf4pRRec33","DzuIfUdD1mgl","DzclltjJ2pAD","C5wU1KTmn-Gx"],"authorship_tag":"ABX9TyNtDuos+ZtzVNS8B0vmLz1e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Text Classification - Training a GAT with PyTorch Geometric and Distance Sampler\n"],"metadata":{"id":"dUIPrkd5ZhSk"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","* Admin\n","* Dataset\n","* Model\n","* Sampling\n","* Train - Validate\n","* Test Predictions\n"],"metadata":{"id":"B8XfyA9PZvEw"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","We now train a GAT in PyTorch Geometric. We will keep the network quite close to the previous version. Note poor performance using GAT in this problem. A stable versioning between torch-spare, torch, and torch-geometric is required."],"metadata":{"id":"vret55TUZ02j"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"NIT-f4xaaHAN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wcuqh_quIMyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738848728619,"user_tz":-60,"elapsed":616,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"3d0b4e2b-b4e6-422b-b50f-93467ea19f8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"id":"DzhX1zvqaNvl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738848746791,"user_tz":-60,"elapsed":17108,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"33d5ce05-b877-4de3-c3ee-af350cdf5a07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import torch\n","!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install git+https://github.com/pyg-team/pytorch_geometric.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndE1nWhnWJNw","executionInfo":{"status":"ok","timestamp":1738848769643,"user_tz":-60,"elapsed":22857,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"8af49673-e03f-4df7-e451-0446dc3346f1","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt25cu124\n","Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.18+pt25cu124\n","Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt25cu124\n","Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-1oafvqvf\n","  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-1oafvqvf\n","  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 2f1e4f2e666db65056d001650488be9b31f8dd0f\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.11.11)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2024.12.14)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1172901 sha256=74c17bbae3eb7bb9c2552ddf3744a3996665555a5ac16aeb4bc1da15c82e83a6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-zhft8c2z/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\n","Successfully built torch-geometric\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.7.0\n"]}]},{"cell_type":"code","source":["import torch_geometric"],"metadata":{"id":"e9oamFSEX3-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data\n","* Load adjacency matrices\n","* Instantiate PyTorch Geometric Data objects"],"metadata":{"id":"5h6V_IS4aUHE"}},{"cell_type":"code","source":["path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train')\n","df_dev = pd.read_pickle(path + 'df_dev')\n","df_test = pd.read_pickle(path + 'df_test')"],"metadata":{"id":"ODsXJcTmaSS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = 'class/tensors/adj_{}.pt'\n","\n","# train\n","train_people = torch.load(path.format('train_people'), weights_only=True)\n","train_locations = torch.load(path.format('train_locations'), weights_only=True)\n","train_entities = torch.load(path.format('train_entities'), weights_only=True)\n","\n","# dev\n","dev_people = torch.load(path.format('dev_people'), weights_only=True)\n","dev_locations = torch.load(path.format('dev_locations'), weights_only=True)\n","dev_entities = torch.load(path.format('dev_entities'), weights_only=True)\n","\n","# val (contains the adjacency matrix for both the training and the development set)\n","val_people = torch.load(path.format('val_people.1'), weights_only=True)\n","val_locations = torch.load(path.format('val_locations.1'), weights_only=True)\n","val_entities = torch.load(path.format('val_entities.1'), weights_only=True)"],"metadata":{"id":"Gq2r3eC3aYsu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_entities +=  torch.eye(train_entities.size(0), device=train_entities.device)  # Identity matrix\n","val_entities +=  torch.eye(val_entities.size(0), device=val_entities.device)  # Identity matrix"],"metadata":{"id":"ldWDks6YkZcC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = df_train[['index', 'chapter_idx', 'vanilla_embedding.1']]\n","df2 = df_dev[['index', 'chapter_idx', 'vanilla_embedding.1']]\n","df_val = pd.concat([df2,df1])"],"metadata":{"id":"O_nJwwBo6tuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inputs\n","H_train = torch.stack([torch.tensor(el) for el in list(df_train['vanilla_embedding.1'])]).to(device)\n","labels_train = torch.LongTensor(list(df_train['chapter_idx'])).to(device)\n","\n","H_dev = torch.stack([torch.tensor(el) for el in list(df_dev['vanilla_embedding.1'])]).to(device)\n","labels_dev = torch.LongTensor(list(df_dev['chapter_idx'])).to(device)\n","\n","H_val = torch.stack([torch.tensor(el) for el in list(df_val['vanilla_embedding.1'])]).to(device)\n","labels_val = torch.LongTensor(list(df_val['chapter_idx'])).to(device)"],"metadata":{"id":"MkSHiOlybvoF","executionInfo":{"status":"ok","timestamp":1738850656139,"user_tz":-60,"elapsed":531,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8f2cb0d-4b35-4c68-eca0-ad11283acaa7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-58-3658073e255a>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  H_train = torch.stack([torch.tensor(el) for el in list(df_train['vanilla_embedding.1'])]).to(device)\n","<ipython-input-58-3658073e255a>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  H_dev = torch.stack([torch.tensor(el) for el in list(df_dev['vanilla_embedding.1'])]).to(device)\n","<ipython-input-58-3658073e255a>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  H_val = torch.stack([torch.tensor(el) for el in list(df_val['vanilla_embedding.1'])]).to(device)\n"]}]},{"cell_type":"code","source":["# train relationships where edge index is a tuple [0][0] > [1][0] The first element of list one, links to first element of list 2\n","train_edge_index = train_entities.nonzero(as_tuple=True)\n","train_edge_index = torch.stack(train_edge_index).long().to(device)\n","# train_edge_relation = torch.zeros(train_edge_index.size(1), dtype=torch.long)\n","\n","dev_edge_index = dev_entities.nonzero(as_tuple=True)\n","dev_edge_index = torch.stack(dev_edge_index).long().to(device)\n","# dev_edge_relation = torch.zeros(dev_edge_index.size(1), dtype=torch.long)\n","\n","val_edge_index = val_entities.nonzero(as_tuple=True)\n","val_edge_index = torch.stack(val_edge_index).long().to(device)\n","# val_edge_relation = torch.zeros(val_edge_index.size(1), dtype=torch.long)"],"metadata":{"id":"pHHVIJqZcIlp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.data import Data\n","\n","train_data = Data(x=H_train, edge_index=train_edge_index, y=labels_train)\n","dev_data = Data(x=H_dev, edge_index=dev_edge_index, y=labels_dev)\n","val_data = Data(x=H_val, edge_index=val_edge_index, y=labels_val)"],"metadata":{"id":"h8qp93KRbT-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","\n","def create_closest_neighbors_dict(embedding_matrix, adjacency_matrix, k=4):\n","    \"\"\"\n","    Create a dictionary of closest neighbors based on cosine similarity.\n","\n","    Parameters:\n","    - embedding_matrix: (n x d) tensor where n is the number of nodes and d is the embedding dimension.\n","    - adjacency_matrix: (n x n) tensor representing the graph connectivity.\n","    - k: Number of closest neighbors to find for each node.\n","\n","    Returns:\n","    - closest_neighbor_indices_dict: A dictionary where keys are node indices and values are lists of closest neighbor indices.\n","    \"\"\"\n","    num_nodes = embedding_matrix.size(0)\n","    closest_neighbor_indices_dict = {}\n","\n","    # Iterate over each node\n","    for i in range(num_nodes):\n","        # Get similarities with all other nodes\n","        # Use only neighbors defined by the adjacency matrix\n","        neighbor_indices = adjacency_matrix[i].nonzero(as_tuple=True)[0].to(device)  # Indices of neighbors\n","\n","        # Calculate cosine similarities if there are neighbors\n","        if neighbor_indices.numel() > 0:\n","            similarities = F.cosine_similarity(embedding_matrix[i].unsqueeze(0), embedding_matrix[neighbor_indices], dim=1)\n","            # Get the top k neighbor indices based on similarities\n","            if similarities.size(0) < k:\n","                top_k_vals, top_k_indices = similarities.topk(similarities.size(0))\n","                top_k_vals = [el.item() for el in top_k_vals]\n","            else:\n","                top_k_vals, top_k_indices = similarities.topk(k)\n","                top_k_vals = [el.item() for el in top_k_vals]\n","\n","            closest_neighbors = neighbor_indices[top_k_indices].tolist() # Convert to list\n","\n","            closest_neighbor_indices_dict[i] = list(zip(closest_neighbors, top_k_vals))\n","        else:\n","            # If no neighbors, return an empty list\n","            closest_neighbor_indices_dict[i] = []\n","\n","    return closest_neighbor_indices_dict"],"metadata":{"id":"4r28mxKrW894"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_closest_neighbors = create_closest_neighbors_dict(H_train, train_entities)\n","val_closest_neighbors = create_closest_neighbors_dict(H_val, val_entities)"],"metadata":{"id":"3Uf7Ar-IYHRS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Model}$\n"],"metadata":{"id":"7gHf4pRRec33"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree\n","\n","class GATLayer(MessagePassing):\n","    def __init__(self, in_features, out_channels, dropout=0.45):\n","        super(GATLayer, self).__init__(aggr='add')  # Use 'add' for aggregation.\n","        self.in_features = in_features\n","        self.out_features = out_channels\n","        self.dropout = dropout\n","\n","        # Linear transformations for queries, keys, and values\n","        self.Wq = nn.Linear(in_features, out_channels)\n","        self.Wk = nn.Linear(in_features, out_channels)\n","        self.Wv = nn.Linear(in_features, out_channels)\n","\n","        # Boost self\n","        self.self_bias = nn.Parameter(torch.Tensor(1))  # Bias term for self-loops\n","        nn.init.constant_(self.self_bias, 1.0)\n","        self.leakyrelu = nn.LeakyReLU()\n","\n","        self.batch_norm = nn.BatchNorm1d(out_channels)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for layer in [self.Wq, self.Wk, self.Wv]:\n","            nn.init.xavier_uniform_(layer.weight)\n","\n","    def forward(self, x, edge_index):\n","        # Transform node features into Q, K, V\n","        H_q = self.Wq(x)  # (N, out_channels)\n","        H_k = self.Wk(x)  # (N, out_channels)\n","        H_v = self.Wv(x)  # (N, out_channels)\n","\n","        edge_index = torch.stack([edge_index.coo()[0], edge_index.coo()[1]])\n","\n","        # Propagate messages using the edge index\n","        out = self.propagate(edge_index, x=H_v, H_q=H_q, H_k=H_k)\n","\n","        # Apply dropout and batch normalization\n","        out = F.dropout(out, p=self.dropout)\n","        out = self.batch_norm(out)\n","\n","        return out\n","\n","    def message(self, x_j, H_q, H_k, edge_index):\n","\n","        # flag = True\n","        # Calculate attention scores. Assuming H_k and H_q are already of shape (N, out_channels)\n","        E = torch.matmul(H_q, H_k.transpose(0, 1))  # (N, N) attention scores\n","\n","        n = H_q.size(0)\n","        I = torch.eye(n, device=x_j.device)  # Identity matrix\n","        E += self.self_bias * I  # Incorporate self-attention bias\n","\n","        row = edge_index[0]\n","        col = edge_index[1]\n","\n","        attention = E[row, col]  # Correct attention for each directed edge\n","\n","        # Apply softmax to get normalized attention weights for each node\n","        attention = F.softmax(attention, dim=-1)\n","\n","        # Weight the neighbor features by the attention coefficients\n","        weighted_messages = attention.view(-1, 1) * x_j  # Scale by attention scores\n","\n","        return weighted_messages  # Return the weighted messages\n"],"metadata":{"id":"7LWcP7aPcTg3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GNNModel(nn.Module):\n","    def __init__(self, d, h, c, num_layers=2, dropout_rate=0.42):\n","        super(GNNModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.gnn_layers = nn.ModuleList([GATLayer(d, d, dropout_rate) for _ in range(num_layers)])\n","        self.fc1 = nn.Linear(d, h)\n","        self.batch_norm_fc1 = nn.BatchNorm1d(h)\n","        self.fc2 = nn.Linear(h, c)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, edge_index):\n","        #print('############# to GAT Layers #############')\n","        for layer in self.gnn_layers:\n","            x = layer(x, edge_index)\n","\n","        x = self.relu(self.batch_norm_fc1(self.dropout(self.fc1(x))))\n","        Output = self.fc2(x)\n","        return Output\n","\n","    def forward_layer(self, x, edge_index, layer_idx):\n","        \"\"\"Forward pass for a specific layer.\"\"\"\n","        x = self.gnn_layers[layer_idx](x, edge_index)\n","        return x"],"metadata":{"id":"SHYnC6PZrXcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d = 768\n","h = 400   # hidden dimension of fully connected layer\n","c = 70   # number of classes\n","num_relations = 2   # number of relationship types\n","\n","# Model, Loss, Optimizer\n","model = GNNModel(d,h,c)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"],"metadata":{"id":"nKdPLK7UyxI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_parameters_per_module(model):\n","    print(\"Module and parameter counts:\")\n","\n","    for name, module in model.named_modules():\n","        # Skip the top-level module (the model itself)\n","        if not isinstance(module, nn.Module) or name == \"\":\n","            continue\n","\n","        param_count = sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","        if param_count > 0:  # Only print modules that have parameters\n","            print(f\"{name}: {param_count} parameters\")"],"metadata":{"id":"Yr_9pjgP0Xv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count_parameters_per_module(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfjwlWEN0n70","executionInfo":{"status":"ok","timestamp":1738850717578,"user_tz":-60,"elapsed":287,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"4039adeb-23a2-48e6-a449-ff48c7aaec87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Module and parameter counts:\n","gnn_layers: 3546626 parameters\n","gnn_layers.0: 1773313 parameters\n","gnn_layers.0.Wq: 590592 parameters\n","gnn_layers.0.Wk: 590592 parameters\n","gnn_layers.0.Wv: 590592 parameters\n","gnn_layers.0.batch_norm: 1536 parameters\n","gnn_layers.1: 1773313 parameters\n","gnn_layers.1.Wq: 590592 parameters\n","gnn_layers.1.Wk: 590592 parameters\n","gnn_layers.1.Wv: 590592 parameters\n","gnn_layers.1.batch_norm: 1536 parameters\n","fc1: 307600 parameters\n","batch_norm_fc1: 800 parameters\n","fc2: 28070 parameters\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Sampling}$\n"],"metadata":{"id":"DzuIfUdD1mgl"}},{"cell_type":"code","source":["import torch\n","from torch import Tensor\n","from typing import Callable, List, NamedTuple, Optional, Tuple, Union\n","from torch_geometric.loader import NeighborSampler\n","from torch_geometric.typing import SparseTensor\n","from collections import defaultdict\n","\n","class EdgeIndex(NamedTuple):\n","    edge_index: Tensor\n","    e_id: Optional[Tensor]\n","    size: Tuple[int, int]\n","\n","    def to(self, *args, **kwargs):\n","        edge_index = self.edge_index.to(*args, **kwargs)\n","        e_id = self.e_id.to(*args, **kwargs) if self.e_id is not None else None\n","        return EdgeIndex(edge_index, e_id, self.size)\n","\n","class Adj(NamedTuple):\n","    adj_t: SparseTensor\n","    e_id: Optional[Tensor]\n","    size: Tuple[int, int]\n","\n","    def to(self, *args, **kwargs):\n","        adj_t = self.adj_t.to(*args, **kwargs)\n","        e_id = self.e_id.to(*args, **kwargs) if self.e_id is not None else None\n","        return Adj(adj_t, e_id, self.size)\n","\n","class CustomNeighborSampler(NeighborSampler):\n","    def __init__(self, edge_index, closest_neighbor_indices_dict, k_neighbor=4, **kwargs):\n","        super(CustomNeighborSampler, self).__init__(edge_index, **kwargs)\n","        self.closest_neighbor_indices_dict = closest_neighbor_indices_dict\n","        self.k_neighbor = k_neighbor\n","\n","    def sample(self, node_idx):\n","        \"\"\"Sample neighbors based on precomputed closest neighbor indices.\"\"\"\n","\n","        batch_size = len(node_idx)\n","        adjs = []\n","        n_id = torch.tensor(node_idx)\n","        # Sample first-hop neighbors\n","        first_hop_neighbors_dict = defaultdict(list)\n","        for node in n_id:\n","            neighbors = self.closest_neighbor_indices_dict.get(node.item(), [])\n","            # Select the top k neighbors\n","            sampled_neighbors = neighbors[:self.k_neighbor]\n","            sampled_neighbors = [x for x,y in sampled_neighbors]  # Sample first-hop neighbors\n","            first_hop_neighbors_dict[node.item()].extend(sampled_neighbors)\n","\n","        # Flatten first-hop neighbors into a set for uniqueness\n","        first_hop_node_ids_set = set()\n","        for node_neighbors in first_hop_neighbors_dict.values():\n","            first_hop_node_ids_set.update(node_neighbors)  # Keep unique entries\n","\n","        # Prepare to store second-hop neighbors\n","        second_hop_neighbors_dict = defaultdict(list)\n","        second_hop_node_ids_set = set()  # Keep unique second-hop IDs\n","        for node in first_hop_node_ids_set:\n","            neighbors = self.closest_neighbor_indices_dict.get(node, [])\n","            # Select the top k neighbors\n","            sampled_neighbors = neighbors[:self.k_neighbor]  # Sample second-hop neighbors\n","            # Filter out first-hop neighbors\n","            sampled_neighbors_filtered = [n[0] for n in sampled_neighbors if n[0] not in first_hop_node_ids_set]\n","            second_hop_neighbors_dict[node].extend(sampled_neighbors_filtered) # dict of tuples (ind, cosine similarity)\n","\n","\n","        second_hop_neighbors = [val for vals in second_hop_neighbors_dict.values() for val in vals]\n","        second_hop_node_ids_set = set(second_hop_neighbors)  # Save second-hop neighbors\n","\n","\n","        # Combine first-hop and second-hop nodes to n_id\n","        all_neighbors = first_hop_node_ids_set.union(second_hop_node_ids_set).union(set(node_idx))\n","        n_id = torch.tensor(list(all_neighbors))  # Update n_id to include all unique first and second hop neighbors\n","\n","        # Create the adjacency tensor for both first-hop and second-hop neighbors\n","        adj_t = self.create_adj_tensor(first_hop_neighbors_dict, second_hop_neighbors_dict,n_id)\n","\n","        # Append the adjacency structure\n","        adjs.append(adj_t)\n","\n","        # Return the batch size, combined node IDs excluding seed nodes, and any adjacency structures\n","        return batch_size, n_id, adjs[::-1]  # Return updated n_id and adjacency list\n","\n","    def create_adj_tensor(self, first_hop_neighbors_dict, second_hop_neighbors_dict, n_id):\n","        # Step 1: Create a combined dictionary from both first and second hop neighbors\n","        combined_neighbors = defaultdict(set)\n","\n","        # Add first-hop neighbors\n","        for seed_node, neighbors in first_hop_neighbors_dict.items():\n","            combined_neighbors[seed_node].update(neighbors)\n","\n","        # Add second-hop neighbors\n","        for first_hop_node, neighbors in second_hop_neighbors_dict.items():\n","            combined_neighbors[first_hop_node].update(neighbors)\n","\n","        # Step 2: Create a node_id to index mapping\n","        mapping = {node: idx for idx, node in enumerate(n_id.numpy())}\n","\n","        # Step 3: Fill row and column indices for the sparse tensor\n","        row_indices = []\n","        col_indices = []\n","\n","        for node, neighbors in combined_neighbors.items():\n","            if node in mapping:  # Ensure the source node is in the mapping\n","                for neighbor in neighbors:\n","                    if neighbor in mapping:  # Ensure the neighbor is in the mapping\n","                        row_indices.append(mapping[node])\n","                        col_indices.append(mapping[neighbor])\n","\n","        edge_index = torch.tensor([row_indices, col_indices], dtype=torch.long)\n","\n","        # When creating the SparseTensor, ensure you are specifying correct sparse size\n","        edge_index_sparse = SparseTensor(\n","            row=edge_index[0],\n","            col=edge_index[1],\n","            sparse_sizes=(len(n_id), len(n_id))\n","        )\n","\n","        # Instead of using sparse_size, use directly the 'sparse_sizes' tuple you defined.\n","        edge_index_obj = EdgeIndex(\n","            edge_index=edge_index_sparse,\n","            e_id=None,\n","            size=edge_index_sparse.sizes()  # Use the method or property for size\n","        )\n","\n","        return [edge_index_obj]  # Return as a list containing the EdgeIndex object\n","\n"],"metadata":{"id":"L-1NL20qYp0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["edge_index = train_data.edge_index\n","# Get unique linked nodes from edge_index\n","linked_nodes = torch.unique(edge_index[0])  # Get source nodes\n","linked_nodes = torch.unique(torch.cat([edge_index[0], edge_index[1]]))  # Get both ends of edges\n","\n","# Now you can pass linked_nodes to NeighborSampler\n","train_sampler = CustomNeighborSampler(\n","  train_data.edge_index,\n","  closest_neighbor_indices_dict = train_closest_neighbors,\n","  node_idx=linked_nodes,  # Use only linked nodes\n","  sizes=[4, 4],\n","  batch_size=32,\n","  shuffle=True,\n","  num_workers=0\n",")"],"metadata":{"id":"lohsBke8yxTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now you can pass linked_nodes to NeighborSampler\n","val_sampler = CustomNeighborSampler(\n","  val_data.edge_index,\n","  closest_neighbor_indices_dict = val_closest_neighbors,\n","  node_idx=None, #torch.arange(964),  # Use only linked nodes\n","  sizes=[4, 4],\n","  batch_size=256,\n","  shuffle=False,\n","  num_workers=0\n",")"],"metadata":{"id":"WJSbSKIy9NeF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","\n","for batch_size, n_id, adj in train_sampler:\n","  if count < 2:\n","    print(f'batch size: {batch_size}')\n","    print(f'n_id: {n_id}')\n","    print(f'n_id size: {n_id.size()}')\n","    print(f'adj: {adj}')\n","    count += 1\n","  break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hne2rwVdadGU","executionInfo":{"status":"ok","timestamp":1738851190817,"user_tz":-60,"elapsed":318,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"3c41aeb3-c882-4086-b3be-cac7878036f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["batch size: 32\n","n_id: tensor([ 2562,  2055,  2057,  5131,  9745, 11793, 11797,  7702,  5658, 10273,\n","         6690,  5153,   552,  8745,  2601,  6188,  6189,  4143, 10288,  1583,\n","         6193, 11315,  3640,  5692,  5182,   574,  9798,  6727, 10823,  3657,\n","        10826,  7771,  1628,  6749,  5729,  4195,  3173, 10861,   113,  9851,\n","         2173,  2178,   643,  6276,  2693,   648, 10383,  1680,  8336,   149,\n","         6296,  3227, 11931,  9887,  8868,  2217,   170,  1707,  7851,   173,\n","         9900,  2733,  3255,  5307,  3266,  1730,  5317, 11461,  1222,  8392,\n","         3274,  1742,  9936,   721,   208,  6356,  6357,  5338,  6363,  1247,\n","         5856,  2786,  7394,   227,  6896,  5876,  5885,  8959,  5888,   775,\n","         6920, 10510,  5390,  8464, 11025,  9486,  2319,  4880,  2320, 10006,\n","         6427,  6940,   796,  7968, 10024, 10537,   811, 11052,  9516,  1326,\n","         7984,  9525,  5944,  6969,  7994,  6461,  4414,  8001,  5968,  1363,\n","         7507,  4436,  2389, 11607, 11610,  5467,  8031, 10081,  8034,  9062,\n","         6503,  6505,  6521,   891,  6015, 10634, 10123,  5005,  2965,  7575,\n","         1443,  7077, 10151,  9643,  3502,  9654,  6586,  6076,  1470,  9152,\n","         2497,  4035, 10693,  3018,  1484,  5076, 11734,  9174,  5594,  7130,\n","          476,   989, 10209,  3045,  7149, 11246, 10742,   504,  7675,  9727])\n","n_id size: torch.Size([170])\n","adj: [[EdgeIndex(edge_index=SparseTensor(row=tensor([  1,   1,   1,   3,   3,   9,   9,  10,  10,  11,  11,  11,  11,  13,\n","                            13,  13,  13,  14,  17,  18,  18,  23,  24,  26,  26,  27,  27,  27,\n","                            30,  30,  30,  32,  32,  32,  32,  35,  35,  35,  35,  37,  37,  40,\n","                            40,  40,  41,  41,  41,  45,  46,  46,  46,  46,  47,  47,  49,  49,\n","                            50,  53,  53,  53,  54,  56,  57,  57,  59,  66,  66,  69,  69,  72,\n","                            72,  72,  73,  73,  79,  80,  80,  81,  81,  81,  81,  82,  82,  83,\n","                            83,  83,  87,  87,  87,  88,  88,  88,  88,  89,  91,  91,  91,  92,\n","                            92,  92,  92,  93,  93,  93,  93,  94,  94,  99, 100, 100, 100, 100,\n","                           101, 101, 104, 104, 105, 105, 106, 106, 107, 108, 108, 108, 110, 113,\n","                           113, 113, 113, 116, 116, 116, 117, 119, 125, 126, 128, 128, 128, 128,\n","                           129, 130, 132, 132, 132, 134, 134, 134, 134, 137, 139, 139, 139, 140,\n","                           140, 140, 141, 141, 143, 143, 143, 143, 144, 144, 145, 145, 145, 145,\n","                           147, 150, 150, 150, 153, 153, 153, 153, 156, 156, 158, 165, 168]),\n","             col=tensor([ 70, 148, 166,  20, 164,   4,  76,  16, 103,  11,  24,  66, 132,  13,\n","                            26,  41,  91,  14,  17,  33,  36,  23, 112,  74, 138,   2,  84, 146,\n","                            12, 111, 121,   9,  32,  69, 126,  35,  45,  82, 117,  86, 103,   0,\n","                           163, 169,   5,  38,  60, 161,   8,  46,  59, 129,  15,  77,  55, 114,\n","                            50,   6,  62, 151, 154,  56,  39, 133, 155, 142, 159,  61, 115,  63,\n","                           118, 149,  51, 111,  79,  22,  64,  18,  54,  81, 156,  42,  85,  34,\n","                           109, 120,  95, 102, 127,   1,  27,  88, 140,  89,  71,  97, 109,  40,\n","                            83,  92, 150,  93,  94, 104, 116, 122, 135,  99,  30,  73,  87, 100,\n","                            33,  96, 124, 157,  29,  68,  29,  48,  36,  25,  65, 123, 110, 105,\n","                           106, 113, 141,  28,  43,  78,  90, 119, 125,  75,  53,  57, 128, 139,\n","                           155, 130,  52,  98, 112,   3,  47, 134, 144, 137,  58, 131, 136,  67,\n","                           152, 160,  21,  44,  10,  37, 143, 158,   7, 164,  49, 101, 107, 145,\n","                           147,  19, 167, 169,  72,  80, 108, 153,  31, 162, 161, 165, 168]),\n","             size=(170, 170), nnz=181, density=0.63%), e_id=None, size=[170, 170])]]\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Train-Validate}$\n"],"metadata":{"id":"DzclltjJ2pAD"}},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    # argmax to get predicted classes\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # count correct\n","    correct = (predicted == labels).sum().item()\n","\n","    # get average\n","    acc = correct / labels.size(0)  # Total number of samples\n","    return acc"],"metadata":{"id":"C5c0Gv_L272t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def train(model, sampler, criterion, optimizer, scheduler):\n","    model.train()\n","    epoch_train_losses = []\n","    epoch_train_accuracy = []\n","    for batch_size, n_id, adjs in sampler:\n","      optimizer.zero_grad()\n","\n","      x = train_data.x[n_id].to(device)  ##### Change to train\n","      edge_index = adjs[0][0].edge_index.t().to(device)\n","      #print('################  to model #############')\n","      out = model(x, edge_index)\n","      y = train_data.y[n_id].to(device) #### Change to train\n","\n","\n","      train_loss = criterion(out, y)\n","      train_accuracy = accuracy(out, y)\n","\n","\n","      epoch_train_losses.append(train_loss.item())\n","      epoch_train_accuracy.append(train_accuracy)\n","\n","      # Backpropagation and optimization\n","      train_loss.backward()\n","      optimizer.step()\n","    scheduler.step()\n","\n","    return np.mean(epoch_train_losses), np.mean(epoch_train_accuracy)"],"metadata":{"id":"7z1e7Z1028pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","def score(reals, preds):\n","  return (reals == preds).sum()/len(reals)\n","\n","def validate(model, sampler, criterion):\n","    \"\"\"\n","    Validate the model on the validation dataset using the provided sampler.\n","\n","    Parameters:\n","    - model: The model to be evaluated.\n","    - sampler: The sampler to sample validation data.\n","    - criterion: The loss function used for evaluation.\n","\n","    Returns:\n","    - dev_loss: The calculated loss on the validation data.\n","    - dev_accuracy: The calculated accuracy on the validation data.\n","    \"\"\"\n","\n","    model.eval()\n","\n","\n","    mask = df_dev.connected.to_numpy() # mask for validation points connected on the graph\n","    n = df_dev.shape[0] # cutoff for validation points\n","\n","    with torch.no_grad():\n","        for batch_size, n_id, adjs in sampler:\n","            edge_index = adjs[0][0].edge_index.t().to(device)\n","            x = val_data.x[n_id].to(device)  # Assuming `data.x` is your node features\n","            #print('############### to validate ####################')\n","            out = model(x, edge_index)\n","            y = val_data.y[n_id].to(device)\n","            #print(y[10:20])\n","\n","            loss = criterion(out, y)\n","            acc = accuracy(out, y)\n","\n","            print('val loss', loss)\n","            print('val acc', acc)\n","\n","            _, predicted = torch.max(out, 1)\n","            reals = y[:n]\n","            preds = predicted[:n]\n","            outs = out[:n,:]\n","            total_loss = criterion(outs, reals)\n","            total_acc = score(reals, preds)\n","\n","            # connected\n","            reals_con = reals\n","            preds_con = preds\n","            connected_acc = score(reals_con, preds_con)\n","\n","            # isolated\n","            reals_iso = reals\n","            preds_iso = preds\n","            isolated_acc = score(reals_iso, preds_iso)\n","\n","    return  total_loss, total_acc, connected_acc, isolated_acc\n","\n","\n","\n"],"metadata":{"id":"dfWUP1WvbKz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 0, trace=False):\n","  \"\"\"\n","  Runs a training setup\n","  verbose == 1 - print model results\n","  verbose == 2 -> print epoch and model results\n","  \"\"\"\n","  model = model.to(device)\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=alpha)\n","\n","  #Warm-up and linear decay scheduler\n","  num_warmup_steps = int(0.1 * epochs)  # 10% of epochs for warm-up\n","  def lr_lambda(current_step):\n","      if current_step < num_warmup_steps:\n","          return float(current_step) / float(max(1, num_warmup_steps))\n","      return max(\n","          0.0, float(epochs - current_step) / float(max(1, epochs - num_warmup_steps))\n","      )\n","\n","  scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n","\n","  # Hold epoch stats\n","  train_losses = []\n","  train_accuracy = []\n","  dev_losses = []\n","  dev_accuracy = []\n","  connected_accuracy = []\n","  isolated_accuracy = []\n","  epoch_holder = []\n","\n","  # Break if no improvement\n","  current_best = 0\n","  no_improvement = 0\n","\n","\n","  # Run epochs\n","  for epoch in range(epochs):\n","\n","    # break out of epochs\n","    if no_improvement >= 60:\n","      break\n","\n","    if trace:\n","      torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","      start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_sampler, criterion, optimizer, scheduler)\n","\n","    if trace:\n","      print(\"\\n--- Profiling Results for Training Phase ---\")\n","      training_time = time.time() - start_time  # Calculate elapsed time\n","      max_train_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","      print(f'Time: {training_time}\\nMax memory: {max_train_memory}')\n","      torch.cuda.reset_peak_memory_stats()  # Reset memory stats\n","      start_time = time.time()\n","      print(\"\\n--- Profiling Results for Validation Phase ---\")\n","\n","    dev_loss, dev_acc, connected_acc, isolated_acc = validate(model, val_sampler, criterion)\n","\n","    if trace:\n","      validation_time = time.time() - start_time  # Calculate elapsed time\n","      max_validation_memory = torch.cuda.max_memory_allocated()  # Get max GPU memory used during training\n","      print(f'Time: {validation_time}\\nMax memory: {max_validation_memory}')\n","\n","    # Store epoch stats\n","    train_losses.append(train_loss)\n","    train_accuracy.append(train_acc)\n","    dev_losses.append(dev_loss)\n","    dev_accuracy.append(dev_acc)\n","    connected_accuracy.append(connected_acc.item())\n","    isolated_accuracy.append(isolated_acc)\n","    epoch_holder.append(epoch + 1)\n","\n","    # check for improvement\n","    if connected_acc > current_best:\n","      current_best = connected_acc\n","      no_improvement = 0\n","    else:\n","      no_improvement += 1\n","\n","    # save best model\n","    if connected_acc > max_accuracy:\n","      torch.save(model.state_dict(), path)\n","      max_accuracy = connected_acc\n","\n","\n","    # optionally print epoch results\n","    if verbose == 2:\n","      print(f'\\n --------- \\nEpoch: {epoch + 1}\\n')\n","      print(f'Epoch {epoch + 1} train loss: {train_loss:.4f}')\n","      print(f'Epoch {epoch + 1} train accuracy: {train_acc:.4f}')\n","      print(f'Epoch {epoch + 1} dev loss: {dev_loss:.4f}')\n","      print(f'Epoch {epoch + 1} dev accuracy: {dev_acc:.4f}')\n","      print(f'Epoch {epoch + 1} connected accuracy: {connected_acc:.4f}')\n","      print(f'Epoch {epoch + 1} isolated accuracy: {isolated_acc:.4f}')\n","\n","\n","\n","      # save best results\n","  #print('T',connected_accuracy)\n","  max_ind = np.argmax(connected_accuracy)\n","\n","  stats = Stats(\n","      train_losses[max_ind],\n","      train_accuracy[max_ind],\n","      dev_losses[max_ind],\n","      dev_accuracy[max_ind],\n","      connected_accuracy[max_ind],\n","      isolated_accuracy[max_ind],\n","      epoch_holder[max_ind],\n","      lr, alpha,\n","      max_accuracy\n","  )\n","\n","  # optionally print model results\n","  if verbose in [1,2]:\n","    print('\\n ######## \\n')\n","    print(f'lr:{stats.lr}, alpha:{stats.alpha} @ epoch {stats.epoch}.')\n","    print(f'TL:{stats.train_loss}, TA:{stats.train_accuracy}.')\n","    print(f'DL:{stats.dev_loss}, DA:{stats.dev_accuracy}')\n","    print(f'con_acc:{stats.connected_accuracy}, iso_acc:{stats.isolated_accuracy}')\n","\n","\n","  return stats"],"metadata":{"id":"1z16rqE1nh0d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### $\\color{red}{Sanity-check:}$"],"metadata":{"id":"PLt297-koEFq"}},{"cell_type":"code","source":["from collections import namedtuple\n","Stats = namedtuple('Stats', [\n","    'train_loss',\n","    'train_accuracy',\n","    'dev_loss',\n","    'dev_accuracy',\n","    'connected_accuracy',\n","    'isolated_accuracy',\n","    'epoch',\n","    'lr',\n","    'alpha',\n","    'max_accuracy'\n","])"],"metadata":{"id":"Gr0gpKwVnT47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tv_run(epochs=20, model=model, lr=0.00005, alpha=0.005, max_accuracy=0, path=\"binme2\", verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQipohINoMe1","executionInfo":{"status":"ok","timestamp":1738852714211,"user_tz":-60,"elapsed":61172,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"31efb874-d127-44d0-bdc7-0e06e973df24","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["val loss tensor(4.0646, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0628, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0759, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0515, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0622, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0724, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0553, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0514, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0830, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0479, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0324, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0537, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0516, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0695, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0433, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0526, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0820, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0854, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.1025, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0581, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0578, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0685, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0594, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0485, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0472, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0516, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0894, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0785, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0645, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0386, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0643, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0604, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0641, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0482, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0740, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0405, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0344, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0529, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0484, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0321, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0575, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0550, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0591, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0855, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0694, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0483, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0531, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0449, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0490, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0665, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0307, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 1\n","\n","Epoch 1 train loss: 3.8302\n","Epoch 1 train accuracy: 0.1536\n","Epoch 1 dev loss: 4.0307\n","Epoch 1 dev accuracy: 0.1532\n","Epoch 1 connected accuracy: 0.1532\n","Epoch 1 isolated accuracy: 0.1532\n","val loss tensor(4.0612, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0596, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0725, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0473, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0597, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0694, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0520, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0477, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0796, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0438, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0297, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0501, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0481, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0662, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0389, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0487, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0789, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0825, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.1005, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0545, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0543, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0651, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0572, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0449, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0431, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0483, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0868, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0754, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0605, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0344, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0611, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0570, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0611, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0445, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0703, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0362, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0303, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0488, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0447, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0276, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0534, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0514, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0552, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0830, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0663, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0442, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0489, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0408, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0454, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0638, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0254, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 2\n","\n","Epoch 2 train loss: 3.8324\n","Epoch 2 train accuracy: 0.1510\n","Epoch 2 dev loss: 4.0254\n","Epoch 2 dev accuracy: 0.1532\n","Epoch 2 connected accuracy: 0.1532\n","Epoch 2 isolated accuracy: 0.1532\n","val loss tensor(4.0537, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0523, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0660, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0401, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0528, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0621, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0444, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0406, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0736, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0359, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0211, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0415, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0409, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0595, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0321, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0407, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0724, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0770, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0946, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0479, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0475, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0583, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0497, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0370, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0355, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0404, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0805, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0687, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0540, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0255, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0541, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0500, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0539, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0366, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0639, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0284, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0222, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0417, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0376, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0193, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0459, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0438, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0481, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0765, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0595, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0370, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0413, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0329, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0378, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0564, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0187, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 3\n","\n","Epoch 3 train loss: 3.8375\n","Epoch 3 train accuracy: 0.1509\n","Epoch 3 dev loss: 4.0187\n","Epoch 3 dev accuracy: 0.1532\n","Epoch 3 connected accuracy: 0.1532\n","Epoch 3 isolated accuracy: 0.1532\n","val loss tensor(4.0563, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0552, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0691, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0440, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0571, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0655, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0480, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0441, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0762, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0392, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0261, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0451, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0449, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0623, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0355, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0435, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0740, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0794, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0976, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0513, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0500, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0621, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0534, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0404, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0391, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0442, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0829, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0723, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0573, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0292, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0581, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0536, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0572, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0394, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0664, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0320, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0254, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0449, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0419, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0236, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0483, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0474, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0521, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0795, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0628, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0402, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0459, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0355, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0414, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0601, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0230, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 4\n","\n","Epoch 4 train loss: 3.8364\n","Epoch 4 train accuracy: 0.1514\n","Epoch 4 dev loss: 4.0230\n","Epoch 4 dev accuracy: 0.1532\n","Epoch 4 connected accuracy: 0.1532\n","Epoch 4 isolated accuracy: 0.1532\n","val loss tensor(4.0506, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0496, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0642, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0377, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0511, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0606, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0426, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0384, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0710, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0337, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0193, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0402, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0394, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0570, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0293, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0385, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0693, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0742, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0931, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0449, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0452, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0562, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0475, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0335, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0331, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0391, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0790, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0673, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0521, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0227, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0530, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0487, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0529, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0337, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0608, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0256, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0188, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0389, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0352, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0168, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0435, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0417, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0457, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0749, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0578, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0340, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0406, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0298, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0352, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0540, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0145, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 5\n","\n","Epoch 5 train loss: 3.8343\n","Epoch 5 train accuracy: 0.1522\n","Epoch 5 dev loss: 4.0145\n","Epoch 5 dev accuracy: 0.1532\n","Epoch 5 connected accuracy: 0.1532\n","Epoch 5 isolated accuracy: 0.1532\n","val loss tensor(4.0469, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0457, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0599, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0337, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0468, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0569, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0384, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0339, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0668, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0298, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0148, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0361, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0352, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0529, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0248, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0349, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0666, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0709, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0900, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0413, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0414, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0520, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0429, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0296, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0292, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0348, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0755, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0643, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0477, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0188, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0483, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0452, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0477, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0295, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0573, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0210, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0144, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0352, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0311, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0120, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0393, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0373, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0423, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0712, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0535, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0302, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0364, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0262, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0306, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0505, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0109, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 6\n","\n","Epoch 6 train loss: 3.8330\n","Epoch 6 train accuracy: 0.1520\n","Epoch 6 dev loss: 4.0109\n","Epoch 6 dev accuracy: 0.1532\n","Epoch 6 connected accuracy: 0.1532\n","Epoch 6 isolated accuracy: 0.1532\n","val loss tensor(4.0470, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0462, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0602, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0345, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0469, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0570, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0391, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0340, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0679, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0304, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0154, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0357, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0352, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0532, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0248, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0340, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0661, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0703, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0897, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0419, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0421, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0531, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0442, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0299, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0300, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0351, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0752, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0639, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0481, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0190, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0490, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0460, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0479, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0301, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0576, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0220, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0143, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0354, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0323, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0125, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0391, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0373, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0423, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0717, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0535, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0306, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0363, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0261, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0310, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0496, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0119, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 7\n","\n","Epoch 7 train loss: 3.8350\n","Epoch 7 train accuracy: 0.1507\n","Epoch 7 dev loss: 4.0119\n","Epoch 7 dev accuracy: 0.1532\n","Epoch 7 connected accuracy: 0.1532\n","Epoch 7 isolated accuracy: 0.1532\n","val loss tensor(4.0438, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0434, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0569, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0311, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0434, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0552, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0367, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0305, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0655, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0285, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0121, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0334, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0317, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0508, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0215, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0313, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0637, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0683, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0877, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0391, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0395, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0499, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0409, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0269, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0272, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0322, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0733, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0619, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0450, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0162, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0459, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0440, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0457, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0269, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0547, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0189, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0109, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0326, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0295, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0090, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0356, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0343, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0395, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0693, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0510, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0272, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0336, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0235, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0283, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0468, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0087, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 8\n","\n","Epoch 8 train loss: 3.8270\n","Epoch 8 train accuracy: 0.1533\n","Epoch 8 dev loss: 4.0087\n","Epoch 8 dev accuracy: 0.1532\n","Epoch 8 connected accuracy: 0.1532\n","Epoch 8 isolated accuracy: 0.1532\n","val loss tensor(4.0480, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0459, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0604, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0357, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0470, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0588, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0401, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0338, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0684, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0312, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0168, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0374, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0367, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0538, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0261, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0355, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0672, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0717, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0905, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0433, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0428, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0548, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0454, device='cuda:0')\n","val acc 0.14216634429400388\n","val loss tensor(4.0306, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0316, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0364, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0763, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0652, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0490, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0206, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0498, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0476, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0499, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0317, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0587, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0232, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0161, device='cuda:0')\n","val acc 0.1452914798206278\n","val loss tensor(4.0366, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0342, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0134, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0398, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0385, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0439, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0729, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0547, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0321, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0378, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0277, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0323, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0511, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0136, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 9\n","\n","Epoch 9 train loss: 3.8283\n","Epoch 9 train accuracy: 0.1520\n","Epoch 9 dev loss: 4.0136\n","Epoch 9 dev accuracy: 0.1532\n","Epoch 9 connected accuracy: 0.1532\n","Epoch 9 isolated accuracy: 0.1532\n","val loss tensor(4.0501, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0486, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0626, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0377, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0490, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0605, device='cuda:0')\n","val acc 0.12734452122408688\n","val loss tensor(4.0423, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0364, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0690, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0340, device='cuda:0')\n","val acc 0.13029989658738367\n","val loss tensor(4.0205, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0396, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0384, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0560, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0284, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0379, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0695, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0737, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0922, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0452, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0454, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0550, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0459, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0336, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0341, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0389, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0777, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0672, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0507, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0239, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0518, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0497, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0516, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0335, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0600, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0253, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0181, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0393, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0366, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0159, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0420, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0403, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0465, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0747, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0566, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0344, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0400, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0301, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0350, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0539, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0171, device='cuda:0')\n","val acc 0.15181058495821728\n","\n"," --------- \n","Epoch: 10\n","\n","Epoch 10 train loss: 3.8270\n","Epoch 10 train accuracy: 0.1528\n","Epoch 10 dev loss: 4.0171\n","Epoch 10 dev accuracy: 0.1518\n","Epoch 10 connected accuracy: 0.1518\n","Epoch 10 isolated accuracy: 0.1518\n","val loss tensor(4.0512, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0490, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0638, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0392, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0499, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0614, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0429, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0378, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0714, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0346, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0220, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0392, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0393, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0565, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0296, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0384, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0691, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0743, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0923, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0468, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0466, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0572, device='cuda:0')\n","val acc 0.13812677388836328\n","val loss tensor(4.0480, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0341, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0351, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0394, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0786, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0675, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0517, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0244, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0524, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0501, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0516, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0342, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0611, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0265, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0197, device='cuda:0')\n","val acc 0.1452914798206278\n","val loss tensor(4.0398, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0376, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0168, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0432, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0410, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0473, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0747, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0564, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0353, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0409, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0306, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0353, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0546, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0175, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 11\n","\n","Epoch 11 train loss: 3.8297\n","Epoch 11 train accuracy: 0.1516\n","Epoch 11 dev loss: 4.0175\n","Epoch 11 dev accuracy: 0.1532\n","Epoch 11 connected accuracy: 0.1532\n","Epoch 11 isolated accuracy: 0.1532\n","val loss tensor(4.0489, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0482, device='cuda:0')\n","val acc 0.12092130518234165\n","val loss tensor(4.0619, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0363, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0484, device='cuda:0')\n","val acc 0.1267092069279854\n","val loss tensor(4.0594, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0408, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0360, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0678, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0313, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0192, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0374, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0370, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0541, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0269, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0356, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0668, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0721, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0906, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0442, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0439, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0559, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0447, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0314, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0328, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0371, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0758, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0651, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0492, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0218, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0504, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0485, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0505, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0313, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0587, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0243, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0154, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0377, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0349, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0136, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0407, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0391, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0445, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0732, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0549, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0327, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0381, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0277, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0324, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0524, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0142, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 12\n","\n","Epoch 12 train loss: 3.8292\n","Epoch 12 train accuracy: 0.1514\n","Epoch 12 dev loss: 4.0142\n","Epoch 12 dev accuracy: 0.1532\n","Epoch 12 connected accuracy: 0.1532\n","Epoch 12 isolated accuracy: 0.1532\n","val loss tensor(4.0504, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0487, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0631, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0382, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0506, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0614, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0427, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0386, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0697, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0357, device='cuda:0')\n","val acc 0.13029989658738367\n","val loss tensor(4.0217, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0396, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0391, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0561, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0294, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0384, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0697, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0746, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0916, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0461, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0459, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0574, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0475, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0334, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0344, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0392, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0768, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0673, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0514, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0237, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0523, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0503, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0522, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0339, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0604, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0263, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0186, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0398, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0373, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0164, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0430, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0412, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0467, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0750, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0572, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0351, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0409, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0305, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0353, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0544, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0201, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 13\n","\n","Epoch 13 train loss: 3.8262\n","Epoch 13 train accuracy: 0.1523\n","Epoch 13 dev loss: 4.0201\n","Epoch 13 dev accuracy: 0.1532\n","Epoch 13 connected accuracy: 0.1532\n","Epoch 13 isolated accuracy: 0.1532\n","val loss tensor(4.0459, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0445, device='cuda:0')\n","val acc 0.12092130518234165\n","val loss tensor(4.0588, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0332, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0452, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0570, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0380, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0329, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0655, device='cuda:0')\n","val acc 0.1028971028971029\n","val loss tensor(4.0298, device='cuda:0')\n","val acc 0.13029989658738367\n","val loss tensor(4.0153, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0346, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0338, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0513, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0245, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0329, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0657, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0701, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0885, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0414, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0407, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0520, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0426, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0286, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0294, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0341, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0742, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0621, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0461, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0181, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0472, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0455, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0490, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0281, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0555, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0205, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0132, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0346, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0312, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0104, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0381, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0359, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0415, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0707, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0526, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0294, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0353, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0248, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0292, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0491, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0133, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 14\n","\n","Epoch 14 train loss: 3.8285\n","Epoch 14 train accuracy: 0.1512\n","Epoch 14 dev loss: 4.0133\n","Epoch 14 dev accuracy: 0.1532\n","Epoch 14 connected accuracy: 0.1532\n","Epoch 14 isolated accuracy: 0.1532\n","val loss tensor(4.0453, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0441, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0578, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0318, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0446, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0559, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0372, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0313, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0636, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0276, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0155, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0333, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0331, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0508, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0233, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0319, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0649, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0695, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0876, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0398, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0404, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0509, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0430, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0278, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0284, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0329, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0732, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0613, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0453, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0168, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0471, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0448, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0484, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0270, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0549, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0202, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0130, device='cuda:0')\n","val acc 0.1452914798206278\n","val loss tensor(4.0331, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0306, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0096, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0371, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0351, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0408, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0696, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0516, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0289, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0342, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0244, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0284, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0482, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0107, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 15\n","\n","Epoch 15 train loss: 3.8284\n","Epoch 15 train accuracy: 0.1524\n","Epoch 15 dev loss: 4.0107\n","Epoch 15 dev accuracy: 0.1532\n","Epoch 15 connected accuracy: 0.1532\n","Epoch 15 isolated accuracy: 0.1532\n","val loss tensor(4.0484, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0469, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0606, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0356, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0477, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0593, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0410, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0363, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0674, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0320, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0177, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0370, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0364, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0539, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0272, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0357, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0675, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0718, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0902, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0437, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0441, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0548, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0452, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0308, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0325, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0368, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0760, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0645, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0489, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0209, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0497, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0482, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0502, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0307, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0585, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0241, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0161, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0368, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0338, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0138, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0402, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0387, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0450, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0729, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0544, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0328, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0378, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0280, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0318, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0512, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0140, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 16\n","\n","Epoch 16 train loss: 3.8299\n","Epoch 16 train accuracy: 0.1513\n","Epoch 16 dev loss: 4.0140\n","Epoch 16 dev accuracy: 0.1532\n","Epoch 16 connected accuracy: 0.1532\n","Epoch 16 isolated accuracy: 0.1532\n","val loss tensor(4.0480, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0460, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0605, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0349, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0475, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0584, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0402, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0355, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0672, device='cuda:0')\n","val acc 0.1028971028971029\n","val loss tensor(4.0316, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0175, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0363, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0360, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0534, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0264, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0349, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0672, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0721, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0900, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0434, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0432, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0542, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0454, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0303, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0317, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0359, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0749, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0640, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0486, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0202, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0494, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0475, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0508, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0302, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0575, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0234, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0159, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0362, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0335, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0136, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0399, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0385, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0440, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0723, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0541, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0327, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0376, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0272, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0315, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0511, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0131, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 17\n","\n","Epoch 17 train loss: 3.8277\n","Epoch 17 train accuracy: 0.1520\n","Epoch 17 dev loss: 4.0131\n","Epoch 17 dev accuracy: 0.1532\n","Epoch 17 connected accuracy: 0.1532\n","Epoch 17 isolated accuracy: 0.1532\n","val loss tensor(4.0463, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0447, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0589, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0331, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0456, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0571, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0383, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0331, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0662, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0297, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0157, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0342, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0344, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0514, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0246, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0333, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0654, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0707, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0884, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0421, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0408, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0519, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0440, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0279, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0302, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0343, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0740, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0628, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0465, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0181, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0476, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0458, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0499, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0283, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0552, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0216, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0139, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0344, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0321, device='cuda:0')\n","val acc 0.14565004887585534\n","val loss tensor(4.0110, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0382, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0360, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0426, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0709, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0526, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0303, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0360, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0253, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0296, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0497, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0122, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 18\n","\n","Epoch 18 train loss: 3.8295\n","Epoch 18 train accuracy: 0.1513\n","Epoch 18 dev loss: 4.0122\n","Epoch 18 dev accuracy: 0.1532\n","Epoch 18 connected accuracy: 0.1532\n","Epoch 18 isolated accuracy: 0.1532\n","val loss tensor(4.0448, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0434, device='cuda:0')\n","val acc 0.12092130518234165\n","val loss tensor(4.0578, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0315, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0441, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0556, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0366, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0320, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0637, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0279, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0135, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0330, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0327, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0501, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0229, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0319, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0642, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0688, device='cuda:0')\n","val acc 0.09800190294957184\n","val loss tensor(4.0874, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0398, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0399, device='cuda:0')\n","val acc 0.11776859504132231\n","val loss tensor(4.0516, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0421, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0269, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0283, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0324, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0729, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0614, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0454, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0164, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0461, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0444, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0471, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0268, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0550, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0199, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0117, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0333, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0298, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0092, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0367, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0347, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0412, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0696, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0512, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0283, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0343, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0236, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0279, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0478, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0103, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 19\n","\n","Epoch 19 train loss: 3.8283\n","Epoch 19 train accuracy: 0.1514\n","Epoch 19 dev loss: 4.0103\n","Epoch 19 dev accuracy: 0.1532\n","Epoch 19 connected accuracy: 0.1532\n","Epoch 19 isolated accuracy: 0.1532\n","val loss tensor(4.0423, device='cuda:0')\n","val acc 0.12332695984703633\n","val loss tensor(4.0407, device='cuda:0')\n","val acc 0.1218809980806142\n","val loss tensor(4.0555, device='cuda:0')\n","val acc 0.12035225048923678\n","val loss tensor(4.0288, device='cuda:0')\n","val acc 0.12755598831548198\n","val loss tensor(4.0412, device='cuda:0')\n","val acc 0.1276207839562443\n","val loss tensor(4.0529, device='cuda:0')\n","val acc 0.12833168805528133\n","val loss tensor(4.0340, device='cuda:0')\n","val acc 0.1326530612244898\n","val loss tensor(4.0293, device='cuda:0')\n","val acc 0.1439153439153439\n","val loss tensor(4.0609, device='cuda:0')\n","val acc 0.1038961038961039\n","val loss tensor(4.0249, device='cuda:0')\n","val acc 0.1313340227507756\n","val loss tensor(4.0107, device='cuda:0')\n","val acc 0.17025862068965517\n","val loss tensor(4.0300, device='cuda:0')\n","val acc 0.11566484517304189\n","val loss tensor(4.0300, device='cuda:0')\n","val acc 0.1342031686859273\n","val loss tensor(4.0479, device='cuda:0')\n","val acc 0.10797665369649806\n","val loss tensor(4.0200, device='cuda:0')\n","val acc 0.1403180542563143\n","val loss tensor(4.0290, device='cuda:0')\n","val acc 0.11449676823638043\n","val loss tensor(4.0619, device='cuda:0')\n","val acc 0.0813844714686623\n","val loss tensor(4.0665, device='cuda:0')\n","val acc 0.09895337773549001\n","val loss tensor(4.0854, device='cuda:0')\n","val acc 0.10542168674698796\n","val loss tensor(4.0376, device='cuda:0')\n","val acc 0.13152610441767068\n","val loss tensor(4.0377, device='cuda:0')\n","val acc 0.11880165289256199\n","val loss tensor(4.0483, device='cuda:0')\n","val acc 0.1390728476821192\n","val loss tensor(4.0393, device='cuda:0')\n","val acc 0.14313346228239845\n","val loss tensor(4.0238, device='cuda:0')\n","val acc 0.1239356669820246\n","val loss tensor(4.0256, device='cuda:0')\n","val acc 0.14958448753462603\n","val loss tensor(4.0297, device='cuda:0')\n","val acc 0.13703703703703704\n","val loss tensor(4.0708, device='cuda:0')\n","val acc 0.09350393700787402\n","val loss tensor(4.0590, device='cuda:0')\n","val acc 0.11284046692607004\n","val loss tensor(4.0429, device='cuda:0')\n","val acc 0.11739130434782609\n","val loss tensor(4.0135, device='cuda:0')\n","val acc 0.13877551020408163\n","val loss tensor(4.0435, device='cuda:0')\n","val acc 0.13123359580052493\n","val loss tensor(4.0420, device='cuda:0')\n","val acc 0.13411078717201166\n","val loss tensor(4.0440, device='cuda:0')\n","val acc 0.1437246963562753\n","val loss tensor(4.0237, device='cuda:0')\n","val acc 0.12026515151515152\n","val loss tensor(4.0516, device='cuda:0')\n","val acc 0.09380863039399624\n","val loss tensor(4.0169, device='cuda:0')\n","val acc 0.15060804490177737\n","val loss tensor(4.0086, device='cuda:0')\n","val acc 0.14618834080717488\n","val loss tensor(4.0301, device='cuda:0')\n","val acc 0.13949275362318841\n","val loss tensor(4.0263, device='cuda:0')\n","val acc 0.1466275659824047\n","val loss tensor(4.0067, device='cuda:0')\n","val acc 0.16073147256977863\n","val loss tensor(4.0342, device='cuda:0')\n","val acc 0.10679611650485436\n","val loss tensor(4.0322, device='cuda:0')\n","val acc 0.12832699619771862\n","val loss tensor(4.0379, device='cuda:0')\n","val acc 0.14191106906338694\n","val loss tensor(4.0671, device='cuda:0')\n","val acc 0.10823311748381129\n","val loss tensor(4.0489, device='cuda:0')\n","val acc 0.1278962001853568\n","val loss tensor(4.0255, device='cuda:0')\n","val acc 0.13732718894009216\n","val loss tensor(4.0314, device='cuda:0')\n","val acc 0.13746369796708616\n","val loss tensor(4.0208, device='cuda:0')\n","val acc 0.11857707509881422\n","val loss tensor(4.0247, device='cuda:0')\n","val acc 0.13165013525698827\n","val loss tensor(4.0454, device='cuda:0')\n","val acc 0.13219424460431656\n","val loss tensor(4.0077, device='cuda:0')\n","val acc 0.1532033426183844\n","\n"," --------- \n","Epoch: 20\n","\n","Epoch 20 train loss: 3.8311\n","Epoch 20 train accuracy: 0.1516\n","Epoch 20 dev loss: 4.0077\n","Epoch 20 dev accuracy: 0.1532\n","Epoch 20 connected accuracy: 0.1532\n","Epoch 20 isolated accuracy: 0.1532\n","\n"," ######## \n","\n","lr:5e-05, alpha:0.005 @ epoch 1.\n","TL:3.8302038237253826, TA:0.15355335892644795.\n","DL:4.030656814575195, DA:0.1532033383846283\n","con_acc:0.1532033383846283, iso_acc:0.1532033383846283\n"]},{"output_type":"execute_result","data":{"text/plain":["Stats(train_loss=3.8302038237253826, train_accuracy=0.15355335892644795, dev_loss=tensor(4.0307, device='cuda:0'), dev_accuracy=tensor(0.1532, device='cuda:0'), connected_accuracy=0.1532033383846283, isolated_accuracy=tensor(0.1532, device='cuda:0'), epoch=1, lr=5e-05, alpha=0.005, max_accuracy=tensor(0.1532, device='cuda:0'))"]},"metadata":{},"execution_count":138}]},{"cell_type":"code","source":["def gen_config(lr_low, lr_high, alpha_low, alpha_high):\n","  np.random.seed()\n","  lr = round(10**float(np.random.uniform(lr_low,lr_high)),6)\n","  alpha = round(10**float(np.random.uniform(alpha_low,alpha_high)),6)\n","  return lr, alpha"],"metadata":{"id":"Cxz7XYn2nXL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_ranges( lr, lr_range, alpha, alpha_range):\n","\n","  lr_center = lr\n","  lr_low = lr_center - lr_range/2\n","  lr_high = lr_center + lr_range/2\n","  lr_diff = lr_high - lr_low\n","\n","  alpha_center = alpha\n","  alpha_low = alpha_center - alpha_range/2\n","  alpha_high = alpha_center + alpha_range/2\n","  alpha_diff = alpha_high - alpha_low\n","\n","  return (lr_low, lr_high, alpha_low, alpha_high)"],"metadata":{"id":"7tfL9PPQnZyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def search_stats(results):\n","  best_stats = None\n","  max_dev_accuracy = 0\n","  for i in range(len(results)):\n","    acc = results[i].dev_accuracy\n","    if acc > max_dev_accuracy:\n","      best_stats = results[i]\n","      max_dev_accuracy = acc\n","  return best_stats"],"metadata":{"id":"bb0vRh3Vnd-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs = 60\n","max_accuracy = 0\n","path = \"class/models/GNN_geom_distance.4.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -5\n","lr_high = -3\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -2\n","alpha_range = alpha_high - alpha_low\n","\n","d = 768\n","h = 400\n","c = 70\n","num_relations = 2\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(4):\n","  # debug\n","  print(\"\\n################\\n\")\n","  print(f'round: {i}')\n","  # print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  # print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print('max', max_accuracy)\n","  print(\"\\n################\\n\")\n","\n","\n","  for j in range(6):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha = gen_config(lr_low, lr_high, alpha_low, alpha_high)\n","    # define model\n","    model = GNNModel(d,h,c)\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, lr, alpha, max_accuracy, path, verbose = 1)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range)\n","  lr_low, lr_high, alpha_low, alpha_high = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKK2OQbS58M4","outputId":"b272229c-90df-4f25-9c25-1543597130cc","executionInfo":{"status":"ok","timestamp":1738751867426,"user_tz":-60,"elapsed":706271,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","################\n","\n","round: 0\n","max 0\n","\n","################\n","\n","1\n","T [0.00917431153357029, 0.12614677846431732, 0.24541282653808594, 0.28669723868370056, 0.36467888951301575, 0.39678898453712463, 0.4266054928302765, 0.45642200112342834, 0.4816513657569885, 0.5137614607810974, 0.5321100950241089, 0.5481651425361633, 0.5596330165863037, 0.5779816508293152, 0.5940366983413696, 0.60550457239151, 0.6100917458534241, 0.6100917458534241, 0.6146788597106934, 0.6146788597106934, 0.6169724464416504, 0.6238532066345215, 0.6330274939537048, 0.6376146674156189, 0.6376146674156189, 0.6353210806846619, 0.6444953680038452, 0.6513761281967163, 0.6490825414657593, 0.6444953680038452, 0.6444953680038452, 0.6376146674156189, 0.6467889547348022, 0.6513761281967163]\n","\n"," ######## \n","\n","lr:5.2e-05, alpha:0.002825 @ epoch 28.\n","TL:0.46861774086952207, TA:0.8937791779287226.\n","DL:1.698555827140808, DA:0.5549792647361755\n","con_acc:0.6513761281967163, iso_acc:0.4753788113594055\n","2\n","T [0.0, 0.12155962735414505, 0.23853209614753723, 0.3096330165863037, 0.3692660331726074, 0.408256858587265, 0.45183485746383667, 0.4747706353664398, 0.49541282653808594, 0.5022935271263123, 0.5344036221504211, 0.5527522563934326, 0.5802751779556274, 0.5940366983413696, 0.600917398929596, 0.6100917458534241, 0.6123852729797363, 0.6192660331726074, 0.6215596199035645, 0.6192660331726074, 0.6261467337608337, 0.6284403204917908, 0.6399082541465759, 0.6330274939537048, 0.6284403204917908, 0.6307339072227478, 0.6467889547348022, 0.6444953680038452, 0.6467889547348022, 0.6376146674156189, 0.6467889547348022, 0.6444953680038452, 0.6376146674156189]\n","\n"," ######## \n","\n","lr:5.5e-05, alpha:2.7e-05 @ epoch 27.\n","TL:0.4564515718391963, TA:0.8956821024273811.\n","DL:1.7085509300231934, DA:0.5570539832115173\n","con_acc:0.6467889547348022, iso_acc:0.48295456171035767\n","3\n","T [0.01834862306714058, 0.18577980995178223, 0.2545871436595917, 0.353210985660553, 0.40366971492767334, 0.4541284143924713, 0.4816513657569885, 0.5252293348312378, 0.5435779690742493, 0.5711008906364441, 0.5940366983413696, 0.6169724464416504, 0.6238532066345215, 0.6215596199035645, 0.6399082541465759, 0.6422017812728882, 0.6490825414657593, 0.6444953680038452, 0.6513761281967163, 0.6605504155158997, 0.6697247624397278, 0.6559633016586304, 0.6697247624397278, 0.6559633016586304, 0.6697247624397278, 0.6674311757087708, 0.6628440022468567]\n","\n"," ######## \n","\n","lr:8.5e-05, alpha:0.000728 @ epoch 21.\n","TL:0.3558434706074851, TA:0.9208986622566809.\n","DL:1.6453458070755005, DA:0.5778008699417114\n","con_acc:0.6697247624397278, iso_acc:0.501893937587738\n","4\n","T [0.03211009129881859, 0.30504587292671204, 0.4013761281967163, 0.4793577790260315, 0.5504586696624756, 0.5963302254676819, 0.6353210806846619, 0.6261467337608337, 0.6536697149276733, 0.6444953680038452, 0.6674311757087708, 0.6490825414657593, 0.6605504155158997, 0.6490825414657593, 0.6559633016586304, 0.6536697149276733, 0.6559633016586304]\n","\n"," ######## \n","\n","lr:0.000337, alpha:0.0091 @ epoch 11.\n","TL:0.21919480093887875, TA:0.950621862760638.\n","DL:1.643255352973938, DA:0.5850622653961182\n","con_acc:0.6674311757087708, iso_acc:0.5170454978942871\n","5\n","T [0.00917431153357029, 0.15366971492767334, 0.2614678740501404, 0.3348623812198639, 0.3692660331726074, 0.41055044531822205, 0.4541284143924713, 0.49541282653808594, 0.5229357481002808, 0.5344036221504211, 0.5711008906364441, 0.5871559381484985, 0.60550457239151, 0.6123852729797363, 0.6192660331726074, 0.6146788597106934, 0.6261467337608337, 0.6215596199035645, 0.6215596199035645, 0.6215596199035645, 0.6192660331726074, 0.6215596199035645, 0.6261467337608337]\n","\n"," ######## \n","\n","lr:6.9e-05, alpha:0.002982 @ epoch 17.\n","TL:0.6631287479400635, TA:0.8461069263562137.\n","DL:1.7966630458831787, DA:0.5404564738273621\n","con_acc:0.6261467337608337, iso_acc:0.4696969985961914\n","6\n","T [0.01834862306714058, 0.04816513508558273, 0.17889907956123352, 0.24541282653808594, 0.27293577790260315, 0.30504587292671204, 0.31880733370780945, 0.3417431116104126, 0.3669724464416504, 0.39678898453712463, 0.4128440320491791, 0.4449540972709656, 0.44954127073287964, 0.46330273151397705, 0.4724770486354828, 0.48394492268562317, 0.49770641326904297, 0.5114678740501404, 0.5229357481002808, 0.5298165082931519, 0.5298165082931519, 0.5458715558052063, 0.5481651425361633, 0.5550458431243896, 0.56651371717453, 0.5688073039054871, 0.5825687646865845, 0.5871559381484985, 0.5894495248794556, 0.5917431116104126, 0.5894495248794556, 0.5894495248794556, 0.5940366983413696, 0.603210985660553, 0.603210985660553, 0.603210985660553, 0.5963302254676819, 0.607798159122467, 0.6123852729797363, 0.60550457239151, 0.6123852729797363, 0.6100917458534241, 0.6146788597106934, 0.6123852729797363, 0.6146788597106934, 0.6123852729797363, 0.6169724464416504, 0.6192660331726074, 0.6215596199035645, 0.6238532066345215, 0.6284403204917908, 0.6284403204917908, 0.6307339072227478, 0.6238532066345215, 0.6215596199035645, 0.6238532066345215, 0.6330274939537048, 0.6284403204917908, 0.6284403204917908, 0.6238532066345215]\n","\n"," ######## \n","\n","lr:2.4e-05, alpha:0.000695 @ epoch 57.\n","TL:0.7003083920478821, TA:0.8327094962207116.\n","DL:1.836340069770813, DA:0.5290456414222717\n","con_acc:0.6330274939537048, iso_acc:0.4431818425655365\n","Stats(train_loss=0.21919480093887875, train_accuracy=0.950621862760638, dev_loss=tensor(1.6433, device='cuda:0'), dev_accuracy=tensor(0.5851, device='cuda:0'), connected_accuracy=0.6674311757087708, isolated_accuracy=tensor(0.5170, device='cuda:0'), epoch=11, lr=0.000337, alpha=0.0091, max_accuracy=tensor(0.6697, device='cuda:0'))\n","\n","################\n","\n","round: 1\n","max tensor(0.6697, device='cuda:0')\n","\n","################\n","\n","7\n","T [0.011467888951301575, 0.3165137469768524, 0.41743117570877075, 0.5298165082931519, 0.5894495248794556, 0.6123852729797363, 0.6490825414657593, 0.6536697149276733, 0.6399082541465759, 0.6720183491706848, 0.6788990497589111, 0.6766054630279541, 0.6582568287849426, 0.6674311757087708, 0.6559633016586304, 0.6582568287849426, 0.6788990497589111]\n","\n"," ######## \n","\n","lr:0.000404, alpha:0.012479 @ epoch 11.\n","TL:0.1854664744223867, TA:0.9573435845936216.\n","DL:1.6578500270843506, DA:0.5923236608505249\n","con_acc:0.6788990497589111, iso_acc:0.5208333730697632\n","8\n","T [0.016055045649409294, 0.23165136575698853, 0.3463302552700043, 0.4449540972709656, 0.5114678740501404, 0.5619266033172607, 0.6169724464416504, 0.5986238121986389, 0.6284403204917908, 0.6307339072227478, 0.6513761281967163, 0.6284403204917908, 0.6444953680038452, 0.6559633016586304, 0.6559633016586304, 0.6766054630279541, 0.6559633016586304, 0.6490825414657593, 0.6513761281967163, 0.6582568287849426, 0.6628440022468567, 0.6605504155158997]\n","\n"," ######## \n","\n","lr:0.000203, alpha:0.018669 @ epoch 16.\n","TL:0.17428424886294774, TA:0.9618250633829575.\n","DL:1.6245476007461548, DA:0.5860996246337891\n","con_acc:0.6766054630279541, iso_acc:0.5113636255264282\n","9\n","T [0.00917431153357029, 0.27293577790260315, 0.37844035029411316, 0.45183485746383667, 0.5275229215621948, 0.5802751779556274, 0.603210985660553, 0.600917398929596, 0.6284403204917908, 0.6536697149276733, 0.6467889547348022, 0.6444953680038452, 0.6467889547348022, 0.6582568287849426, 0.6582568287849426, 0.6490825414657593, 0.6536697149276733, 0.6651375889778137, 0.6766054630279541, 0.6651375889778137, 0.6697247624397278, 0.6834862232208252, 0.6720183491706848, 0.6674311757087708, 0.6788990497589111, 0.6628440022468567, 0.6743118762969971, 0.6720183491706848]\n","\n"," ######## \n","\n","lr:0.000248, alpha:0.007789 @ epoch 22.\n","TL:0.06632769067372594, TA:0.9863984784837481.\n","DL:1.7006865739822388, DA:0.6099585294723511\n","con_acc:0.6834862232208252, iso_acc:0.5492424368858337\n","10\n","T [0.025229357182979584, 0.33027520775794983, 0.45642200112342834, 0.5550458431243896, 0.6123852729797363, 0.6353210806846619, 0.6330274939537048, 0.6444953680038452, 0.6467889547348022, 0.6513761281967163, 0.6651375889778137, 0.6674311757087708, 0.6444953680038452, 0.6651375889778137, 0.6857798099517822, 0.6743118762969971, 0.6628440022468567, 0.6720183491706848, 0.6788990497589111, 0.6811926364898682, 0.6605504155158997]\n","\n"," ######## \n","\n","lr:0.000549, alpha:0.006699 @ epoch 15.\n","TL:0.09127288622515542, TA:0.9776003757373233.\n","DL:1.7978469133377075, DA:0.6058091521263123\n","con_acc:0.6857798099517822, iso_acc:0.5397727489471436\n","11\n","T [0.013761467300355434, 0.24082568287849426, 0.36467888951301575, 0.45183485746383667, 0.5091742873191833, 0.5458715558052063, 0.600917398929596, 0.607798159122467, 0.6353210806846619, 0.6444953680038452, 0.6376146674156189, 0.6490825414657593, 0.6422017812728882, 0.6490825414657593, 0.6582568287849426, 0.6490825414657593, 0.6651375889778137, 0.6490825414657593, 0.6513761281967163, 0.6536697149276733, 0.6559633016586304, 0.6651375889778137, 0.6766054630279541, 0.6697247624397278, 0.6605504155158997, 0.6651375889778137, 0.6720183491706848, 0.6674311757087708, 0.6697247624397278]\n","\n"," ######## \n","\n","lr:0.000211, alpha:0.010462 @ epoch 23.\n","TL:0.07559206047228405, TA:0.9840324068488159.\n","DL:1.6777241230010986, DA:0.5985477566719055\n","con_acc:0.6766054630279541, iso_acc:0.5340909361839294\n","12\n","T [0.011467888951301575, 0.2637614607810974, 0.35091742873191833, 0.42431190609931946, 0.49770641326904297, 0.5527522563934326, 0.5871559381484985, 0.60550457239151, 0.6330274939537048, 0.6399082541465759, 0.6422017812728882, 0.6399082541465759, 0.6559633016586304, 0.6422017812728882, 0.6422017812728882, 0.6536697149276733, 0.6513761281967163, 0.6536697149276733, 0.6536697149276733]\n","\n"," ######## \n","\n","lr:0.000193, alpha:0.007527 @ epoch 13.\n","TL:0.2865520874091557, TA:0.9361591306639798.\n","DL:1.6352980136871338, DA:0.5778008699417114\n","con_acc:0.6559633016586304, iso_acc:0.5132575631141663\n","Stats(train_loss=0.06632769067372594, train_accuracy=0.9863984784837481, dev_loss=tensor(1.7007, device='cuda:0'), dev_accuracy=tensor(0.6100, device='cuda:0'), connected_accuracy=0.6834862232208252, isolated_accuracy=tensor(0.5492, device='cuda:0'), epoch=22, lr=0.000248, alpha=0.007789, max_accuracy=tensor(0.6835, device='cuda:0'))\n","\n","################\n","\n","round: 2\n","max tensor(0.6858, device='cuda:0')\n","\n","################\n","\n","13\n","T [0.004587155766785145, 0.2637614607810974, 0.3807339370250702, 0.4587155878543854, 0.5435779690742493, 0.5779816508293152, 0.6100917458534241, 0.6307339072227478, 0.6536697149276733, 0.6513761281967163, 0.6307339072227478, 0.6422017812728882, 0.6720183491706848, 0.6536697149276733, 0.6582568287849426, 0.6536697149276733, 0.6605504155158997, 0.6605504155158997, 0.6605504155158997]\n","\n"," ######## \n","\n","lr:0.000245, alpha:0.008324 @ epoch 13.\n","TL:0.2132299485376903, TA:0.9528442148730696.\n","DL:1.6346670389175415, DA:0.5964730381965637\n","con_acc:0.6720183491706848, iso_acc:0.5340909361839294\n","14\n","T [0.016055045649409294, 0.2637614607810974, 0.37614676356315613, 0.4220183193683624, 0.5045871138572693, 0.5596330165863037, 0.5802751779556274, 0.60550457239151, 0.6192660331726074, 0.6330274939537048, 0.6513761281967163, 0.6467889547348022, 0.6536697149276733, 0.6628440022468567, 0.6467889547348022, 0.6766054630279541, 0.6811926364898682, 0.6536697149276733, 0.6490825414657593, 0.6720183491706848, 0.6720183491706848, 0.6697247624397278, 0.6674311757087708]\n","\n"," ######## \n","\n","lr:0.000208, alpha:0.009753 @ epoch 17.\n","TL:0.1451280135342053, TA:0.9696706100716362.\n","DL:1.6768836975097656, DA:0.5975103974342346\n","con_acc:0.6811926364898682, iso_acc:0.5284091234207153\n","15\n","T [0.02752293460071087, 0.2499999850988388, 0.3692660331726074, 0.4128440320491791, 0.5022935271263123, 0.5573394298553467, 0.6169724464416504, 0.607798159122467, 0.6215596199035645, 0.6307339072227478, 0.6399082541465759, 0.6307339072227478, 0.6605504155158997, 0.6605504155158997, 0.6536697149276733, 0.6605504155158997, 0.6444953680038452, 0.6720183491706848, 0.6651375889778137, 0.6720183491706848, 0.6674311757087708, 0.6628440022468567, 0.6651375889778137, 0.6697247624397278]\n","\n"," ######## \n","\n","lr:0.000205, alpha:0.006452 @ epoch 18.\n","TL:0.13244238193546023, TA:0.9715848659470818.\n","DL:1.6736036539077759, DA:0.5881742835044861\n","con_acc:0.6720183491706848, iso_acc:0.5189394354820251\n","16\n","T [0.011467888951301575, 0.300458699464798, 0.3669724464416504, 0.44954127073287964, 0.5206421613693237, 0.564220130443573, 0.5986238121986389, 0.6123852729797363, 0.6261467337608337, 0.6192660331726074, 0.6490825414657593, 0.6399082541465759, 0.6444953680038452, 0.6513761281967163, 0.6376146674156189, 0.6582568287849426, 0.6513761281967163, 0.6651375889778137, 0.6651375889778137, 0.6605504155158997, 0.6697247624397278, 0.6674311757087708, 0.6720183491706848, 0.6788990497589111, 0.6628440022468567, 0.6743118762969971, 0.6743118762969971, 0.6697247624397278, 0.6766054630279541, 0.6674311757087708]\n","\n"," ######## \n","\n","lr:0.000194, alpha:0.006325 @ epoch 24.\n","TL:0.07885971258793559, TA:0.9831955624977642.\n","DL:1.7301050424575806, DA:0.5943983793258667\n","con_acc:0.6788990497589111, iso_acc:0.5246212482452393\n","17\n","T [0.01834862306714058, 0.2821100652217865, 0.4013761281967163, 0.4793577790260315, 0.5573394298553467, 0.5917431116104126, 0.6123852729797363, 0.6123852729797363, 0.6628440022468567, 0.6605504155158997, 0.6651375889778137, 0.6513761281967163, 0.6651375889778137, 0.6674311757087708, 0.6766054630279541, 0.6720183491706848, 0.6674311757087708, 0.6674311757087708, 0.6720183491706848, 0.6651375889778137, 0.6811926364898682, 0.6766054630279541, 0.6788990497589111, 0.6788990497589111, 0.6788990497589111, 0.6674311757087708, 0.6834862232208252, 0.6788990497589111, 0.6834862232208252, 0.6788990497589111, 0.6766054630279541, 0.6743118762969971, 0.6811926364898682]\n","\n"," ######## \n","\n","lr:0.000319, alpha:0.007079 @ epoch 27.\n","TL:0.04086269864014217, TA:0.9902180391402029.\n","DL:1.833931565284729, DA:0.6120332479476929\n","con_acc:0.6834862232208252, iso_acc:0.5530303120613098\n","18\n","T [0.011467888951301575, 0.2431192547082901, 0.36467888951301575, 0.4541284143924713, 0.5114678740501404, 0.5940366983413696, 0.6261467337608337, 0.6284403204917908, 0.6353210806846619, 0.6628440022468567, 0.6582568287849426, 0.6559633016586304, 0.6720183491706848, 0.6697247624397278, 0.6743118762969971, 0.6720183491706848, 0.6697247624397278, 0.6857798099517822, 0.6720183491706848, 0.6605504155158997, 0.6697247624397278, 0.6926605105400085, 0.6834862232208252, 0.6628440022468567, 0.6857798099517822, 0.6903669238090515, 0.6834862232208252, 0.6834862232208252]\n","\n"," ######## \n","\n","lr:0.000241, alpha:0.006908 @ epoch 22.\n","TL:0.07264607556164265, TA:0.9840093830909681.\n","DL:1.7026376724243164, DA:0.613070547580719\n","con_acc:0.6926605105400085, iso_acc:0.5473484992980957\n","Stats(train_loss=0.07264607556164265, train_accuracy=0.9840093830909681, dev_loss=tensor(1.7026, device='cuda:0'), dev_accuracy=tensor(0.6131, device='cuda:0'), connected_accuracy=0.6926605105400085, isolated_accuracy=tensor(0.5473, device='cuda:0'), epoch=22, lr=0.000241, alpha=0.006908, max_accuracy=tensor(0.6927, device='cuda:0'))\n","\n","################\n","\n","round: 3\n","max tensor(0.6927, device='cuda:0')\n","\n","################\n","\n","19\n","T [0.016055045649409294, 0.2958715558052063, 0.37155961990356445, 0.45183485746383667, 0.5298165082931519, 0.56651371717453, 0.603210985660553, 0.6100917458534241, 0.6100917458534241, 0.6444953680038452, 0.6559633016586304, 0.6467889547348022, 0.6766054630279541, 0.6490825414657593, 0.6697247624397278, 0.6582568287849426, 0.6743118762969971, 0.6628440022468567, 0.6674311757087708]\n","\n"," ######## \n","\n","lr:0.000223, alpha:0.006331 @ epoch 13.\n","TL:0.23913115186350686, TA:0.9475854641462157.\n","DL:1.6332893371582031, DA:0.5923236608505249\n","con_acc:0.6766054630279541, iso_acc:0.5227273106575012\n","20\n","T [0.01834862306714058, 0.29128438234329224, 0.37844035029411316, 0.46330273151397705, 0.5366972088813782, 0.5986238121986389, 0.600917398929596, 0.6353210806846619, 0.6261467337608337, 0.6536697149276733, 0.6444953680038452, 0.6513761281967163, 0.6582568287849426, 0.6467889547348022, 0.6720183491706848, 0.6628440022468567, 0.6697247624397278, 0.6720183491706848, 0.6582568287849426, 0.6513761281967163, 0.6857798099517822, 0.6788990497589111, 0.6697247624397278, 0.6834862232208252, 0.6605504155158997, 0.6972476840019226, 0.6720183491706848, 0.6834862232208252, 0.6834862232208252, 0.6628440022468567, 0.6743118762969971, 0.6811926364898682]\n","\n"," ######## \n","\n","lr:0.000242, alpha:0.00735 @ epoch 26.\n","TL:0.05208699264696666, TA:0.9892178139152221.\n","DL:1.7426588535308838, DA:0.6120332479476929\n","con_acc:0.6972476840019226, iso_acc:0.5416666865348816\n","21\n","T [0.006880733650177717, 0.2752293348312378, 0.39220181107521057, 0.4541284143924713, 0.5573394298553467, 0.603210985660553, 0.6100917458534241, 0.6169724464416504, 0.6261467337608337, 0.6215596199035645, 0.6238532066345215, 0.6307339072227478, 0.6490825414657593, 0.6330274939537048, 0.6399082541465759, 0.6536697149276733, 0.6536697149276733, 0.6536697149276733, 0.6651375889778137, 0.6628440022468567, 0.6628440022468567, 0.6605504155158997, 0.6766054630279541, 0.6674311757087708, 0.6743118762969971, 0.6513761281967163, 0.6628440022468567, 0.6559633016586304, 0.6743118762969971]\n","\n"," ######## \n","\n","lr:0.000254, alpha:0.007445 @ epoch 23.\n","TL:0.06351263050522123, TA:0.986359881347303.\n","DL:1.6997177600860596, DA:0.610995888710022\n","con_acc:0.6766054630279541, iso_acc:0.5568181872367859\n","22\n","T [0.016055045649409294, 0.28440365195274353, 0.3990825414657593, 0.4747706353664398, 0.5504586696624756, 0.6123852729797363, 0.6100917458534241, 0.6330274939537048, 0.6399082541465759, 0.6513761281967163, 0.6651375889778137, 0.6605504155158997, 0.6674311757087708, 0.6674311757087708, 0.6536697149276733, 0.6697247624397278, 0.6513761281967163, 0.6697247624397278, 0.6697247624397278, 0.6651375889778137, 0.6697247624397278, 0.6697247624397278]\n","\n"," ######## \n","\n","lr:0.000252, alpha:0.007142 @ epoch 16.\n","TL:0.1301062426822526, TA:0.9724512146151897.\n","DL:1.7259855270385742, DA:0.5829876065254211\n","con_acc:0.6697247624397278, iso_acc:0.5113636255264282\n","23\n","T [0.00917431153357029, 0.2821100652217865, 0.38302749395370483, 0.4541284143924713, 0.5229357481002808, 0.5733944773674011, 0.603210985660553, 0.6284403204917908, 0.6353210806846619, 0.6536697149276733, 0.6353210806846619, 0.6582568287849426, 0.6605504155158997, 0.6697247624397278, 0.6559633016586304, 0.6788990497589111, 0.6766054630279541, 0.6788990497589111, 0.6811926364898682, 0.6880733370780945, 0.6674311757087708, 0.6743118762969971, 0.6720183491706848, 0.6926605105400085, 0.6857798099517822, 0.6743118762969971, 0.6720183491706848, 0.6743118762969971, 0.6811926364898682, 0.6926605105400085]\n","\n"," ######## \n","\n","lr:0.000253, alpha:0.006182 @ epoch 24.\n","TL:0.05790837381567274, TA:0.9867626661229846.\n","DL:1.747822880744934, DA:0.6120332479476929\n","con_acc:0.6926605105400085, iso_acc:0.5454545617103577\n","24\n","T [0.016055045649409294, 0.2637614607810974, 0.38532108068466187, 0.4449540972709656, 0.5321100950241089, 0.5825687646865845, 0.6123852729797363, 0.6376146674156189, 0.6399082541465759, 0.6582568287849426, 0.6651375889778137, 0.6582568287849426, 0.6788990497589111, 0.6743118762969971, 0.6697247624397278, 0.6720183491706848, 0.6857798099517822, 0.6766054630279541, 0.6857798099517822, 0.6903669238090515, 0.6788990497589111, 0.6811926364898682, 0.6834862232208252, 0.6880733370780945, 0.6995412707328796, 0.6788990497589111, 0.6926605105400085, 0.6926605105400085, 0.6857798099517822, 0.6949540972709656, 0.6880733370780945]\n","\n"," ######## \n","\n","lr:0.000243, alpha:0.007317 @ epoch 25.\n","TL:0.05605664350092411, TA:0.9877094920239886.\n","DL:1.6933140754699707, DA:0.6161826252937317\n","con_acc:0.6995412707328796, iso_acc:0.5473484992980957\n","Stats(train_loss=0.05605664350092411, train_accuracy=0.9877094920239886, dev_loss=tensor(1.6933, device='cuda:0'), dev_accuracy=tensor(0.6162, device='cuda:0'), connected_accuracy=0.6995412707328796, isolated_accuracy=tensor(0.5473, device='cuda:0'), epoch=25, lr=0.000243, alpha=0.007317, max_accuracy=tensor(0.6995, device='cuda:0'))\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Test-Predictions}$\n","\n"],"metadata":{"id":"C5wU1KTmn-Gx"}},{"cell_type":"code","source":["model = GNNModel(d,h,c)\n","model.load_state_dict(torch.load(\"binme\", weights_only=True))\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rFkYWS7hJ88","executionInfo":{"status":"ok","timestamp":1738246794815,"user_tz":-60,"elapsed":299,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"6dbb815c-d134-4dc9-ab72-323b7e8d91d7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GNNModel(\n","  (gnn_layers): ModuleList(\n","    (0-1): 2 x GNNLayer(768, 768)\n","  )\n","  (fc1): Linear(in_features=768, out_features=400, bias=True)\n","  (batch_norm_fc1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc2): Linear(in_features=400, out_features=70, bias=True)\n","  (dropout): Dropout(p=0.4, inplace=False)\n","  (relu): ReLU()\n",")"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["import torch\n","\n","def score(reals, preds):\n","  return (reals == preds).sum()/len(reals)\n","\n","def validate(model, sampler, criterion):\n","    \"\"\"\n","    Validate the model on the validation dataset using the provided sampler.\n","\n","    Parameters:\n","    - model: The model to be evaluated.\n","    - sampler: The sampler to sample validation data.\n","    - criterion: The loss function used for evaluation.\n","\n","    Returns:\n","    - dev_loss: The calculated loss on the validation data.\n","    - dev_accuracy: The calculated accuracy on the validation data.\n","    \"\"\"\n","\n","    model.eval()\n","\n","\n","    mask = df_dev.connected.to_numpy() # mask for validation points connected on the graph\n","    n = df_dev.shape[0] # cutoff for validation points\n","\n","    with torch.no_grad():\n","        for batch_size, n_id, adjs in sampler:\n","            edge_index = adjs[0][0].edge_index.t().to(device)\n","            x = val_data.x[n_id].to(device)  # Assuming `data.x` is your node features\n","            out = model(x, edge_index)\n","            y = val_data.y[n_id].to(device)\n","\n","            # loss = criterion(out, y)\n","            # acc = accuracy(out, y)\n","\n","            _, predicted = torch.max(out, 1)\n","            reals = y[:n]\n","            preds = predicted[:n]\n","            outs = out[:n,:]\n","            total_loss = criterion(outs, reals)\n","            total_acc = score(reals, preds)\n","\n","            # connected\n","            reals_con = reals[mask]\n","            preds_con = preds[mask]\n","            connected_acc = score(reals_con, preds_con)\n","\n","            # isolated\n","            reals_iso = reals[~mask]\n","            preds_iso = preds[~mask]\n","            isolated_acc = score(reals_iso, preds_iso)\n","\n","    return total_loss, total_acc, connected_acc, isolated_acc\n","\n"],"metadata":{"id":"Em5cbkvchSMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_loss, total_acc, connected_acc, isolated_acc = validate(model, val_sampler, nn.CrossEntropyLoss())"],"metadata":{"id":"Cp1hzKwOhKFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def score(reals, preds):\n","  return (reals == preds).sum()/len(reals)"],"metadata":{"id":"NTu6bw8IqOL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Overall score: {\"{:.4f}\".format(score(reals, preds))}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmnlomjrpPb1","executionInfo":{"status":"ok","timestamp":1738248349188,"user_tz":-60,"elapsed":358,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"a68bd402-b1dc-414e-eb1a-28eb7183f570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overall score: 0.6006\n"]}]},{"cell_type":"code","source":["reals_connected = reals[mask]\n","preds_connected = preds[mask]\n","reals_isol = reals[~mask]\n","preds_isol = preds[~mask]"],"metadata":{"id":"gWksbTetqB2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Connected score: {\"{:.4f}\".format(score(reals_connected, preds_connected))}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwUTUXX2rdvf","executionInfo":{"status":"ok","timestamp":1738248596913,"user_tz":-60,"elapsed":7,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"0198a792-9616-4353-d834-aa48ae6671fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Connected score: 0.6766\n"]}]},{"cell_type":"code","source":["print(f'Isolated score: {\"{:.4f}\".format(score(reals_isol, preds_isol))}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyJPwuEcrner","executionInfo":{"status":"ok","timestamp":1738248599375,"user_tz":-60,"elapsed":228,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"812ae1f1-81b3-4b18-d498-13fd5c203a9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Isolated score: 0.5379\n"]}]}]}