{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["jE5NTl8O7knr","eIaQcNIY7nfk","l5hnPknT7qxR","VfMHZEz17wuU","8JFdwbR18OFH","nLMmV5oU8R5P","rslNz7pHQwU6","mUuijWZHydU3"],"toc_visible":true,"authorship_tag":"ABX9TyPPuUWCfsv+w5dRLm+ar5r5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text Classification - Dataset\n","\n","---"],"metadata":{"id":"8lOILB94r8e4"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","* Preamble\n","* Admin - importing libraries\n","* Scraping - getting our data\n","* Splitting - formatting data into datapoints\n","* Analysis - distribution and size of data\n","* Data - formatting into Pandas and adding more metadata\n","* Subset and Save - train/dev/test set and pickling"],"metadata":{"id":"8iAEkgoVsGoy"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","This is a text classification project where we attempt to test numerous types of AI models on a single task. This first notebook prepares our dataset.\n","\n","#### General Project Themes:\n","\n","* Embedding models\n","  * Finetuning\n","  * Hard Negatives/ Positive Triplet finetuning\n","  * End-End finetuning\n","  * Embedding finetuning\n","* Mixture models\n","* LLMs\n","  * finetuning\n","* GNNs\n","\n","#### Data\n","\n","Our data includes 12,000 training points of approx 40 words in length. These come from 4 classic books, but be counted as 6 given that Ulysses has 3 distinct parts.\n","* Ulysses - James Joyce\n","* Dubliners - James Joyce\n","* Dracula - Bram Stoker\n","* The Republic - Plato\n","\n","#### Comments\n","\n","The task can also be considered 70 classes for each chapter of each book. The works have been carefully selected, for example, there is a variation in the similarity between the works. James Joyce v James Joyce or James Joyce v Plato. The set up will allow us to break up the task and have specialist models for each book. This project allows for practice at various techniques, and although it remains a ficticious challenge. The results of this project will be largely applicable into applications like:\n","\n","* Topic Classification\n","* Fraud Detection\n","* Product Tagging\n","* Sentiment Analysis\n","\n","---\n","\n","#### Notebook Details\n","\n","This notebook imports HTML documents and scrapes the content with Beautiful Soup. With Langchain and Llama-Index the documents are split and prepared to get our clean datasets.\n","\n","\n"],"metadata":{"id":"tVHMZ-H1tDs5"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin:}$\n"],"metadata":{"id":"8D6nW69D7eXD"}},{"cell_type":"code","source":["from google.colab import drive"],"metadata":{"id":"iMzihgs1--h9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mv2MoTUc_OZ6","executionInfo":{"status":"ok","timestamp":1729846804021,"user_tz":-120,"elapsed":21609,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"a15393f2-26c6-4403-a365-164f1f559e1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F36vihB58DVN"},"outputs":[],"source":["%%capture\n","!pip install langchain langchain-community bs4 llama-index"]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import re"],"metadata":{"id":"r_MRKJqn-a9h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Scraping:}$\n"],"metadata":{"id":"Gw9FBK2fwbVR"}},{"cell_type":"markdown","source":["### $\\color{red}{Ulysses:}$\n"],"metadata":{"id":"jE5NTl8O7knr"}},{"cell_type":"code","source":["\n","# Load the HTML file\n","with open('class/data/ulysses_text.html', 'r', encoding='utf-8') as file:\n","    html_content = file.read()\n","\n","# Parse the HTML content\n","soup = BeautifulSoup(html_content, 'html.parser')"],"metadata":{"id":"DeqLvL5i7iTp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to hold all episodes\n","ulysses_episodes = []\n","last_book_title = None\n","\n","# Iterate through each 'div' with the class 'chapter'\n","for chapter in soup.find_all('div', class_='chapter'):\n","    # Check for a book title (h2) above the current chapter\n","    book_title_tag = chapter.find_previous('h2')\n","    if book_title_tag:\n","        last_book_title = book_title_tag.get_text(strip=True)\n","\n","    # Get the episode title from the current chapter (h3)\n","    episode_title_tag = chapter.find('h3')\n","    if episode_title_tag:\n","        episode_title = episode_title_tag.get_text(strip=True)\n","    else:\n","        continue  # Skip if there is no episode title (h3)\n","\n","    # Initialize a dictionary for the current episode\n","    episode_data = {\n","        'master': 'Ulysses',\n","        'book': last_book_title,\n","        'episode': episode_title,\n","        'content': ''\n","    }\n","\n","    # Gather all paragraphs within the current chapter\n","    for paragraph in chapter.find_all('p'):\n","        episode_data['content'] += paragraph.get_text() + ' '  # Add space to separate paragraphs\n","\n","    # Clean up the content by stripping whitespace\n","    episode_data['content'] = episode_data['content'].replace(\"\\n\",\" \")\n","\n","    # Append episode data to the list of episodes\n","    ulysses_episodes.append(episode_data)"],"metadata":{"id":"szmDNAoa-_PN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(ulysses_episodes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ySgA_AKJdod","executionInfo":{"status":"ok","timestamp":1728468534623,"user_tz":-120,"elapsed":14,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"c2713de2-f7b7-4c3a-dfe2-23c33981768e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":127}]},{"cell_type":"markdown","source":["-"],"metadata":{"id":"0RRwhuD7LUvB"}},{"cell_type":"code","source":["ulysses_master = []\n","ulysses_book = []\n","ulysses_chapter = []\n","ulysses_text = []\n","\n","for item in ulysses_episodes:\n","  # get master\n","  ulysses_master.append(item['master'])\n","\n","  # get book number\n","  ulysses_book.append(len(re.findall('I',item['book']))-1)\n","\n","  # get chapter number\n","  number = ''\n","  for char in item['episode']:\n","    if char.isnumeric():\n","      number += char\n","  ulysses_chapter.append(int(number)-1)\n","\n","  # get text\n","  ulysses_text.append(item['content'])"],"metadata":{"id":"S2QgX8qiLeKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ulysses_master)\n","print(ulysses_book)\n","print(ulysses_chapter)\n","print(len(ulysses_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUlvdCVIQaui","executionInfo":{"status":"ok","timestamp":1728468534623,"user_tz":-120,"elapsed":8,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"65133ede-3b4a-4dad-f1c7-ddd1642b0a43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses', 'Ulysses']\n","[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n","18\n"]}]},{"cell_type":"markdown","source":["### $\\color{red}{Dubliners:}$\n"],"metadata":{"id":"eIaQcNIY7nfk"}},{"cell_type":"code","source":["# Load the HTML file\n","with open('class/data/dubliners_text.html', 'r', encoding='utf-8') as file:\n","    html_content = file.read()\n","\n","# Parse the HTML content\n","soup = BeautifulSoup(html_content, 'html.parser')"],"metadata":{"id":"NIsCXj6dRDXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dubliners_episodes = []\n","\n","# Iterate through each 'div' with the class 'chapter'\n","for chapter in soup.find_all('div', class_='chapter'):\n","    # Get the episode title from the current chapter (h3)\n","    episode_title_tag = chapter.find('h2')\n","    if episode_title_tag:\n","        episode_title = episode_title_tag.get_text(strip=True)\n","    else:\n","        continue  # Skip if there is no episode title (h3)\n","\n","    # Initialize a dictionary for the current episode\n","    episode_data = {\n","        'master': 'Dubliners',\n","        'book': 'Dubliners',\n","        'episode': episode_title,\n","        'content': ''\n","    }\n","\n","    # Gather all paragraphs within the current chapter\n","    for paragraph in chapter.find_all('p'):\n","        episode_data['content'] += paragraph.get_text() + ' '  # Add space to separate paragraphs\n","\n","    # Clean up the content by stripping whitespace\n","    episode_data['content'] = episode_data['content'].replace(\"\\n\",\" \")\n","\n","    # Append episode data to the list of episodes\n","    dubliners_episodes.append(episode_data)\n"],"metadata":{"id":"L1uQEoziUpRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dubliners_title = [episode['episode'] for episode in dubliners_episodes]\n","dubliners_inds = list(range(len(ulysses_episodes),len(ulysses_episodes) + len(dubliners_episodes)))\n","dublin_title = {dubliners_title[i]:dubliners_inds[i] for i in range(len(dubliners_episodes))}\n","dublin_title"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kGlhpMOB3zE","executionInfo":{"status":"ok","timestamp":1728468535826,"user_tz":-120,"elapsed":5,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"4b946a33-225a-4822-88d0-dca865e84be8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'THE SISTERS': 18,\n"," 'AN ENCOUNTER': 19,\n"," 'ARABY': 20,\n"," 'EVELINE': 21,\n"," 'AFTER THE RACE': 22,\n"," 'TWO GALLANTS': 23,\n"," 'THE BOARDING HOUSE': 24,\n"," 'A LITTLE CLOUD': 25,\n"," 'COUNTERPARTS': 26,\n"," 'CLAY': 27,\n"," 'A PAINFUL CASE': 28,\n"," 'IVY DAY IN THE COMMITTEE ROOM': 29,\n"," 'A MOTHER': 30,\n"," 'GRACE': 31,\n"," 'THE DEAD': 32}"]},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["dubliners_master = []\n","dubliners_book = []\n","dubliners_chapter = []\n","dubliners_text = []\n","\n","for item in dubliners_episodes:\n","  # get master\n","  dubliners_master.append(item['master'])\n","\n","  # get book number\n","  dubliners_book.append(3)\n","\n","  # get chapter number\n","  dubliners_chapter.append(dublin_title[item['episode']])\n","\n","  # get text\n","  dubliners_text.append(item['content'])"],"metadata":{"id":"hK2cWFsQBcFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(dubliners_master)\n","print(dubliners_book)\n","print(dubliners_chapter)\n","print(len(dubliners_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PcdFpVWFTlo","executionInfo":{"status":"ok","timestamp":1728468535826,"user_tz":-120,"elapsed":4,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"1b59c382-0d44-44b8-a3f0-a4f8eb83be23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners', 'Dubliners']\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n","15\n"]}]},{"cell_type":"markdown","source":["### $\\color{red}{Dracula:}$\n"],"metadata":{"id":"l5hnPknT7qxR"}},{"cell_type":"code","source":["# Load the HTML file\n","with open('class/data/dracula_text.html', 'r', encoding='utf-8') as file:\n","    html_content = file.read()\n","\n","# Parse the HTML content\n","soup = BeautifulSoup(html_content, 'html.parser')"],"metadata":{"id":"C4GCVj-oFs5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dracula_episodes = []\n","\n","# Iterate through each 'div' with the class 'chapter'\n","for chapter in soup.find_all('div', class_='chapter'):\n","    # Get the episode title from the current chapter (h3)\n","    episode_title_tag = chapter.find('h2')\n","    if episode_title_tag:\n","        episode_title = episode_title_tag.get_text(strip=True)\n","    else:\n","        continue  # Skip if there is no episode title (h3)\n","\n","    # Initialize a dictionary for the current episode\n","    episode_data = {\n","        'master': 'Dracula',\n","        'book': 'Dracula',\n","        'episode': episode_title,\n","        'content': ''\n","    }\n","\n","    # Gather all paragraphs within the current chapter\n","    paragraphs = chapter.find('p')\n","    if paragraphs:\n","      for paragraph in chapter.find_all('p'):\n","          episode_data['content'] += paragraph.get_text() + ' '  # Add space to separate paragraphs\n","\n","      # Clean up the content by stripping whitespace\n","      episode_data['content'] = episode_data['content'].replace(\"\\n\",\" \")\n","\n","      # Append episode data to the list of episodes\n","      dracula_episodes.append(episode_data)"],"metadata":{"id":"Z-m8bHJaLj1D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(dracula_episodes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btiKUe6NMWDj","executionInfo":{"status":"ok","timestamp":1728468537627,"user_tz":-120,"elapsed":9,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"cac37911-514b-43c9-d14e-d014b2513275"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","source":["dracula_episodes = dracula_episodes[:-1]"],"metadata":{"id":"n9ChHoTDNsCg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dracula_title = [episode['episode'] for episode in dracula_episodes]\n","dracula_inds = list(range(len(ulysses_episodes) + len(dubliners_episodes),len(ulysses_episodes) + len(dubliners_episodes) + len(dracula_episodes)))\n","drac_title = {dracula_title[i]:dracula_inds[i] for i in range(len(dracula_episodes))}\n","drac_title"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKMxs7bRNkhA","executionInfo":{"status":"ok","timestamp":1728468537627,"user_tz":-120,"elapsed":6,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"5485b02d-f2d3-4010-b933-20e3a1ddbc46","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'CHAPTER IJONATHAN HARKER’S JOURNAL': 33,\n"," 'CHAPTER IIJONATHAN HARKER’S JOURNAL—continued': 34,\n"," 'CHAPTER IIIJONATHAN HARKER’S JOURNAL—continued': 35,\n"," 'CHAPTER IVJONATHAN HARKER’S JOURNAL—continued': 36,\n"," 'CHAPTER V': 37,\n"," 'CHAPTER VIMINA MURRAY’S JOURNAL': 38,\n"," 'CHAPTER VIICUTTING FROM “THE DAILYGRAPH,” 8 AUGUST': 39,\n"," 'CHAPTER VIIIMINA MURRAY’S JOURNAL': 40,\n"," 'CHAPTER IX': 41,\n"," 'CHAPTER X': 42,\n"," 'CHAPTER XI': 43,\n"," 'CHAPTER XIIDR. SEWARD’S DIARY': 44,\n"," 'CHAPTER XIIIDR. SEWARD’S DIARY—continued.': 45,\n"," 'CHAPTER XIVMINA HARKER’S JOURNAL': 46,\n"," 'CHAPTER XVDR. SEWARD’S DIARY—continued.': 47,\n"," 'CHAPTER XVIDR. SEWARD’S DIARY—continued': 48,\n"," 'CHAPTER XVIIDR. SEWARD’S DIARY—continued': 49,\n"," 'CHAPTER XVIIIDR. SEWARD’S DIARY': 50,\n"," 'CHAPTER XIXJONATHAN HARKER’S JOURNAL': 51,\n"," 'CHAPTER XXJONATHAN HARKER’S JOURNAL': 52,\n"," 'CHAPTER XXIDR. SEWARD’S DIARY': 53,\n"," 'CHAPTER XXIIJONATHAN HARKER’S JOURNAL': 54,\n"," 'CHAPTER XXIIIDR. SEWARD’S DIARY': 55,\n"," 'CHAPTER XXIVDR. SEWARD’S PHONOGRAPH DIARY, SPOKEN BY VAN HELSING': 56,\n"," 'CHAPTER XXVDR. SEWARD’S DIARY': 57,\n"," 'CHAPTER XXVIDR. SEWARD’S DIARY': 58,\n"," 'CHAPTER XXVIIMINA HARKER’S JOURNAL': 59}"]},"metadata":{},"execution_count":139}]},{"cell_type":"code","source":["dracula_master = []\n","dracula_book = []\n","dracula_chapter = []\n","dracula_text = []\n","\n","for item in dracula_episodes:\n","  # get master\n","  dracula_master.append(item['master'])\n","\n","  # get book number\n","  dracula_book.append(4)\n","\n","  # get chapter number\n","  dracula_chapter.append(drac_title[item['episode']])\n","\n","  # get text\n","  dracula_text.append(item['content'])"],"metadata":{"id":"DNlsJr_CO3Te"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(dracula_master)\n","print(dracula_book)\n","print(dracula_chapter)\n","print(len(dracula_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vq5s2KsiMrT1","executionInfo":{"status":"ok","timestamp":1728468537628,"user_tz":-120,"elapsed":5,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"d967edab-c570-4b46-c3c0-e511ab99b3b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula', 'Dracula']\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n","27\n"]}]},{"cell_type":"markdown","source":["### $\\color{red}{Republic:}$\n"],"metadata":{"id":"VfMHZEz17wuU"}},{"cell_type":"code","source":["# Load the HTML file\n","with open('class/data/republic_text.html', 'r', encoding='utf-8') as file:\n","    html_content = file.read()\n","\n","# Parse the HTML content\n","soup = BeautifulSoup(html_content, 'html.parser')"],"metadata":{"id":"JBsxKsN08XwE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["republic_episodes = []\n","\n","# Iterate through each 'div' with the class 'chapter'\n","for chapter in soup.find_all('div', class_='chapter'):\n","    # Get the episode title from the current chapter (h3)\n","    episode_title_tag = chapter.find('h2')\n","    if episode_title_tag:\n","        episode_title = episode_title_tag.get_text(strip=True)\n","    else:\n","        continue  # Skip if there is no episode title (h3)\n","\n","    # Initialize a dictionary for the current episode\n","    episode_data = {\n","        'master': 'Republic',\n","        'book': 'Republic',\n","        'episode': episode_title,\n","        'content': ''\n","    }\n","\n","    # Gather all paragraphs within the current chapter\n","    paragraphs = chapter.find('p')\n","    if paragraphs:\n","      for paragraph in chapter.find_all('p'):\n","          episode_data['content'] += paragraph.get_text() + ' '  # Add space to separate paragraphs\n","\n","      # Clean up the content by stripping whitespace\n","      episode_data['content'] = episode_data['content'].replace(\"\\n\",\" \")\n","\n","      # Append episode data to the list of episodes\n","      republic_episodes.append(episode_data)"],"metadata":{"id":"l11ydEG_8bpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(republic_episodes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZYczqIMX9jz7","executionInfo":{"status":"ok","timestamp":1728468539777,"user_tz":-120,"elapsed":14,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"85d8f3a9-8b56-4a8a-a201-e919b5b4f500"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":144}]},{"cell_type":"code","source":["republic_episodes = republic_episodes[2:]"],"metadata":{"id":"OK60l3QJ9y9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chapter_title = [episode['episode'] for episode in republic_episodes]\n","republic_inds = list(range(len(ulysses_episodes) + len(dubliners_episodes) + len(dracula_episodes),len(ulysses_episodes) + len(dubliners_episodes) + len(dracula_episodes) + len(republic_episodes)))\n","republic_title = {chapter_title[i]:republic_inds[i] for i in range(len(republic_episodes))}\n","republic_title"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40MS0qoR9qgu","executionInfo":{"status":"ok","timestamp":1728468539777,"user_tz":-120,"elapsed":9,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"c45d24a0-57d2-4e75-bae0-4541da6c201b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'BOOK I.': 60,\n"," 'BOOK II.': 61,\n"," 'BOOK III.': 62,\n"," 'BOOK IV.': 63,\n"," 'BOOK V.': 64,\n"," 'BOOK VI.': 65,\n"," 'BOOK VII.': 66,\n"," 'BOOK VIII.': 67,\n"," 'BOOK IX.': 68,\n"," 'BOOK X.': 69}"]},"metadata":{},"execution_count":146}]},{"cell_type":"code","source":["republic_master = []\n","republic_book = []\n","republic_chapter = []\n","republic_text = []\n","\n","for item in republic_episodes:\n","  # get master\n","  republic_master.append(item['master'])\n","\n","  # get book number\n","  republic_book.append(5)\n","\n","  # get chapter number\n","  republic_chapter.append(republic_title[item['episode']])\n","\n","  # get text\n","  republic_text.append(item['content'])"],"metadata":{"id":"ENBu-VpN-f9z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(republic_master)\n","print(republic_book)\n","print(republic_chapter)\n","print(len(republic_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kc3B--xJ-4EM","executionInfo":{"status":"ok","timestamp":1728468539777,"user_tz":-120,"elapsed":7,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9f090a9e-0fc8-4180-94d4-456eb1d0137d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic']\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n","10\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Splitting:}$\n"],"metadata":{"id":"8JFdwbR18OFH"}},{"cell_type":"code","source":["from llama_index.core.node_parser import SentenceSplitter"],"metadata":{"id":"pNqmwBtpPSGi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["splitter = SentenceSplitter(\n","    chunk_size=80,\n","    chunk_overlap=0,\n","    separator='.'\n",")"],"metadata":{"id":"MN9rrOLWX_jN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.docstore.document import Document"],"metadata":{"id":"gYe95AOhYOl0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ulysses_docs = []\n","for i in range(len(ulysses_text)):\n","  ulysses_nodes = splitter.split_text(ulysses_text[i])\n","  for node in ulysses_nodes:\n","    doc =  Document(page_content=node, metadata={\"master\":ulysses_master[i],\"book_idx\":ulysses_book[i], \"chapter_idx\":ulysses_chapter[i]})\n","    ulysses_docs.append(doc)\n"],"metadata":{"id":"EIeOq2gYYc_k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dubliners_docs = []\n","for i in range(len(dubliners_text)):\n","  dubliners_nodes = splitter.split_text(dubliners_text[i])\n","  for node in dubliners_nodes:\n","    doc =  Document(page_content=node, metadata={\"master\":dubliners_master[i],\"book_idx\":dubliners_book[i], \"chapter_idx\":dubliners_chapter[i]})\n","    dubliners_docs.append(doc)\n"],"metadata":{"id":"GhG2Ku9yPcIi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dracula_docs = []\n","for i in range(len(dracula_text)):\n","  dracula_nodes = splitter.split_text(dracula_text[i])\n","  for node in dracula_nodes:\n","    doc =  Document(page_content=node, metadata={\"master\":dracula_master[i],\"book_idx\":dracula_book[i], \"chapter_idx\":dracula_chapter[i]})\n","    dracula_docs.append(doc)"],"metadata":{"id":"oXQbLGtEQJD8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["republic_docs = []\n","for i in range(len(republic_text)):\n","  republic_nodes = splitter.split_text(republic_text[i])\n","  for node in republic_nodes:\n","    doc =  Document(page_content=node, metadata={\"master\":republic_master[i],\"book_idx\":republic_book[i], \"chapter_idx\":republic_chapter[i]})\n","    republic_docs.append(doc)"],"metadata":{"id":"2UNrPi2j_DnE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Analysis:}$\n"],"metadata":{"id":"nLMmV5oU8R5P"}},{"cell_type":"code","source":["import numpy as np\n","from collections import Counter\n","def report_docs(docs):\n","  length = len(docs)\n","  book_count = set()\n","  chapter_count = set()\n","  name = docs[0].metadata['master']\n","  word_count = []\n","  chapter_count_list = []\n","  for doc in docs:\n","    book_count.add(doc.metadata[\"book_idx\"])\n","    chapter = doc.metadata[\"chapter_idx\"]\n","    chapter_count.add(chapter)\n","    chapter_count_list.append(chapter)\n","    word_count.append(len(doc.page_content.split()))\n","\n","  mean = np.mean(word_count)\n","  max = np.max(word_count)\n","  min = np.min(word_count)\n","  std = np.std(word_count)\n","  c = Counter(chapter_count_list)\n","  fewest = c.most_common()[-1][1]\n","  most = c.most_common()[0][1]\n","  print('\\n ############## \\n')\n","  print(f'Title: {name}')\n","  print('-------------- \\n')\n","  print(f'total word count: {np.sum(word_count)}')\n","  print(f'total chapters: {len(chapter_count)}')\n","  print(f'total book count: {len(book_count)}')\n","  print('------------- \\n')\n","  print(f'data points: {len(docs)}')\n","  print(f'minority class data points: {fewest}')\n","  print(f'majority class data points: {most}')\n","  print('------------- \\n')\n","  print(f'mean words: {round(mean,1)}')\n","  print(f'max words: {round(max,1)}')\n","  print(f'min words: {round(min,1)}')\n","  print(f'std words: {round(std,1)}')\n"],"metadata":{"id":"bdIADjOugReQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["report_docs(ulysses_docs)\n","report_docs(dubliners_docs)\n","report_docs(dracula_docs)\n","report_docs(republic_docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTnEdwAfZ_l-","executionInfo":{"status":"ok","timestamp":1728468623540,"user_tz":-120,"elapsed":303,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"75021d07-c297-4b71-d47e-49740864c596"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," ############## \n","\n","Title: Ulysses\n","-------------- \n","\n","total word count: 265597\n","total chapters: 18\n","total book count: 3\n","------------- \n","\n","data points: 7093\n","minority class data points: 94\n","majority class data points: 1484\n","------------- \n","\n","mean words: 37.4\n","max words: 72\n","min words: 1\n","std words: 14.9\n","\n"," ############## \n","\n","Title: Dubliners\n","-------------- \n","\n","total word count: 67496\n","total chapters: 15\n","total book count: 1\n","------------- \n","\n","data points: 1378\n","minority class data points: 34\n","majority class data points: 323\n","------------- \n","\n","mean words: 49.0\n","max words: 73\n","min words: 7\n","std words: 10.8\n","\n"," ############## \n","\n","Title: Dracula\n","-------------- \n","\n","total word count: 159755\n","total chapters: 27\n","total book count: 1\n","------------- \n","\n","data points: 3216\n","minority class data points: 72\n","majority class data points: 151\n","------------- \n","\n","mean words: 49.7\n","max words: 71\n","min words: 5\n","std words: 11.1\n","\n"," ############## \n","\n","Title: Republic\n","-------------- \n","\n","total word count: 118281\n","total chapters: 10\n","total book count: 1\n","------------- \n","\n","data points: 2277\n","minority class data points: 172\n","majority class data points: 269\n","------------- \n","\n","mean words: 51.9\n","max words: 73\n","min words: 1\n","std words: 12.3\n"]}]},{"cell_type":"code","source":["all_docs = ulysses_docs + dubliners_docs + dracula_docs + republic_docs"],"metadata":{"id":"KFhOxR_Jb_WB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(all_docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VV2ODJseDQv","executionInfo":{"status":"ok","timestamp":1728468663569,"user_tz":-120,"elapsed":325,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"b3dda418-e405-4e6b-ab92-fd65845ea8e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13964"]},"metadata":{},"execution_count":163}]},{"cell_type":"code","source":["def print_point(ind):\n","  print(' \\n #################### \\n')\n","  contents = all_docs[ind].page_content\n","  meta = all_docs[ind].metadata\n","  print(f'Book: {meta[\"master\"]}')\n","  print(f'Book Index: {meta[\"book_idx\"]}')\n","  print(f'Chapter Index: {meta[\"chapter_idx\"]}')\n","  print('--------------------------')\n","  print(contents)"],"metadata":{"id":"C4tSJR4YcJKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","  print_point(np.random.choice(range(len(all_docs))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUBkQQjIdSyt","executionInfo":{"status":"ok","timestamp":1728468688687,"user_tz":-120,"elapsed":266,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"b5782dea-4c14-45df-afc8-2b7586c53b2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" \n"," #################### \n","\n","Book: Ulysses\n","Book Index: 1\n","Chapter Index: 14\n","--------------------------\n","LORD TENNYSON: (Gentleman poet in Union Jack blazer and cricket flannels, bareheaded, flowingbearded.) Theirs not to reason why.   PRIVATE COMPTON: Biff him, Harry.   STEPHEN: (To Private Compton.) I don’t know your name but you are quite right.\n"," \n"," #################### \n","\n","Book: Ulysses\n","Book Index: 1\n","Chapter Index: 14\n","--------------------------\n","BLOOM: (Turns to the gallery.) The royal Dublins, boys, the salt of the earth, known the world over. I think I see some old comrades in arms up there among you.\n"," \n"," #################### \n","\n","Book: Ulysses\n","Book Index: 1\n","Chapter Index: 12\n","--------------------------\n","he old pair on her inside out and that was for luck and lovers’ meeting if you p\n"," \n"," #################### \n","\n","Book: Dubliners\n","Book Index: 3\n","Chapter Index: 28\n","--------------------------\n","No one wanted him; he was outcast from life’s feast. He turned his eyes to the grey gleaming river, winding along towards Dublin. Beyond the river he saw a goods train winding out of Kingsbridge Station, like a worm with a fiery head winding through the darkness, obstinately and laboriously.\n"," \n"," #################### \n","\n","Book: Ulysses\n","Book Index: 1\n","Chapter Index: 14\n","--------------------------\n","GARRETT DEASY: (Bolt upright, his nailscraped face plastered with postagestamps, brandishes his hockeystick, his blue eyes flashing in the prism of the chandelier as his mount lopes by at schooling gallop.)   Per vias rectas!\n"," \n"," #################### \n","\n","Book: Republic\n","Book Index: 5\n","Chapter Index: 64\n","--------------------------\n","Assuming therefore the possibility of the proposal, I shall now proceed to enquire how the rulers will carry out these arrangements, and I shall demonstrate that our plan, if executed, will be of the greatest benefit to the State and to the guardians.\n"," \n"," #################### \n","\n","Book: Republic\n","Book Index: 5\n","Chapter Index: 60\n","--------------------------\n","’   How admirable are his words!\n"," \n"," #################### \n","\n","Book: Ulysses\n","Book Index: 1\n","Chapter Index: 6\n","--------------------------\n","Two bridegrooms laughing heartily at each other. Cuprani too, printer. More Irish than the Irish.   The machines clanked in threefour time. Thump, thump, thump.\n"," \n"," #################### \n","\n","Book: Ulysses\n","Book Index: 2\n","Chapter Index: 17\n","--------------------------\n","he was married Im sure hed have a fine strong child but I dont know Poldy has mo\n"," \n"," #################### \n","\n","Book: Ulysses\n","Book Index: 1\n","Chapter Index: 13\n","--------------------------\n","He would have withdrawn from the feast had not the noise of voices allayed the smart. Madden had lost five drachmas on Sceptre for a whim of the rider’s name: Lenehan as much more. He told them of the race. The flag fell and, huuh!\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Data:}$\n"],"metadata":{"id":"rslNz7pHQwU6"}},{"cell_type":"code","source":["# Ulysses\n","\n","D_ul_book = {0: \"Telemachia\", 1: \"Odyssey\", 2:\"Nostos\"}\n","D_ul_chapter = {\n","    0:\"Telemachus\",\n","    1:\"Nestor\",\n","    2:\"Proteus\",\n","    3:\"Calypso\",\n","    4:\"Lotus Eaters\",\n","    5:\"Hades\",\n","    6:\"Aeolus\",\n","    7:\"Lestrygonians\",\n","    8:\"Scylla and Charybdis\",\n","    9:\"Wandering Rocks\",\n","    10:\"Sirens\",\n","    11:\"Cyclops\",\n","    12:\"Nausicaa\",\n","    13:\"Oxen of the Sun\",\n","    14:\"Circe\",\n","    15:\"Eumaeus\",\n","    16:\"Ithaca\",\n","    17:\"Penelope\"\n","}\n","\n","ul_master = [item.metadata['master'] for item in ulysses_docs]\n","ul_book_idx = [item.metadata['book_idx'] for item in ulysses_docs]\n","ul_book = [D_ul_book[i] for i in ul_book_idx]\n","ul_chapter_idx = [item.metadata['chapter_idx'] for item in ulysses_docs]\n","ul_chapter = [D_ul_chapter[i] for i in ul_chapter_idx]\n","ul_content = [item.page_content for item in ulysses_docs]\n","ul_author = [\"Joyce\" for item in ul_content]\n"],"metadata":{"id":"051_3nZUQ2TM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dubliners\n","D_db_chapter = {v:k for (k,v) in dublin_title.items()}\n","\n","db_master = [item.metadata['master'] for item in dubliners_docs]\n","db_book_idx = [item.metadata['book_idx'] for item in dubliners_docs]\n","db_book = [\"Dubliners\" for i in db_book_idx]\n","db_chapter_idx = [item.metadata['chapter_idx'] for item in dubliners_docs]\n","db_chapter = [D_db_chapter[i] for i in db_chapter_idx]\n","db_content = [item.page_content for item in dubliners_docs]\n","db_author = [\"Joyce\" for item in db_content]\n"],"metadata":{"id":"S0Ge0MC0XbdK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dracula\n","D_dr_chapter = {\n"," \"CHAPTER I: JONATHAN HARKER’S JOURNAL\": 33,\n"," \"CHAPTER II: JONATHAN HARKER’S JOURNAL—continued\": 34,\n"," \"CHAPTER III: JONATHAN HARKER’S JOURNAL—continued\": 35,\n"," \"CHAPTER IV: JONATHAN HARKER’S JOURNAL—continued\": 36,\n"," \"CHAPTER V: LETTER FROM MISS MINA MURRAY TO MISS LUCY WESTENRA\": 37,\n"," \"CHAPTER VI: MINA MURRAY’S JOURNAL\": 38,\n"," \"CHAPTER VII: CUTTING FROM 'THE DAILYGRAPH,' 8 AUGUST\": 39,\n"," \"CHAPTER VIII: MINA MURRAY’S JOURNAL\": 40,\n"," \"CHAPTER IX: LETTER, MINA HARKER TO LUCY WESTENRA\": 41,\n"," \"CHAPTER X: LETTER, DR.SEWARD TO HON ARTHUR HOLMWOOD\": 42,\n"," \"CHAPTER XI: LUCY WESTENRA'S DIARY\": 43,\n"," \"CHAPTER XII: DR. SEWARD’S DIARY\": 44,\n"," \"CHAPTER XIII: DR. SEWARD’S DIARY—continued.\": 45,\n"," \"CHAPTER XIV: MINA HARKER’S JOURNAL\": 46,\n"," \"CHAPTER XV: DR. SEWARD’S DIARY—continued.\": 47,\n"," \"CHAPTER XVI: DR. SEWARD’S DIARY—continued\": 48,\n"," \"CHAPTER XVII: DR. SEWARD’S DIARY—continued\": 49,\n"," \"CHAPTER XVIII: DR. SEWARD’S DIARY\": 50,\n"," \"CHAPTER XIX: JONATHAN HARKER’S JOURNAL\": 51,\n"," \"CHAPTER XX: JONATHAN HARKER’S JOURNAL\": 52,\n"," \"CHAPTER XXI: DR. SEWARD’S DIARY\": 53,\n"," \"CHAPTER XXII: JONATHAN HARKER’S JOURNAL\": 54,\n"," \"CHAPTER XXIII: DR. SEWARD’S DIARY\": 55,\n"," \"CHAPTER XXIV: DR. SEWARD’S PHONOGRAPH DIARY, SPOKEN BY VAN HELSING\": 56,\n"," \"CHAPTER XXV: DR. SEWARD’S DIARY\": 57,\n"," \"CHAPTER XXVI: DR. SEWARD’S DIARY\": 58,\n"," \"CHAPTER XXVII: MINA HARKER’S JOURNAL\": 59\n","}\n","D_dr_chapter = {v:k for (k,v) in D_dr_chapter.items()}\n","\n","dr_master = [item.metadata['master'] for item in dracula_docs]\n","dr_book_idx = [item.metadata['book_idx'] for item in dracula_docs]\n","dr_book = [\"Dracula\" for i in dr_book_idx]\n","dr_chapter_idx = [item.metadata['chapter_idx'] for item in dracula_docs]\n","dr_chapter = [D_dr_chapter[item] for item in dr_chapter_idx]\n","dr_content = [item.page_content for item in dracula_docs]\n","dr_author = [\"Bram Stoker\" for item in dr_content]"],"metadata":{"id":"apuBhnl4YfIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["D_rp_chapter = {\n","    60: \"Book I\",\n","    61: \"Book II\",\n","    62: \"Book III\",\n","    63: \"Book IV\",\n","    64: \"Book V\",\n","    65: \"Book VI\",\n","    66: \"Book VII\",\n","    67: \"Book VIII\",\n","    68: \"Book IX\",\n","    69: \"Book X\"\n","}\n","\n","rp_master = [item.metadata['master'] for item in republic_docs]\n","rp_book_idx = [item.metadata['book_idx'] for item in republic_docs]\n","rp_book = [\"Republic\" for i in rp_book_idx]\n","rp_chapter_idx = [item.metadata['chapter_idx'] for item in republic_docs]\n","rp_chapter = [D_rp_chapter[item] for item in rp_chapter_idx]\n","rp_content = [item.page_content for item in republic_docs]\n","rp_author = [\"Plato\" for item in rp_content]"],"metadata":{"id":"xPy2Lpy4dRAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["master = ul_master + db_master + dr_master + rp_master\n","book_idx = ul_book_idx + db_book_idx + dr_book_idx + rp_book_idx\n","book = ul_book + db_book + dr_book + rp_book\n","chapter_idx = ul_chapter_idx + db_chapter_idx + dr_chapter_idx + rp_chapter_idx\n","chapter = ul_chapter + db_chapter + dr_chapter + rp_chapter\n","author = ul_author + db_author + dr_author + rp_author\n","content = ul_content + db_content + dr_content + rp_content"],"metadata":{"id":"OXPzXU3biEZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.DataFrame(\n","    {\n","        \"master\": master,\n","        \"book_idx\": book_idx,\n","        \"book\": book,\n","        \"chapter_idx\": chapter_idx,\n","        \"chapter\": chapter,\n","        \"author\": author,\n","        \"content\": content\n","    }\n",")"],"metadata":{"id":"2V6iuZnEm0OL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_meta(docs, name, data):\n","  for i in range(len(docs)):\n","    docs[i].metadata[name] = data[i]\n","  return docs\n"],"metadata":{"id":"HZZ8rmbHnwBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ulysses_docs\n","dubliners_docs\n","dracula_docs\n","republic_docs\n","\n","\n","\n","book chapter author"],"metadata":{"id":"xxiTmjXgo-fc"}},{"cell_type":"code","source":["fields = [\"book\", \"chapter\", \"author\"]\n","datas = [ul_book, ul_chapter, ul_author]\n","for i in range(3):\n","  ulysses_docs = add_meta(ulysses_docs,fields[i],datas[i])"],"metadata":{"id":"f6BGBrwsneng"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fields = [\"book\", \"chapter\", \"author\"]\n","datas = [db_book, db_chapter, db_author]\n","for i in range(3):\n","  dubliners_docs = add_meta(dubliners_docs,fields[i],datas[i])"],"metadata":{"id":"7F9m_TAZqsbp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fields = [\"book\", \"chapter\", \"author\"]\n","datas = [dr_book, dr_chapter, dr_author]\n","for i in range(3):\n","  dracula_docs = add_meta(dracula_docs,fields[i],datas[i])"],"metadata":{"id":"-7quN9cTqs2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fields = [\"book\", \"chapter\", \"author\"]\n","datas = [rp_book, rp_chapter, rp_author]\n","for i in range(3):\n","  republic_docs = add_meta(republic_docs,fields[i],datas[i])"],"metadata":{"id":"pHOgIRIFqs5V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["docs = ulysses_docs + dubliners_docs + dracula_docs + republic_docs"],"metadata":{"id":"9PdWxteUrGSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.reset_index()"],"metadata":{"id":"hiGc_OlR2P6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inds = list(df['index'])\n","for i in range(len(inds)):\n","  docs[i].metadata['index'] = inds[i]\n"],"metadata":{"id":"h1Co_Amc2iNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def integrity():\n","  ind = np.random.choice(df.shape[0])\n","  df_point = df.loc[ind]\n","  df_vals = [df_point['index'], df_point['master'], df_point['book'], df_point['book_idx'], df_point['chapter'], df_point['chapter_idx'], df_point['author']]\n","  dm = docs[ind].metadata\n","  doc_vals = [dm['index'], dm['master'], dm['book'], dm['book_idx'], dm['chapter'], dm['chapter_idx'], dm['author']]\n","  print(\"\\n ################### \\n\")\n","  print('DataFrame:', df_vals[0], df_vals[1], df_vals[2], df_vals[3], df_vals[4], df_vals[5], df_vals[6])\n","  print('---------------')\n","  print('Document:', doc_vals[0], doc_vals[1], doc_vals[2], doc_vals[3], doc_vals[4], doc_vals[5], )\n","  if df_vals == doc_vals:\n","    print('\\n meta match')\n","  else:\n","    print('\\n ooops!!!')\n","  print('\\n --------------- \\n')\n","  df_cont = df_point['content']\n","  doc_cont = docs[ind].page_content\n","  print('Dataframe:', df_cont)\n","  print('---------------')\n","  print('Document:', doc_cont)\n","  if df_cont == doc_cont:\n","    print('\\n content match\\n')\n","  else:\n","    print('\\n oops\\n')\n","\n","  result = (df_vals == doc_vals) and (df_cont == doc_cont)\n","  print(f'\\n ___ \\nFinal Result: {result}')\n","  return result"],"metadata":{"id":"Sine8BKKrQvc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = []\n","for i in range(10):\n","  test.append(integrity())\n","print(f'\\n ***** \\nMeta Result {all(test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56Ac7E_Drpd1","executionInfo":{"status":"ok","timestamp":1728469019792,"user_tz":-120,"elapsed":412,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"74b05f3e-4f82-4201-a9b1-a7afff9665b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," ################### \n","\n","DataFrame: Dubliners Dubliners 3 THE SISTERS 18 Joyce\n","---------------\n","Document: Dubliners Dubliners 3 THE SISTERS 18 Joyce\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: His face was very truculent, grey and massive, with black cavernous nostrils and circled by a scanty white fur. There was a heavy odour in the room—the flowers.   We blessed ourselves and came away. In the little room downstairs we found Eliza seated in his arm-chair in state.\n","---------------\n","Document: His face was very truculent, grey and massive, with black cavernous nostrils and circled by a scanty white fur. There was a heavy odour in the room—the flowers.   We blessed ourselves and came away. In the little room downstairs we found Eliza seated in his arm-chair in state.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Dubliners Dubliners 3 THE DEAD 32 Joyce\n","---------------\n","Document: Dubliners Dubliners 3 THE DEAD 32 Joyce\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: after the death of their brother Pat, had left the house in Stoney Batter and taken Mary Jane, their only niece, to live with them in the dark gaunt house on Usher’s Island, the upper part of which they had rented from Mr Fulham, the corn-factor on the ground floor. That was a good thirty years ago if it was a day.\n","---------------\n","Document: after the death of their brother Pat, had left the house in Stoney Batter and taken Mary Jane, their only niece, to live with them in the dark gaunt house on Usher’s Island, the upper part of which they had rented from Mr Fulham, the corn-factor on the ground floor. That was a good thirty years ago if it was a day.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Ulysses Odyssey 1 Aeolus 6 Joyce\n","---------------\n","Document: Ulysses Odyssey 1 Aeolus 6 Joyce\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: We mustn’t be led away by words, by sounds of words. We think of Rome, imperial, imperious, imperative.   He extended elocutionary arms from frayed stained shirtcuffs, pausing:   —What was their civilisation? Vast, I allow: but vile. Cloacae: sewers.\n","---------------\n","Document: We mustn’t be led away by words, by sounds of words. We think of Rome, imperial, imperious, imperative.   He extended elocutionary arms from frayed stained shirtcuffs, pausing:   —What was their civilisation? Vast, I allow: but vile. Cloacae: sewers.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Ulysses Odyssey 1 Calypso 3 Joyce\n","---------------\n","Document: Ulysses Odyssey 1 Calypso 3 Joyce\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: Everyone says I am quite the belle in my new tam. I got mummy’s lovely box of creams and am writing. They are lovely. I am getting on swimming in the photo business now. Mr Coghlan took one of me and Mrs. Will send when developed. We did great biz yesterday.\n","---------------\n","Document: Everyone says I am quite the belle in my new tam. I got mummy’s lovely box of creams and am writing. They are lovely. I am getting on swimming in the photo business now. Mr Coghlan took one of me and Mrs. Will send when developed. We did great biz yesterday.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Dracula Dracula 4 CHAPTER XVII: DR. SEWARD’S DIARY—continued 49 Bram Stoker\n","---------------\n","Document: Dracula Dracula 4 CHAPTER XVII: DR. SEWARD’S DIARY—continued 49 Bram Stoker\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: On my affording an opportunity, through the medium of the currency of the realm, of the allaying, at a later period, this beneficial evil, one of the men remarked:— “That ’ere ’ouse, guv’nor, is the rummiest I ever was in. Blyme! but it ain’t been touched sence a hundred years.\n","---------------\n","Document: On my affording an opportunity, through the medium of the currency of the realm, of the allaying, at a later period, this beneficial evil, one of the men remarked:— “That ’ere ’ouse, guv’nor, is the rummiest I ever was in. Blyme! but it ain’t been touched sence a hundred years.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Ulysses Nostos 2 Penelope 17 Joyce\n","---------------\n","Document: Ulysses Nostos 2 Penelope 17 Joyce\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: it everything was whatyoucallit moustache had he he said hed come back Lord its\n","---------------\n","Document: it everything was whatyoucallit moustache had he he said hed come back Lord its\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Ulysses Nostos 2 Ithaca 16 Joyce\n","---------------\n","Document: Ulysses Nostos 2 Ithaca 16 Joyce\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: For if my master he did hear He’d make it a sorry ball.”  She took him by the lilywhite hand And led him along the hall Until she led him to a room Where none could hear him call.  She took a penknife out of her pocket And cut off his little head. And now he’ll play his ball no more For he lies among the dead.\n","---------------\n","Document: For if my master he did hear He’d make it a sorry ball.”  She took him by the lilywhite hand And led him along the hall Until she led him to a room Where none could hear him call.  She took a penknife out of her pocket And cut off his little head. And now he’ll play his ball no more For he lies among the dead.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Dracula Dracula 4 CHAPTER I: JONATHAN HARKER’S JOURNAL 33 Bram Stoker\n","---------------\n","Document: Dracula Dracula 4 CHAPTER I: JONATHAN HARKER’S JOURNAL 33 Bram Stoker\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: I had only a couple of glasses of this, and nothing else. When I got on the coach the driver had not taken his seat, and I saw him talking with the landlady.\n","---------------\n","Document: I had only a couple of glasses of this, and nothing else. When I got on the coach the driver had not taken his seat, and I saw him talking with the landlady.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Dracula Dracula 4 CHAPTER V: LETTER FROM MISS MINA MURRAY TO MISS LUCY WESTENRA 37 Bram Stoker\n","---------------\n","Document: Dracula Dracula 4 CHAPTER V: LETTER FROM MISS MINA MURRAY TO MISS LUCY WESTENRA 37 Bram Stoker\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: Men like women, certainly their wives, to be quite as fair as they are; and women, I am afraid, are not always quite as fair as they should be. Well, my dear, number One came just before lunch. I told you of him, Dr. John Seward, the lunatic-asylum man, with the strong jaw and the good forehead.\n","---------------\n","Document: Men like women, certainly their wives, to be quite as fair as they are; and women, I am afraid, are not always quite as fair as they should be. Well, my dear, number One came just before lunch. I told you of him, Dr. John Seward, the lunatic-asylum man, with the strong jaw and the good forehead.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ################### \n","\n","DataFrame: Dubliners Dubliners 3 GRACE 31 Joyce\n","---------------\n","Document: Dubliners Dubliners 3 GRACE 31 Joyce\n","\n"," meta match\n","\n"," --------------- \n","\n","Dataframe: I forget now what.... O yes, it was on the Pope, the late Pope. I remember it well. Upon my word it was magnificent, the style of the oratory. And his voice! God! hadn’t he a voice! The Prisoner of the Vatican, he called him.\n","---------------\n","Document: I forget now what.... O yes, it was on the Pope, the late Pope. I remember it well. Upon my word it was magnificent, the style of the oratory. And his voice! God! hadn’t he a voice! The Prisoner of the Vatican, he called him.\n","\n"," content match\n","\n","\n"," ___ \n","Final Result: True\n","\n"," ***** \n","Meta Result True\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Subset/Save:}$\n"],"metadata":{"id":"mUuijWZHydU3"}},{"cell_type":"code","source":["np.random.seed(0)\n","train_inds = np.random.choice(df.shape[0], 12000, replace = False)\n","other_inds = set(range(df.shape[0])) - set(train_inds)\n","dev_inds = np.random.choice(list(other_inds), 964, replace = False)\n","test_inds = np.array(list(other_inds - set(dev_inds)))"],"metadata":{"id":"QjEv1fI3yguW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_inds[:5])\n","print(len(train_inds))\n","print(dev_inds[:5])\n","print(len(dev_inds))\n","print(test_inds[:5])\n","print(len(test_inds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wH4Cm3eiyPOF","executionInfo":{"status":"ok","timestamp":1728470418209,"user_tz":-120,"elapsed":311,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f1043029-9be0-4237-bae4-f56eb96a9da5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 8114  4951  4629 11556 12262]\n","12000\n","[3781 2532  662 2352 7128]\n","964\n","[   0 2051 4108 2068 6167]\n","1000\n"]}]},{"cell_type":"code","source":["df_train = df.loc[train_inds]\n","df_dev = df.loc[dev_inds]\n","df_test = df.loc[test_inds]\n","docs_train = [docs[i] for i in train_inds]\n","docs_dev = [docs[i] for i in dev_inds]\n","docs_test = [docs[i] for i in test_inds]"],"metadata":{"id":"6Jk79J9G3Y47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(set(df_train['index'] + df_dev['index'] + df_test['index']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0O8x9IIs33GA","executionInfo":{"status":"ok","timestamp":1728470965644,"user_tz":-120,"elapsed":307,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"c34f5561-bb8b-4736-911d-5168a3ed6076"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13964"]},"metadata":{},"execution_count":245}]},{"cell_type":"code","source":["all_inds = set()\n","for item in docs_train:\n","  all_inds.add(item.metadata['index'])\n","for item in docs_dev:\n","  all_inds.add(item.metadata['index'])\n","for item in docs_test:\n","  all_inds.add(item.metadata['index'])"],"metadata":{"id":"xUIhdh5n4Kii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(set(all_inds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoWEcCL45-ww","executionInfo":{"status":"ok","timestamp":1728471113311,"user_tz":-120,"elapsed":6,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"7a6bc4c7-cb89-4c70-c1a4-030261eb0ecb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13964"]},"metadata":{},"execution_count":251}]},{"cell_type":"code","source":["training = [item.metadata['index'] for item in docs_train]\n","training == list(df_train['index'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6oTZ9NX4TXx","executionInfo":{"status":"ok","timestamp":1728471225494,"user_tz":-120,"elapsed":319,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"2be004ca-c767-44b2-af1c-c85d08a91e71"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":254}]},{"cell_type":"code","source":["dev = [item.metadata['index'] for item in docs_dev]\n","dev == list(df_dev['index'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvqfJmYG6dsV","executionInfo":{"status":"ok","timestamp":1728471256064,"user_tz":-120,"elapsed":342,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"2e383b85-f5c1-4e84-e59f-01f012952429"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":258}]},{"cell_type":"code","source":["test = [item.metadata['index'] for item in docs_test]\n","test == list(df_test['index'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZXTNFlU44Lf","executionInfo":{"status":"ok","timestamp":1728471293029,"user_tz":-120,"elapsed":10,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"ea62cb7c-21ae-4952-b466-c5279c4e0033"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":259}]},{"cell_type":"code","source":["df_train.to_pickle('class/datasets/df_train')\n","df_dev.to_pickle('class/datasets/df_dev')\n","df_test.to_pickle('class/datasets/df_test')"],"metadata":{"id":"GQuE7_ed6vQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install dill"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCpaEJIw7pRn","executionInfo":{"status":"ok","timestamp":1728471673418,"user_tz":-120,"elapsed":4223,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"bebfd1c4-9cbe-40f6-f3b3-b8edb46b3f5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dill\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.9\n"]}]},{"cell_type":"code","source":["import dill"],"metadata":{"id":"-MUKbU2_7urF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_langchain_docs(docs, filename):\n","    \"\"\"Save a list of Langchain Documents to a .dill file.\"\"\"\n","    with open(filename, 'wb') as f:\n","        dill.dump(docs, f)\n","    print(f\"Documents saved to {filename}\")"],"metadata":{"id":"2ORiHZ3h8ML4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_langchain_docs(filename):\n","    \"\"\"Load a list of Langchain Documents from a .dill file.\"\"\"\n","    with open(filename, 'rb') as f:\n","        docs = dill.load(f)\n","    print(f\"Documents loaded from {filename}\")\n","    return docs"],"metadata":{"id":"r5nE5x3b8VPc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_langchain_docs(docs_train, \"class/datasets/docs_train\")\n","save_langchain_docs(docs_dev, \"class/datasets/docs_dev\")\n","save_langchain_docs(docs_test, \"class/datasets/docs_test\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_VQWUH98eyG","executionInfo":{"status":"ok","timestamp":1728471834520,"user_tz":-120,"elapsed":2049,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"38038b4e-d19a-408f-8d09-69ad35235b11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents saved to class/datasets/docs_train\n","Documents saved to class/datasets/docs_dev\n","Documents saved to class/datasets/docs_test\n"]}]}]}