{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LrYfQxznCxd6fz-2tv9FVTWgGkFCIvW7","timestamp":1728976468780},{"file_id":"1wov8AsUCwvkyGrNQGI0uZIpqvfIe-JAl","timestamp":1728908209639}],"machine_shape":"hm","gpuType":"L4","toc_visible":true,"authorship_tag":"ABX9TyMovK5S/UKkYSIrf1qOY3rb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Text Classification - Vanilla Mixture of Experts (Hard, Pretrained)\n","\n","----"],"metadata":{"id":"7bm-QDtacSiP"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","* Preamble\n","* Admin - importing libraries\n","* Load - Loading our data from pandas\n","* Dataset - Create PyTorch Dataset\n","* Model - Create PyTorch Vanilla Model\n","* Helper - Training helper functions\n","* Training - Training Loop\n"],"metadata":{"id":"NuCuZ_BudQGl"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","This notebook creates a vanilla mixture of experts model. We pre train experts for each author, then build and train a hard MoE classifier with these experts. The weights of the experts are frozen during the MoE classifier."],"metadata":{"id":"xe8wi1XGdsYg"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin:}$"],"metadata":{"id":"i-a1PCObeWis"}},{"cell_type":"code","source":["from google.colab import drive"],"metadata":{"id":"J2nVP8EIeEQr","executionInfo":{"status":"ok","timestamp":1731052099448,"user_tz":-60,"elapsed":2,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive/'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_q0vrFD0eZve","executionInfo":{"status":"ok","timestamp":1731052126245,"user_tz":-60,"elapsed":24574,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"583019f9-6583-486c-aacc-0933652ac725"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install torch\n","!pip install dill"],"metadata":{"id":"ksCw2OLTeero","executionInfo":{"status":"ok","timestamp":1731052133071,"user_tz":-60,"elapsed":6833,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1LB8g7VfJ-Z","executionInfo":{"status":"ok","timestamp":1731052136612,"user_tz":-60,"elapsed":3547,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"d6709f24-e6c7-4583-93e6-a9a4ad404faf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Load:}$"],"metadata":{"id":"3ADkVfjYemwf"}},{"cell_type":"code","source":["import pandas as pd\n","path = \"class/datasets/\"\n","df_train = pd.read_pickle(path + \"df_train\")\n","df_dev = pd.read_pickle(path + \"df_dev\")\n","df_test = pd.read_pickle(path + \"df_test\")"],"metadata":{"id":"zqQLJhNvelrB","executionInfo":{"status":"ok","timestamp":1731052158941,"user_tz":-60,"elapsed":22341,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"C77mixZverHU","executionInfo":{"status":"ok","timestamp":1729053222472,"user_tz":-120,"elapsed":15,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"3bd31261-c081-4551-cfa6-049f42b10534"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       index     master  book_idx       book  chapter_idx  \\\n","8114    8114  Dubliners         3  Dubliners           31   \n","4951    4951    Ulysses         2     Nostos           15   \n","4629    4629    Ulysses         2     Nostos           15   \n","11556  11556    Dracula         4    Dracula           59   \n","12262  12262   Republic         5   Republic           62   \n","\n","                                    chapter       author  \\\n","8114                                  GRACE        Joyce   \n","4951                                Eumaeus        Joyce   \n","4629                                Eumaeus        Joyce   \n","11556  CHAPTER XXVII: MINA HARKER’S JOURNAL  Bram Stoker   \n","12262                              Book III        Plato   \n","\n","                                                 content  \\\n","8114   “Is it John of Tuam?”   “Are you sure of that ...   \n","4951   sibly there were several others. He personally...   \n","4629   Stephen, who was trying his dead best to yawn ...   \n","11556  Now to the historical, for as Madam Mina write...   \n","12262  The harmonies which you mean are the mixed or ...   \n","\n","                                       vanilla_embedding  \n","8114   [-0.012913608, -0.026916211, 0.0023321153, -0....  \n","4951   [-0.019626686, -0.035692617, -0.034875672, 0.0...  \n","4629   [0.015934143, -0.0034991587, 0.0035751674, 0.0...  \n","11556  [-4.009433e-05, -0.0041142944, 0.026873538, -0...  \n","12262  [0.0048890463, -0.0060007297, 0.0054147574, -0...  "],"text/html":["\n","  <div id=\"df-ce20c37a-d7e5-41da-9ea6-c45ef78057be\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>master</th>\n","      <th>book_idx</th>\n","      <th>book</th>\n","      <th>chapter_idx</th>\n","      <th>chapter</th>\n","      <th>author</th>\n","      <th>content</th>\n","      <th>vanilla_embedding</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8114</th>\n","      <td>8114</td>\n","      <td>Dubliners</td>\n","      <td>3</td>\n","      <td>Dubliners</td>\n","      <td>31</td>\n","      <td>GRACE</td>\n","      <td>Joyce</td>\n","      <td>“Is it John of Tuam?”   “Are you sure of that ...</td>\n","      <td>[-0.012913608, -0.026916211, 0.0023321153, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>4951</th>\n","      <td>4951</td>\n","      <td>Ulysses</td>\n","      <td>2</td>\n","      <td>Nostos</td>\n","      <td>15</td>\n","      <td>Eumaeus</td>\n","      <td>Joyce</td>\n","      <td>sibly there were several others. He personally...</td>\n","      <td>[-0.019626686, -0.035692617, -0.034875672, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>4629</th>\n","      <td>4629</td>\n","      <td>Ulysses</td>\n","      <td>2</td>\n","      <td>Nostos</td>\n","      <td>15</td>\n","      <td>Eumaeus</td>\n","      <td>Joyce</td>\n","      <td>Stephen, who was trying his dead best to yawn ...</td>\n","      <td>[0.015934143, -0.0034991587, 0.0035751674, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>11556</th>\n","      <td>11556</td>\n","      <td>Dracula</td>\n","      <td>4</td>\n","      <td>Dracula</td>\n","      <td>59</td>\n","      <td>CHAPTER XXVII: MINA HARKER’S JOURNAL</td>\n","      <td>Bram Stoker</td>\n","      <td>Now to the historical, for as Madam Mina write...</td>\n","      <td>[-4.009433e-05, -0.0041142944, 0.026873538, -0...</td>\n","    </tr>\n","    <tr>\n","      <th>12262</th>\n","      <td>12262</td>\n","      <td>Republic</td>\n","      <td>5</td>\n","      <td>Republic</td>\n","      <td>62</td>\n","      <td>Book III</td>\n","      <td>Plato</td>\n","      <td>The harmonies which you mean are the mixed or ...</td>\n","      <td>[0.0048890463, -0.0060007297, 0.0054147574, -0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce20c37a-d7e5-41da-9ea6-c45ef78057be')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ce20c37a-d7e5-41da-9ea6-c45ef78057be button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ce20c37a-d7e5-41da-9ea6-c45ef78057be');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0d91fe3f-061d-4418-af37-ab82e9a450b8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d91fe3f-061d-4418-af37-ab82e9a450b8')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0d91fe3f-061d-4418-af37-ab82e9a450b8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_train","summary":"{\n  \"name\": \"df_train\",\n  \"rows\": 12000,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4034,\n        \"min\": 1,\n        \"max\": 13963,\n        \"num_unique_values\": 12000,\n        \"samples\": [\n          12943,\n          6855,\n          3959\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"master\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Ulysses\",\n          \"Republic\",\n          \"Dubliners\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"book_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"book\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Dubliners\",\n          \"Nostos\",\n          \"Telemachia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chapter_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 0,\n        \"max\": 69,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          11,\n          31,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chapter\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"Cyclops\",\n          \"GRACE\",\n          \"Book IX\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Joyce\",\n          \"Bram Stoker\",\n          \"Plato\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12000,\n        \"samples\": [\n          \"The sailors are quarrelling with one another about the steering\\u2014every one is of opinion that he has a right to steer, though he has never learned the art of navigation and cannot tell who taught him or when he learned, and will further assert that it cannot be taught, and they are ready to cut in pieces any one who says the contrary. They throng about the captain,\",\n          \"I often felt I wanted to kiss him all over also his lovely young cock there so\",\n          \"taim and Netaim begat Le Hirsch and Le Hirsch begat Jesurum and Jesurum begat Ma\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vanilla_embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### $\\color{red}{Subset:}$\n","\n","subset the training and the dev DF into Joyce / Stoker / Plato"],"metadata":{"id":"pXqw-GBtDe4Q"}},{"cell_type":"code","source":["df_train_joyce = df_train[df_train['book_idx'].isin([0,1,2,3])]\n","df_train_stoker = df_train[df_train['book_idx'] == 4]\n","df_train_plato = df_train[df_train['book_idx'] == 5]\n","\n","df_dev_joyce = df_dev[df_dev['book_idx'].isin([0,1,2,3])]\n","df_dev_stoker = df_dev[df_dev['book_idx'] == 4]\n","df_dev_plato = df_dev[df_dev['book_idx'] == 5]"],"metadata":{"id":"If3aI5m1DucW","executionInfo":{"status":"ok","timestamp":1731052158941,"user_tz":-60,"elapsed":12,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Dataset:}$"],"metadata":{"id":"cRp9eBQ4f_Dq"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"hT3DSEhJaFzN","executionInfo":{"status":"ok","timestamp":1731052158941,"user_tz":-60,"elapsed":10,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"outputs":[],"source":["train_embeddings = [torch.tensor(array) for array in df_train['vanilla_embedding']]\n","train_x = torch.stack(train_embeddings).to(device)\n","\n","dev_embeddings = [torch.tensor(array) for array in df_dev['vanilla_embedding']]\n","dev_x = torch.stack(dev_embeddings).to(device)\n","\n","test_embeddings = [torch.tensor(array) for array in df_test['vanilla_embedding']]\n","test_x = torch.stack(test_embeddings).to(device)"]},{"cell_type":"code","source":["# train_y = torch.LongTensor(list(df_train['book_idx'])).to(device)\n","# dev_y = torch.LongTensor(list(df_dev['book_idx'])).to(device)\n","# test_y = torch.LongTensor(list(df_test['book_idx'])).to(device)\n","\n","train_y = torch.LongTensor(list(df_train['chapter_idx'])).to(device)\n","dev_y = torch.LongTensor(list(df_dev['chapter_idx'])).to(device)\n","test_y = torch.LongTensor(list(df_test['chapter_idx'])).to(device)"],"metadata":{"id":"Y6wLXwgZgNoz","executionInfo":{"status":"ok","timestamp":1731052158942,"user_tz":-60,"elapsed":11,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","# assuming already tensors, allready on device\n","class VanillaDataset(Dataset):\n","  \"\"\"Dataset maker\"\"\"\n","\n","  def __init__(self, x, y):\n","    self.x = x\n","    self.y = y\n","\n","  def __getitem__(self,index):\n","    x = self.x[index]\n","    y = self.y[index]\n","\n","    return x, y\n","\n","  def __len__(self):\n","    return len(self.y)\n"],"metadata":{"id":"Tv26LKgEgPJY","executionInfo":{"status":"ok","timestamp":1731052158942,"user_tz":-60,"elapsed":10,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_dataset = VanillaDataset(train_x, train_y)\n","dev_dataset = VanillaDataset(dev_x, dev_y)\n","test_dataset = VanillaDataset(test_x, test_y)"],"metadata":{"id":"fzMdq10amXSA","executionInfo":{"status":"ok","timestamp":1731052158942,"user_tz":-60,"elapsed":9,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_dataset[0][0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1acpLl58muUM","executionInfo":{"status":"ok","timestamp":1731052158942,"user_tz":-60,"elapsed":9,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"2a36da40-0a07-4906-eba5-1d38093fed7e"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([768])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### $\\color{red}{Joyce:}$"],"metadata":{"id":"DwF3iZvEFn6c"}},{"cell_type":"code","source":["# get X\n","train_embeddings_joyce = [torch.tensor(array) for array in df_train_joyce['vanilla_embedding']]\n","train_x_joyce = torch.stack(train_embeddings_joyce).to(device)\n","\n","dev_embeddings_joyce = [torch.tensor(array) for array in df_dev_joyce['vanilla_embedding']]\n","dev_x_joyce = torch.stack(dev_embeddings_joyce).to(device)\n","\n","# get y\n","train_y_joyce = torch.LongTensor(list(df_train_joyce['chapter_idx'])).to(device)\n","dev_y_joyce = torch.LongTensor(list(df_dev_joyce['chapter_idx'])).to(device)\n","\n","\n","# create pytorch set\n","train_dataset_joyce = VanillaDataset(train_x_joyce, train_y_joyce)\n","dev_dataset_joyce = VanillaDataset(dev_x_joyce, dev_y_joyce)"],"metadata":{"collapsed":true,"id":"TDjAJpCFFqJv","executionInfo":{"status":"ok","timestamp":1731052158942,"user_tz":-60,"elapsed":7,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### $\\color{red}{Stoker:}$"],"metadata":{"id":"0usF2NL4FqgH"}},{"cell_type":"code","source":["# get X\n","train_embeddings_stoker = [torch.tensor(array) for array in df_train_stoker['vanilla_embedding']]\n","train_x_stoker = torch.stack(train_embeddings_stoker).to(device)\n","\n","dev_embeddings_stoker = [torch.tensor(array) for array in df_dev_stoker['vanilla_embedding']]\n","dev_x_stoker = torch.stack(dev_embeddings_stoker).to(device)\n","\n","# get y\n","train_y_stoker = torch.LongTensor(list(df_train_stoker['chapter_idx'])).to(device)\n","dev_y_stoker = torch.LongTensor(list(df_dev_stoker['chapter_idx'])).to(device)\n","\n","\n","# create pytorch set\n","train_dataset_stoker = VanillaDataset(train_x_stoker, train_y_stoker)\n","dev_dataset_stoker = VanillaDataset(dev_x_stoker, dev_y_stoker)"],"metadata":{"id":"8PlYVPDPFsZ2","executionInfo":{"status":"ok","timestamp":1731052031636,"user_tz":-60,"elapsed":585,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### $\\color{red}{Plato:}$"],"metadata":{"id":"dvX7TfoyFs_I"}},{"cell_type":"code","source":["# get X\n","train_embeddings_plato = [torch.tensor(array) for array in df_train_plato['vanilla_embedding']]\n","train_x_plato = torch.stack(train_embeddings_plato).to(device)\n","\n","dev_embeddings_plato = [torch.tensor(array) for array in df_dev_plato['vanilla_embedding']]\n","dev_x_plato = torch.stack(dev_embeddings_plato).to(device)\n","\n","# get y\n","train_y_plato = torch.LongTensor(list(df_train_plato['chapter_idx'])).to(device)\n","dev_y_plato = torch.LongTensor(list(df_dev_plato['chapter_idx'])).to(device)\n","\n","\n","# create pytorch set\n","train_dataset_plato = VanillaDataset(train_x_plato, train_y_plato)\n","dev_dataset_plato = VanillaDataset(dev_x_plato, dev_y_plato)"],"metadata":{"id":"xfYQXFTpFw9G","executionInfo":{"status":"ok","timestamp":1731052033565,"user_tz":-60,"elapsed":250,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Expert-Model:}$"],"metadata":{"id":"V2dl9alJo_8E"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DenseBlock(nn.Module):\n","    def __init__(self, input_size, output_size, dropout_rate):\n","        super(DenseBlock, self).__init__()\n","        self.linear = nn.Linear(input_size, output_size)\n","        self.batch_norm = nn.BatchNorm1d(output_size)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","        x = self.batch_norm(x)\n","        x = self.activation(x)\n","        x = self.dropout(x)\n","        return x\n","\n","class FeedForwardExpert(nn.Module):\n","    def __init__(self, output_size, dropout_rate):\n","        super(FeedForwardExpert, self).__init__()\n","        self.output_size = output_size\n","\n","        # Define the dense blocks\n","        self.block1 = DenseBlock(768, 400, dropout_rate)\n","        self.block2 = DenseBlock(400, 200, dropout_rate)\n","        self.final_layer = nn.Linear(200, self.output_size)\n","\n","        self.initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.block1(x)  # Bx768 -> Bx400\n","        x = self.block2(x)  # Bx400 -> Bx50\n","        x = self.final_layer(x)  # Bx50 -> Bx6\n","        return x\n","\n","    def initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n"],"metadata":{"id":"_5-8HvuHHdsn","executionInfo":{"status":"ok","timestamp":1731052161605,"user_tz":-60,"elapsed":494,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model = FeedForwardExpert(70,.1)\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","count_parameters(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zy7CL_wiH0i9","executionInfo":{"status":"ok","timestamp":1731052161605,"user_tz":-60,"elapsed":12,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"851c1f15-eea0-404e-f8e8-29718b02d3df"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["403070"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## $\\color{blue}{Helper:}$"],"metadata":{"id":"IehbMcagpoTr"}},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    # argmax to get predicted classes\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # count correct\n","    correct = (predicted == labels).sum().item()\n","\n","    # get average\n","    acc = correct / labels.size(0)  # Total number of samples\n","    return acc"],"metadata":{"id":"ZL4yGRfdtIVA","executionInfo":{"status":"ok","timestamp":1731052161605,"user_tz":-60,"elapsed":10,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def train(model, train_loader, criterion, optimizer):\n","    model.train()\n","    epoch_train_losses = []\n","    epoch_train_accuracy = []\n","\n","    for batch_idx, (x, y) in enumerate(train_loader):\n","\n","        optimizer.zero_grad()\n","\n","        out = model(x)\n","        train_loss = criterion(out, y)\n","        train_accuracy = accuracy(out, y)\n","\n","        epoch_train_losses.append(train_loss.item())\n","        epoch_train_accuracy.append(train_accuracy)\n","\n","        # Backpropagation and optimization\n","        train_loss.backward()\n","        optimizer.step()\n","\n","    return np.mean(epoch_train_losses), np.mean(epoch_train_accuracy)"],"metadata":{"id":"0p4GswPcz6di","executionInfo":{"status":"ok","timestamp":1731052161606,"user_tz":-60,"elapsed":10,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def validate(model, dev_loader, criterion):\n","    model.eval()\n","    epoch_dev_losses = []\n","    epoch_dev_accuracy = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (x, y) in enumerate(dev_loader):\n","            out = model(x)\n","\n","            dev_loss = criterion(out, y)\n","            dev_accuracy = accuracy(out, y)\n","\n","            epoch_dev_losses.append(dev_loss.item())\n","            epoch_dev_accuracy.append(dev_accuracy)\n","\n","    return np.mean(epoch_dev_losses), np.mean(epoch_dev_accuracy)"],"metadata":{"id":"ujWAOFw30Uh7","executionInfo":{"status":"ok","timestamp":1731052161606,"user_tz":-60,"elapsed":10,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from collections import namedtuple\n","Stats = namedtuple('Stats', [\n","    'train_loss',\n","    'train_accuracy',\n","    'dev_loss',\n","    'dev_accuracy',\n","    'epoch',\n","    'bs',\n","    'lr',\n","    'alpha',\n","    'max_accuracy'\n","])"],"metadata":{"id":"gBvkpcO7Ktyn","executionInfo":{"status":"ok","timestamp":1731052161606,"user_tz":-60,"elapsed":8,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def gen_config(lr_low, lr_high, alpha_low, alpha_high, b_size, b_step):\n","  bs_list = [b_size - b_step, b_size, b_size + b_step]\n","  bs = int(2**np.random.choice(bs_list))\n","  lr = round(10**float(np.random.uniform(lr_low,lr_high)),6)\n","  alpha = round(10**float(np.random.uniform(alpha_low,alpha_high)),6)\n","  return lr, alpha, bs"],"metadata":{"id":"zLMDuEADZFav","executionInfo":{"status":"ok","timestamp":1731052161606,"user_tz":-60,"elapsed":8,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def gen_ranges( lr, lr_range, alpha, alpha_range, b_size, iteration):\n","\n","  lr_center = lr\n","  lr_low = lr_center - lr_range/2\n","  lr_high = lr_center + lr_range/2\n","  lr_diff = lr_high - lr_low\n","\n","  alpha_center = alpha\n","  alpha_low = alpha_center - alpha_range/2\n","  alpha_high = alpha_center + alpha_range/2\n","  alpha_diff = alpha_high - alpha_low\n","\n","  b_step = 2 - iteration\n","\n","  return (lr_low, lr_high, alpha_low, alpha_high, b_size, b_step)"],"metadata":{"id":"g8RmMZjYZFoS","executionInfo":{"status":"ok","timestamp":1731052161606,"user_tz":-60,"elapsed":8,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def search_stats(results):\n","  best_stats = None\n","  max_dev_accuracy = 0\n","  for i in range(len(results)):\n","    acc = results[i].dev_accuracy\n","    if acc > max_dev_accuracy:\n","      best_stats = results[i]\n","      max_dev_accuracy = acc\n","  return best_stats"],"metadata":{"id":"NFYizCESbNC1","executionInfo":{"status":"ok","timestamp":1731052161606,"user_tz":-60,"elapsed":7,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Training:}$"],"metadata":{"id":"c6l1T-Uip7FG"}},{"cell_type":"code","source":["def tv_run(epochs, model, train_data, dev_data, bs, lr, alpha, max_accuracy, path, verbose = 0):\n","  \"\"\"\n","  Runs a training setup\n","  verbose == 1 - print model results\n","  verbose == 2 -> print epoch and model results\n","  \"\"\"\n","  # Set up new model\n","  model = model.to(device)\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=alpha)\n","\n","  # Prepare data loaders\n","  train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n","  dev_loader = DataLoader(dev_data, batch_size=bs)\n","\n","  # Hold epoch stats\n","  train_losses = []\n","  train_accuracy = []\n","  dev_losses = []\n","  dev_accuracy = []\n","  epoch_holder = []\n","\n","  # Break if no improvement\n","  current_best = 0\n","  no_improvement = 0\n","\n","\n","  # Run epochs\n","  for epoch in range(epochs):\n","\n","    # break out of epochs\n","    if no_improvement >= 5:\n","      break\n","\n","    # call training and validation functions\n","    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n","    dev_loss, dev_acc = validate(model, dev_loader, criterion)\n","\n","    # Store epoch stats\n","    train_losses.append(train_loss)\n","    train_accuracy.append(train_acc)\n","    dev_losses.append(dev_loss)\n","    dev_accuracy.append(dev_acc)\n","    epoch_holder.append(epoch + 1)\n","\n","    # check for improvement\n","    if dev_acc > current_best:\n","      current_best = dev_acc\n","      no_improvement = 0\n","    else:\n","      no_improvement += 1\n","\n","    # save best model\n","    if dev_acc > max_accuracy:\n","      torch.save(model.state_dict(), path)\n","      max_accuracy = dev_acc\n","\n","    # optionally print epoch results\n","    if verbose == 2:\n","      print(f'\\n --------- \\nEpoch: {epoch + 1}\\n')\n","      print(f'Epoch {epoch + 1} train loss: {train_loss:.4f}')\n","      print(f'Epoch {epoch + 1} train accuracy: {train_acc:.4f}')\n","      print(f'Epoch {epoch + 1} dev loss: {dev_loss:.4f}')\n","      print(f'Epoch {epoch + 1} dev accuracy: {dev_acc:.4f}')\n","\n","  # save best results\n","  max_ind = np.argmax(dev_accuracy)\n","\n","  stats = Stats(\n","      train_losses[max_ind],\n","      train_accuracy[max_ind],\n","      dev_losses[max_ind],\n","      dev_accuracy[max_ind],\n","      epoch_holder[max_ind],\n","      bs, lr, alpha,\n","      max_accuracy\n","  )\n","\n","  # optionally print model results\n","  if verbose in [1,2]:\n","    print('\\n ######## \\n')\n","    print(f'bs:{stats.bs}, lr:{stats.lr}, alpha:{stats.alpha} @ epoch {stats.epoch}.')\n","    print(f'TL:{stats.train_loss}, TA:{stats.train_accuracy}.')\n","    print(f'DL:{stats.dev_loss}, DA:{stats.dev_accuracy}')\n","\n","  return stats"],"metadata":{"collapsed":true,"id":"QolAzAGlrqKb","executionInfo":{"status":"ok","timestamp":1731052161606,"user_tz":-60,"elapsed":7,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["### $\\color{red}{Joyce:}$"],"metadata":{"id":"kemWXPr1L6td"}},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs = 40\n","max_accuracy = 0\n","path = \"class/models/vanilla_moe_joyce_expert.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -5\n","lr_high = -1\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -1\n","alpha_range = alpha_high - alpha_low\n","\n","b_size = 5\n","b_step = 2\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(3):\n","  # debug\n","  print(f'round: {i}')\n","  print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print(f'b_size{b_size}')\n","  print(f'b_step{b_step}')\n","  print('max', max_accuracy)\n","\n","  for j in range(27):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha, bs = gen_config(lr_low, lr_high, alpha_low, alpha_high, b_size, b_step)\n","\n","    # define model\n","    model = FeedForwardExpert(70,.1) # model with dropout\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, train_dataset_joyce, dev_dataset_joyce, bs, lr, alpha, max_accuracy, path, verbose = 0)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  bs = np.log2(stats.bs)\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range, bs, i + 1)\n","  lr_low, lr_high, alpha_low, alpha_high, b_size, b_step = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tRW09rVZOUu","executionInfo":{"status":"ok","timestamp":1728980193235,"user_tz":-120,"elapsed":669197,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"5b381825-710f-4ac6-fb16-b9f3f6af63f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["round: 0\n","lr_low-5, lr_high-1, lr_range4\n","alpha_low-5, lr_high-1, lr_range4\n","b_size5\n","b_step2\n","max 0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","Stats(train_loss=0.09397064116701745, train_accuracy=0.9803444910352805, dev_loss=1.1934909105300904, dev_accuracy=0.6994318181818182, epoch=6, bs=128, lr=0.002514, alpha=0.004611, max_accuracy=0.6994318181818182)\n","round: 1\n","lr_low-3.2663013933167275, lr_high-1.9329680599833945, lr_range1.333333333333333\n","alpha_low-3.002871544447259, lr_high-1.669538211113926, lr_range1.333333333333333\n","b_size7.0\n","b_step1\n","max 0.6994318181818182\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","Stats(train_loss=0.019017700971872137, train_accuracy=0.9994517543859649, dev_loss=1.2071991205215453, dev_accuracy=0.6995738636363636, epoch=16, bs=128, lr=0.000862, alpha=0.002853, max_accuracy=0.6995738636363636)\n","round: 2\n","lr_low-3.2867149563975095, lr_high-2.842270511953065, lr_range0.44444444444444464\n","alpha_low-2.766920450565146, lr_high-2.3224760061207013, lr_range0.44444444444444464\n","b_size7.0\n","b_step0\n","max 0.6995738636363636\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","Stats(train_loss=0.0973889995039555, train_accuracy=0.9944060873337189, dev_loss=1.0868995666503907, dev_accuracy=0.7098011363636363, epoch=11, bs=128, lr=0.000556, alpha=0.003216, max_accuracy=0.7098011363636363)\n"]}]},{"cell_type":"markdown","source":["### $\\color{red}{Stoker:}$"],"metadata":{"id":"et_YX5wiMF_x"}},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs = 40\n","max_accuracy = 0\n","path = \"class/models/vanilla_moe_stoker_expert.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -5\n","lr_high = -1\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -1\n","alpha_range = alpha_high - alpha_low\n","\n","b_size = 5\n","b_step = 2\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(3):\n","  # debug\n","  print(f'round: {i}')\n","  print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print(f'b_size{b_size}')\n","  print(f'b_step{b_step}')\n","  print('max', max_accuracy)\n","\n","  for j in range(27):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha, bs = gen_config(lr_low, lr_high, alpha_low, alpha_high, b_size, b_step)\n","\n","    # define model\n","    model = FeedForwardExpert(70,.1) # model with dropout\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, train_dataset_stoker, dev_dataset_stoker, bs, lr, alpha, max_accuracy, path, verbose = 0)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  bs = np.log2(stats.bs)\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range, bs, i + 1)\n","  lr_low, lr_high, alpha_low, alpha_high, b_size, b_step = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6wMosKIMH5U","executionInfo":{"status":"ok","timestamp":1729008753133,"user_tz":-120,"elapsed":684696,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"575e1b7f-cc7d-4bd2-e55f-44e6392702dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["round: 0\n","lr_low-5, lr_high-1, lr_range4\n","alpha_low-5, lr_high-1, lr_range4\n","b_size5\n","b_step2\n","max 0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","Stats(train_loss=0.8481314434223093, train_accuracy=0.7277559867877788, dev_loss=2.4918209676231657, dev_accuracy=0.42410714285714285, epoch=8, bs=8, lr=0.002578, alpha=4.4e-05, max_accuracy=0.42410714285714285)\n","round: 1\n","lr_low-3.2553837536492822, lr_high-1.9220504203159492, lr_range1.333333333333333\n","alpha_low-5.02321399018048, lr_high-3.6898806568471465, lr_range1.3333333333333335\n","b_size3.0\n","b_step1\n","max 0.42410714285714285\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","Stats(train_loss=0.8030121854231881, train_accuracy=0.7488645747316268, dev_loss=2.2395271488598416, dev_accuracy=0.4330357142857143, epoch=7, bs=8, lr=0.000988, alpha=0.000153, max_accuracy=0.4330357142857143)\n","round: 2\n","lr_low-3.2274652776345945, lr_high-2.78302083319015, lr_range0.44444444444444464\n","alpha_low-4.037530791404623, lr_high-3.593086346960179, lr_range0.4444444444444442\n","b_size3.0\n","b_step0\n","max 0.4330357142857143\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","Stats(train_loss=0.7031475892128972, train_accuracy=0.7845788604459125, dev_loss=2.2934842152254924, dev_accuracy=0.45535714285714285, epoch=8, bs=8, lr=0.001117, alpha=0.000106, max_accuracy=0.45535714285714285)\n"]}]},{"cell_type":"markdown","source":["### $\\color{red}{Plato:}$"],"metadata":{"id":"qKJTjtCiMQnj"}},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs = 40\n","max_accuracy = 0\n","path = \"class/models/vanilla_moe_plato_expert.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -5\n","lr_high = -1\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -1\n","alpha_range = alpha_high - alpha_low\n","\n","b_size = 5\n","b_step = 2\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(3):\n","  # debug\n","  print(f'round: {i}')\n","  print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print(f'b_size{b_size}')\n","  print(f'b_step{b_step}')\n","  print('max', max_accuracy)\n","\n","  for j in range(27):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha, bs = gen_config(lr_low, lr_high, alpha_low, alpha_high, b_size, b_step)\n","\n","    # define model\n","    model = FeedForwardExpert(70,.1) # model with dropout\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, train_dataset_plato, dev_dataset_plato, bs, lr, alpha, max_accuracy, path, verbose = 0)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  bs = np.log2(stats.bs)\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range, bs, i + 1)\n","  lr_low, lr_high, alpha_low, alpha_high, b_size, b_step = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDumstL1MXqq","executionInfo":{"status":"ok","timestamp":1728981262018,"user_tz":-120,"elapsed":151073,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"ab4952d5-3a2b-44f7-c7d7-82069a1531dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["round: 0\n","lr_low-5, lr_high-1, lr_range4\n","alpha_low-5, lr_high-1, lr_range4\n","b_size5\n","b_step2\n","max 0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","Stats(train_loss=0.024264571722596884, train_accuracy=0.99951171875, dev_loss=1.5249077677726746, dev_accuracy=0.6223958333333333, epoch=8, bs=128, lr=0.00371, alpha=0.000111, max_accuracy=0.6223958333333333)\n","round: 1\n","lr_low-3.0972927570516204, lr_high-1.7639594237182874, lr_range1.333333333333333\n","alpha_low-4.621343687880009, lr_high-3.288010354546676, lr_range1.3333333333333335\n","b_size7.0\n","b_step1\n","max 0.6223958333333333\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","Stats(train_loss=0.024264571722596884, train_accuracy=0.99951171875, dev_loss=1.5249077677726746, dev_accuracy=0.6223958333333333, epoch=8, bs=128, lr=0.00371, alpha=0.000111, max_accuracy=0.6223958333333333)\n","round: 2\n","lr_low-2.6528483126071762, lr_high-2.2084038681627316, lr_range0.44444444444444464\n","alpha_low-4.176899243435565, lr_high-3.73245479899112, lr_range0.44444444444444464\n","b_size7.0\n","b_step0\n","max 0.6223958333333333\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","Stats(train_loss=0.024264571722596884, train_accuracy=0.99951171875, dev_loss=1.5249077677726746, dev_accuracy=0.6223958333333333, epoch=8, bs=128, lr=0.00371, alpha=0.000111, max_accuracy=0.6223958333333333)\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{MoE-Model:}$"],"metadata":{"id":"IvZ0tFcGMnoG"}},{"cell_type":"code","source":["# load joyce expert\n","model_joyce = FeedForwardExpert(70, dropout_rate=0.1)\n","path_joyce = \"class/models/vanilla_moe_joyce_expert.pt\"\n","model_joyce.load_state_dict(torch.load(path_joyce))\n","\n","# load stoker expert\n","model_stoker = FeedForwardExpert(70, dropout_rate=0.1)\n","path_stoker = \"class/models/vanilla_moe_stoker_expert.pt\"\n","model_stoker.load_state_dict(torch.load(path_stoker))\n","\n","# load plato model\n","model_plato = FeedForwardExpert(70, dropout_rate=0.1)\n","path_plato = \"class/models/vanilla_moe_plato_expert.pt\"\n","model_plato.load_state_dict(torch.load(path_plato))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66AK_JOMPHhO","executionInfo":{"status":"ok","timestamp":1731053850998,"user_tz":-60,"elapsed":8,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"cea8a3ea-8801-4987-eab5-ded45fffd7f6"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-34-955ec92fd47c>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_joyce.load_state_dict(torch.load(path_joyce))\n","<ipython-input-34-955ec92fd47c>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_stoker.load_state_dict(torch.load(path_stoker))\n","<ipython-input-34-955ec92fd47c>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_plato.load_state_dict(torch.load(path_plato))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# freeze joyce expert\n","for param in model_joyce.parameters():\n","  param.requires_grad = False\n","\n","# freeze stoker expert\n","for param in model_stoker.parameters():\n","  param.requires_grad = False\n","\n","# freeze plato\n","for param in model_stoker.parameters():\n","  param.requires_grad = False"],"metadata":{"id":"3Cy7VO0oQbRr","executionInfo":{"status":"error","timestamp":1729053148296,"user_tz":-120,"elapsed":6,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"d099ec77-826b-41ed-be71-702b66593009"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model_joyce' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c0cb2fe9c4fc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# freeze joyce expert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_joyce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# freeze stoker expert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_joyce' is not defined"]}]},{"cell_type":"code","source":["\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Router(nn.Module):\n","    def __init__(self, num_experts, temperature=2):\n","        super().__init__()\n","        self.num_experts = num_experts\n","        self.fc1 = nn.Linear(768, 128)\n","        self.fc2 = nn.Linear(128, self.num_experts)\n","        self.temperature = temperature\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x) / self.temperature\n","\n","        if self.temperature > 1:\n","          self.temperature *= 0.99\n","        else:\n","          self.temperature = 1\n","\n","        return F.softmax(x, dim=-1)\n","\n","class MoE(nn.Module):\n","    def __init__(self, expert_joyce, expert_stoker, expert_plato, temperature=1.2, num_experts=3, output_size=70, dropout_rate=0.11, top_k=1):\n","        super().__init__()\n","        self.num_experts = num_experts\n","        self.dropout_rate = dropout_rate\n","        self.k = top_k\n","        self.output_size = output_size\n","        self.temperature = temperature\n","        self.experts = nn.ModuleList([expert_joyce, expert_stoker, expert_plato])\n","        self.router = Router(self.num_experts)\n","\n","    def forward(self, x):\n","        # Get routing weights\n","        routing_weights = self.router(x)  # Shape (bs, num_experts)\n","\n","        # Sample k experts according to the routing weights\n","        # Ensure sum of weights is 1 (needed condition for probabilities)\n","        routing_weights = F.normalize(routing_weights, p=1, dim=-1)\n","\n","        # Get the indices of experts based on probabilities\n","        topk_indices = torch.multinomial(routing_weights, num_samples=self.k, replacement=False)\n","        topk_vals = routing_weights.gather(1, topk_indices)  # Get the probability values for selected experts\n","        topk_vals_sum = topk_vals.sum(dim=1, keepdim=True)\n","        topk_vals_normalized = topk_vals / topk_vals_sum  # Normalize values for each sample\n","\n","        # Initialize an output tensor with zeros\n","        outputs = torch.zeros(x.size(0), self.output_size, device=x.device)  # Shape (bs, c)\n","\n","        # Iterate through the experts\n","        for i in range(self.k):\n","            expert_indices = topk_indices[:, i]\n","\n","            for j in range(self.num_experts):\n","                # Check if the expert j is selected in current batch\n","                expert_mask = (expert_indices == j)\n","                if expert_mask.any():\n","                    expert_weight = topk_vals_normalized[:, i].view(-1, 1) * expert_mask.float().view(-1, 1)\n","\n","                    # Get output from the expert\n","                    expert_output = self.experts[j](x)  # Shape (bs, c)\n","\n","                    # Multiply the output by the corresponding weights and sum up\n","                    outputs += expert_output * expert_weight  # Shape (bs, c)\n","\n","        return outputs"],"metadata":{"id":"JaPP2hP__ImF","executionInfo":{"status":"ok","timestamp":1731052495152,"user_tz":-60,"elapsed":1063,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Main Admin\n","\"\"\"\n","epochs = 40\n","max_accuracy = 0\n","path = \"class/models/vanilla_moe_hard_pre_free.pt\"\n","results = []\n","\n","\"\"\"\n","init random search\n","lr [10^-5 - 10^-1]\n","alpha [10^-5 - 10^-1]\n","bs [8, 32, 128]\n","\"\"\"\n","lr_low = -5\n","lr_high = -1\n","lr_range = lr_high - lr_low\n","\n","alpha_low = -5\n","alpha_high = -1\n","alpha_range = alpha_high - alpha_low\n","\n","b_size = 5\n","b_step = 2\n","\n","count = 0\n","\n","\"\"\"\n","Hyperparameter Search\n","\"\"\"\n","\n","for i in range(3):\n","  # debug\n","  print(f'round: {i}')\n","  print(f'lr_low{lr_low}, lr_high{lr_high}, lr_range{lr_range}')\n","  print(f'alpha_low{alpha_low}, lr_high{alpha_high}, lr_range{alpha_range}')\n","  print(f'b_size{b_size}')\n","  print(f'b_step{b_step}')\n","  print('max', max_accuracy)\n","\n","  for j in range(27):\n","    count += 1\n","    print(count)\n","\n","    # get config\n","    lr, alpha, bs = gen_config(lr_low, lr_high, alpha_low, alpha_high, b_size, b_step)\n","\n","    # define model\n","    model = MoE(model_joyce, model_stoker, model_plato, temperature=1.2) # model with dropout\n","    model = model.to(device)\n","\n","    # run training\n","    res = tv_run(epochs, model, train_dataset, dev_dataset, bs, lr, alpha, max_accuracy, path, verbose = 0)\n","    max_accuracy = res.max_accuracy\n","    results.append(res)\n","\n","  # get best result of the round or even so far\n","  stats = search_stats(results)\n","\n","\n","  print(stats) # debug\n","\n","  # reconfigure the new hypers\n","  lr = np.log10(stats.lr)\n","  lr_range = lr_range / 3\n","\n","  alpha = np.log10(stats.alpha)\n","  alpha_range = alpha_range / 3\n","\n","  bs = np.log2(stats.bs)\n","\n","  config = gen_ranges(lr, lr_range, alpha, alpha_range, bs, i + 1)\n","  lr_low, lr_high, alpha_low, alpha_high, b_size, b_step = config\n","  lr_range = lr_high - lr_low\n","  alpha_range = alpha_high - alpha_low"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6xON3tyTkI_","executionInfo":{"status":"ok","timestamp":1729056134554,"user_tz":-120,"elapsed":2816769,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"1b5a10d6-6e12-41c7-9a7d-22bc1fa920eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["round: 0\n","lr_low-5, lr_high-1, lr_range4\n","alpha_low-5, lr_high-1, lr_range4\n","b_size5\n","b_step2\n","max 0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","Stats(train_loss=0.348825791100661, train_accuracy=0.9011666666666667, dev_loss=1.74107817680605, dev_accuracy=0.5574596774193549, epoch=6, bs=32, lr=0.000723, alpha=0.080893, max_accuracy=0.5574596774193549)\n","round: 1\n","lr_low-3.8075283693721356, lr_high-2.4741950360388025, lr_range1.333333333333333\n","alpha_low-1.75875572469474, lr_high-0.4254223913614067, lr_range1.3333333333333335\n","b_size5.0\n","b_step1\n","max 0.5574596774193549\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","Stats(train_loss=0.348825791100661, train_accuracy=0.9011666666666667, dev_loss=1.74107817680605, dev_accuracy=0.5574596774193549, epoch=6, bs=32, lr=0.000723, alpha=0.080893, max_accuracy=0.5574596774193549)\n","round: 2\n","lr_low-3.3630839249276914, lr_high-2.9186394804832467, lr_range0.44444444444444464\n","alpha_low-1.3143112802502956, lr_high-0.8698668358058511, lr_range0.44444444444444453\n","b_size5.0\n","b_step0\n","max 0.5574596774193549\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","Stats(train_loss=0.348825791100661, train_accuracy=0.9011666666666667, dev_loss=1.74107817680605, dev_accuracy=0.5574596774193549, epoch=6, bs=32, lr=0.000723, alpha=0.080893, max_accuracy=0.5574596774193549)\n"]}]},{"cell_type":"code","source":["import dill\n","def save_results_to_file(namedtuples, filename):\n","    \"\"\"Saves a list of namedtuples to a specified file using dill.\"\"\"\n","    with open(filename, 'wb') as f:\n","        dill.dump(namedtuples, f)\n","\n","def load_results_from_file(filename):\n","    \"\"\"Loads a list of namedtuples from a specified file using dill.\"\"\"\n","    with open(filename, 'rb') as f:\n","        return dill.load(f)"],"metadata":{"id":"0UVgjxKJ1v28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = 'class/results/'\n","save_results_to_file(results, path + 'vanilla_moe_hard_pre_free.pk')"],"metadata":{"id":"VS3U8EZP2niP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["57.4 fixed\n","with free experts let's see\n"],"metadata":{"id":"Lg-KSxbFmGwL"}}]}