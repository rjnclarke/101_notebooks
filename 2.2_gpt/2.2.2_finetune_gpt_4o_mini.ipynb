{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BAf6BnJwsIxUPyUzR9LZzRnDDCIR6clS","timestamp":1732272000064},{"file_id":"1Gr7WHUidodr44VZvvAqCXa-t7ZaKv2UR","timestamp":1717746596069}],"authorship_tag":"ABX9TyPtskChsUMK9kgrKX1pin2u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text Classification - Finetune GPT-4o-mini\n","\n","\n","---\n","\n","---"],"metadata":{"id":"4ZNd27xZQpCv"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","1.   Admin\n","2.   Data\n","4.   Prompt\n","5.   JSONL\n","6.   Check Datasets\n","7. Create OpenAI Finetuned Model"],"metadata":{"id":"BKrinVbAQ0gg"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","Uploading dataset to OpenAI Finetuning GPT-4o-mini."],"metadata":{"id":"GmhwWOTBmgou"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"lcifqi4flhn3"}},{"cell_type":"code","source":["%%capture\n","!pip install tiktoken openai cohere"],"metadata":{"id":"PBXp0BKqh7qy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install dill"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXymZzeur8Uv","executionInfo":{"status":"ok","timestamp":1732272639107,"user_tz":-60,"elapsed":3637,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"51da7319-c85d-4e97-dfb3-8bd3d22f61e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dill\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112.6/119.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.9\n"]}]},{"cell_type":"code","source":["import openai\n","import re\n","import pandas as pd\n","import requests\n","import json\n","from google.colab import drive\n","from google.colab import userdata\n","from collections import defaultdict\n","import os\n","import dill"],"metadata":{"id":"0WYqYZRiQ3bv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data to a string"],"metadata":{"id":"CaaxjILYlpe-"}},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haNmVkgUQ6d9","executionInfo":{"status":"ok","timestamp":1732274745043,"user_tz":-60,"elapsed":18147,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"bd6a758e-ed7a-412d-e3bb-70924c7ce156"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","path = \"class/datasets/\" # modify path\n","df_train = pd.read_pickle(path + \"df_train\")\n","df_dev = pd.read_pickle(path + \"df_dev\")\n","df_test = pd.read_pickle(path + \"df_test\")"],"metadata":{"id":"-2d-jro_txhv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# $\\color{blue}{JSONL}$\n","\n","----\n","\n","The API requires data to be uploaded in this format.\n","The payload requires a system message (definition of LLM role), a user message (input prompt), and an assistant messages (expected output)."],"metadata":{"id":"D8wzTZyPSeud"}},{"cell_type":"code","source":["system_message = \"\"\"\n","You are required to complete the NLP task of text classification.\n","You must provide a single word response from one of the possible categories.\n","You will provide a one and only one response which must be from the given categories in the categories list.\"\"\".strip()\n","\n","prompt = \"\"\"####Task:\n","The task is to predict the the correct book from the categories below given a short input of text.\n","Telemachia, Odyssey, Nostros are from James Joyce's Ulysses, and Dubliners was also written by Joyce. Dracula is by Bram Stoker, and Republic is by Plato.\n","After reading the Input select a single response from the Categories.\n","\n","####Categories:\n","Telemachia\n","Odyssey\n","Nostros\n","Dubliners\n","Dracula\n","Republic\n","\n","###Input:\n","{}\n","\n","###Classification\n","\"\"\"\n","\n","def format_data(df):\n","  dataset = []\n","  for i in range(df.shape[0]):\n","    point = {\"messages\" : [{\"role\": \"system\" , \"content\" : system_message}]}\n","    point[\"messages\"].append({\"role\": \"user\", \"content\": prompt.format(df.loc[i]['content'])})\n","    point[\"messages\"].append({\"role\": \"assistant\", \"content\": df.loc[i]['book']})\n","    dataset.append(point)\n","  return dataset\n","\n","def save_to_jsonl(dataset, file_path):\n","  \"\"\"\n","  Convert dataset into jsonl.\n","\n","  Parameters\n","  ----------\n","  dataset : list\n","      List of dicts containing datapoint information.\n","  filepath: str\n","      File path to save to.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  with open(file_path,\"w\") as file:\n","    for data in dataset:\n","      json_line = json.dumps(data)\n","      file.write(json_line + '\\n')\n"],"metadata":{"id":"XWEHhA0Agd3u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### $\\color{red}{To-File}$\n"],"metadata":{"id":"RNxJ4RlJXi4E"}},{"cell_type":"code","source":["train_dataset = format_data(df_train)\n","dev_dataset = format_data(df_dev)\n","save_to_jsonl(train_dataset, \"class/datasets/train_openai_book_ft.jsonl\")\n","save_to_jsonl(dev_dataset, \"class/datasets/dev_openai_book_ft.jsonl\")"],"metadata":{"id":"WReTa-Ec-Dv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s67E2vm99HfX","executionInfo":{"status":"ok","timestamp":1732274949961,"user_tz":-60,"elapsed":294,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"05329d95-ebcc-4040-ed9e-d0457b96ecb5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'messages': [{'role': 'system',\n","   'content': 'You are required to complete the NLP task of text classification.\\nYou must provide a single word response from one of the possible categories.\\nYou will provide a one and only one response which must be from the given categories in the categories list.'},\n","  {'role': 'user',\n","   'content': \"####Task:\\nThe task is to predict the the correct book from the categories below given a short input of text. \\nTelemachia, Odyssey, Nostros are from James Joyce's Ulysses, and Dubliners was also written by Joyce. Dracula is by Bram Stoker, and Republic is by Plato. \\nAfter reading the Input select a single response from the Categories.\\n\\n####Categories:\\nTelemachia\\nOdyssey\\nNostros\\nDubliners\\nDracula\\nRepublic\\n\\n###Input: \\n“Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”   “John of Tuam,” repeated Mr Cunningham, “was the man.”   He drank and the other gentlemen followed his lead.\\n\\n###Classification\\n\"},\n","  {'role': 'assistant', 'content': 'Dubliners'}]}"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# $\\color{blue}{Check - Datasets}$"],"metadata":{"id":"QEQFS7qmZM7z"}},{"cell_type":"code","source":["# Get example\n","def message_check(file_path, ind):\n","  \"\"\"\n","  Check message from jsonl file.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to jsonl file.\n","  ind: int\n","      Required ind for checking.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  # Load the dataset\n","  with open(file_path, 'r', encoding='utf-8') as f:\n","      dataset = [json.loads(line) for line in f]\n","\n","  # Initial dataset stats\n","  print(\"Num examples:\", len(dataset))\n","  print(\"First example:\")\n","  for message in dataset[ind][\"messages\"]:\n","      print(message)"],"metadata":{"id":"fzKUNPiQZLxC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Format error checks\n","def check_errors(file_path):\n","  \"\"\"\n","  Check if there are any errors in file that will cause OpenAI training process to fail.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to the json file.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  with open(file_path, 'r', encoding='utf-8') as f:\n","    dataset = [json.loads(line) for line in f]\n","\n","  format_errors = defaultdict(int)\n","\n","  for ex in dataset:\n","      if not isinstance(ex, dict):\n","          format_errors[\"data_type\"] += 1\n","          continue\n","\n","      messages = ex.get(\"messages\", None)\n","      if not messages:\n","          format_errors[\"missing_messages_list\"] += 1\n","          continue\n","\n","      for message in messages:\n","          if \"role\" not in message or \"content\" not in message:\n","              format_errors[\"message_missing_key\"] += 1\n","\n","          if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n","              format_errors[\"message_unrecognized_key\"] += 1\n","\n","          if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n","              format_errors[\"unrecognized_role\"] += 1\n","\n","          content = message.get(\"content\", None)\n","          function_call = message.get(\"function_call\", None)\n","\n","          if (not content and not function_call) or not isinstance(content, str):\n","              format_errors[\"missing_content\"] += 1\n","\n","      if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","          format_errors[\"example_missing_assistant_message\"] += 1\n","\n","  if format_errors:\n","      print(\"Found errors:\")\n","      for k, v in format_errors.items():\n","          print(f\"{k}: {v}\")\n","  else:\n","      print(\"No errors found\")"],"metadata":{"id":"CMu7hKUKbZbZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["message_check(\"class/datasets/train_openai_book_ft.jsonl\",10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQA417Kbckyd","executionInfo":{"status":"ok","timestamp":1732274979031,"user_tz":-60,"elapsed":304,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"dec6a2f9-e9b5-4aea-e657-14e91deaebbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples: 12000\n","First example:\n","{'role': 'system', 'content': 'You are required to complete the NLP task of text classification.\\nYou must provide a single word response from one of the possible categories.\\nYou will provide a one and only one response which must be from the given categories in the categories list.'}\n","{'role': 'user', 'content': \"####Task:\\nThe task is to predict the the correct book from the categories below given a short input of text. \\nTelemachia, Odyssey, Nostros are from James Joyce's Ulysses, and Dubliners was also written by Joyce. Dracula is by Bram Stoker, and Republic is by Plato. \\nAfter reading the Input select a single response from the Categories.\\n\\n####Categories:\\nTelemachia\\nOdyssey\\nNostros\\nDubliners\\nDracula\\nRepublic\\n\\n###Input: \\nMight be still up. Call to the hospital to see. Hope she’s over. Long day I’ve had. Martha, the bath, funeral, house of Keyes, museum with those goddesses, Dedalus’ song. Then that bawler in Barney Kiernan’s. Got my own back there.\\n\\n###Classification\\n\"}\n","{'role': 'assistant', 'content': 'Odyssey'}\n"]}]},{"cell_type":"code","source":["check_errors(\"class/datasets/train_openai_book_ft.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LN_dq6WmRkyx","executionInfo":{"status":"ok","timestamp":1732275070792,"user_tz":-60,"elapsed":338,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"e543affa-ab99-4991-a792-533c865d0080"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No errors found\n"]}]},{"cell_type":"code","source":["check_errors(\"class/datasets/dev_openai_book_ft.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCfXe7RwRtlP","executionInfo":{"status":"ok","timestamp":1732275073742,"user_tz":-60,"elapsed":276,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"adb90e67-15c2-4c23-e5cc-2a4e2024a5e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No errors found\n"]}]},{"cell_type":"markdown","source":["# $\\color{blue}{Create-OpenAi-Finetuned-Model}$"],"metadata":{"id":"1N5bQtFd_xJp"}},{"cell_type":"markdown","source":["##### $\\color{red}{Load-File}$"],"metadata":{"id":"RWYOa1_TLBLF"}},{"cell_type":"code","source":["endpoint = \"https://api.openai.com/v1/files\" # endpoint for files\n","\n","key = userdata.get('OPENAI_API_KEY')\n","\n","headers = {'Authorization': f\"Bearer {key}\"}\n","\n","def upload_file(file_path, endpoint, headers):\n","  \"\"\"\n","  Upload a file to the OpenAI file system.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to the json file.\n","  endpoint : str\n","      Use 'https://api.openai.com/v1/files'.\n","  headers : dict\n","      Use {'Authorization': f\"Bearer {key}\"}.\n","\n","  Returns\n","  -------\n","  response : json\n","      Response from OpenAI confirming details of the upload.\n","  \"\"\"\n","  with open(file_path,'rb') as f:\n","    response = requests.post(endpoint, headers=headers, files={'file': f}, data={'purpose': 'fine-tune'})\n","  return response.json()"],"metadata":{"id":"B9ejjx6HEkoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file_response = upload_file(\"class/datasets/train_openai_book_ft.jsonl\", endpoint, headers)"],"metadata":{"id":"xACBUiufEkuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ie-dQl7jHgLr","executionInfo":{"status":"ok","timestamp":1732275096687,"user_tz":-60,"elapsed":314,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"056eda5b-aef7-421d-bba3-708102749489"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'file',\n"," 'id': 'file-YGu1oQ3iKOLlrt2rldNnQsFk',\n"," 'purpose': 'fine-tune',\n"," 'filename': 'train_openai_book_ft.jsonl',\n"," 'bytes': 13000841,\n"," 'created_at': 1732275093,\n"," 'status': 'processed',\n"," 'status_details': None}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["dev_file_response = upload_file(\"class/datasets/dev_openai_book_ft.jsonl\", endpoint, headers)"],"metadata":{"id":"ozvbGMS6CR80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_file_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTfL8dRrCpD8","executionInfo":{"status":"ok","timestamp":1732275107431,"user_tz":-60,"elapsed":231,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"064b97a2-2286-499d-d77f-102291db8c5b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'file',\n"," 'id': 'file-TkDHbJgzX5JpvhyGUVEeXzvO',\n"," 'purpose': 'fine-tune',\n"," 'filename': 'dev_openai_book_ft.jsonl',\n"," 'bytes': 1040084,\n"," 'created_at': 1732275104,\n"," 'status': 'processed',\n"," 'status_details': None}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["##### $\\color{red}{Create-Models}$"],"metadata":{"id":"N9C0ZLIfLR1x"}},{"cell_type":"code","source":["URL = \"https://api.openai.com/v1/fine_tuning/jobs\" # endpoint\n","\n","\n","headers = {\n","  \"Content-Type\": \"application/json\",\n","  \"Authorization\": f\"Bearer {key}\"\n","}"],"metadata":{"id":"bOK5fV4BCt4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["payload = {\n","  \"training_file\": train_file_response['id'],\n","  \"validation_file\": dev_file_response['id'],\n","  \"model\": \"gpt-4o-mini-2024-07-18\"\n","}\n","finetune_response = requests.post(URL, json=payload, headers=headers)\n","finetune_meta = json.loads(finetune_response.content)"],"metadata":{"id":"cd6PIWfmSZzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["finetune_meta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJ4saBldUE2r","executionInfo":{"status":"ok","timestamp":1732275142358,"user_tz":-60,"elapsed":350,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"b61d7bba-9d69-48fe-fd07-c4faf17e9d66"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'fine_tuning.job',\n"," 'id': 'ftjob-tInjl4yG1WbcwMgNQ4UkuKe4',\n"," 'model': 'gpt-4o-mini-2024-07-18',\n"," 'created_at': 1732275127,\n"," 'finished_at': None,\n"," 'fine_tuned_model': None,\n"," 'organization_id': 'org-4bBdSgsciB8iKzeJ61GgVdXt',\n"," 'result_files': [],\n"," 'status': 'validating_files',\n"," 'validation_file': 'file-TkDHbJgzX5JpvhyGUVEeXzvO',\n"," 'training_file': 'file-YGu1oQ3iKOLlrt2rldNnQsFk',\n"," 'hyperparameters': {'n_epochs': 'auto',\n","  'batch_size': 'auto',\n","  'learning_rate_multiplier': 'auto'},\n"," 'trained_tokens': None,\n"," 'error': {},\n"," 'user_provided_suffix': None,\n"," 'seed': 717072433,\n"," 'estimated_finish': None,\n"," 'integrations': []}"]},"metadata":{},"execution_count":28}]}]}