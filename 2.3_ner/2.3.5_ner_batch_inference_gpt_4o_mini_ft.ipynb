{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1npi3HO2M4saKme4a6Dh0BKMz3Bh-zZ22","timestamp":1733841373469},{"file_id":"1pSGOLwphVDHmnXtS3Fsnh1yDpjwAybN4","timestamp":1733494356620},{"file_id":"1BAf6BnJwsIxUPyUzR9LZzRnDDCIR6clS","timestamp":1732272000064},{"file_id":"1Gr7WHUidodr44VZvvAqCXa-t7ZaKv2UR","timestamp":1717746596069}],"collapsed_sections":["lcifqi4flhn3","CaaxjILYlpe-","D8wzTZyPSeud","QEQFS7qmZM7z","1N5bQtFd_xJp","RWYOa1_TLBLF","N9C0ZLIfLR1x"],"authorship_tag":"ABX9TyPZ3RPmyiX12Tv4j3rWKd/9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text Classification - NER Inference with GPT-4o-mini Finetuned\n","\n","\n","(Open AI batch API)\n","\n","---\n","\n","---"],"metadata":{"id":"4ZNd27xZQpCv"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","1.   Admin\n","2.   Data\n","3.   Prompt\n","3.   JSONL\n","4.   Check Datasets\n","5.   Create batch job\n"],"metadata":{"id":"BKrinVbAQ0gg"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","In this section we create a batch job with OpenAI to get preferential prices in exchange for a none instantaeous response. We get NER inferences for all the data.\n"],"metadata":{"id":"GmhwWOTBmgou"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"lcifqi4flhn3"}},{"cell_type":"code","source":["%%capture\n","!pip install tiktoken openai cohere"],"metadata":{"id":"aVyThQarxo_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"],"metadata":{"id":"ezcbqGyvx-eG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742481647301,"user_tz":-60,"elapsed":37449,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"4c33914d-1f83-4d34-9dad-0f4b54244605"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m351.8/351.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.9.0 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","google-genai 1.4.0 requires httpx<1.0.0dev,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["pip install dill"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXymZzeur8Uv","executionInfo":{"status":"ok","timestamp":1742481658012,"user_tz":-60,"elapsed":10700,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"73483693-6a69-4b17-d708-59fb48df782a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dill\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112.6/119.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.9\n"]}]},{"cell_type":"code","source":["import openai\n","import re\n","import pandas as pd\n","import requests\n","import json\n","from google.colab import drive\n","from google.colab import userdata\n","from collections import defaultdict\n","import os\n","import dill"],"metadata":{"id":"0WYqYZRiQ3bv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data to a string"],"metadata":{"id":"CaaxjILYlpe-"}},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haNmVkgUQ6d9","executionInfo":{"status":"ok","timestamp":1742481677667,"user_tz":-60,"elapsed":16929,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"3fab2783-a7cd-4055-a750-c7f4659d7098"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","path = 'class/datasets/'\n","df_train = pd.read_pickle(path + 'df_train_augmentation_ft')\n","df_dev = pd.read_pickle(path + 'df_dev_augmentation_ft')\n","df_test = pd.read_pickle(path + 'df_test_augmentation_ft')\n"],"metadata":{"id":"-2d-jro_txhv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_dev.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhJZZNFiVe9u","executionInfo":{"status":"ok","timestamp":1742481689609,"user_tz":-60,"elapsed":4,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"3a708abe-0313-4602-b5e4-db48134a5e24"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['master', 'book_idx', 'chapter_idx', 'content', 'vanilla_embedding.1',\n","       'direct_ft_augmented_embedding'],\n","      dtype='object')"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# $\\color{blue}{Prompt}$\n","\n","----\n","\n","The API requires data to be uploaded in this format.\n","The payload requires a system message (definition of LLM role), a user message (input prompt), and an assistant messages (expected output)."],"metadata":{"id":"D8wzTZyPSeud"}},{"cell_type":"code","source":["prompt = \"\"\"The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\n","The output should be identicle to the input with the exception of the Person and Location tags if required.\n","\n","###Examples\n","Input: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”\n","Output: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”\n","\n","Input: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","Output: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","\n","Input: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning.\n","Output: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning.\n","\n","**DON'T LABEL PRONOUNS AS PERSON**\n","\n","###Text\n","Input: {}\n","Output:\"\"\"\n","\n","\n","system_message = \"\"\"You are an excellent linguist.\"\"\"\n"],"metadata":{"id":"XWEHhA0Agd3u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n","\n","{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"],"metadata":{"id":"FGlwyqyECgHw"}},{"cell_type":"code","source":["def format_data(df, set):\n","  dataset = []\n","  for i in range(df.shape[0]):\n","    point = {\"custom_id\": set + str(i),\n","             \"method\": \"POST\",\n","             \"url\": \"/v1/chat/completions\",\n","             \"body\": {\"model\": \"ft:gpt-4o-mini-2024-07-18:personal::AbTiRIUJ\",\n","                      \"messages\": [{\"role\": \"system\" , \"content\" : system_message},\n","                                   {\"role\": \"user\" , \"content\" : prompt.format(df.loc[i]['content'])}\n","                      ]\n","             }\n","    }\n","\n","    dataset.append(point)\n","\n","  return dataset\n","\n","def save_to_jsonl(dataset, file_path):\n","  \"\"\"\n","  Convert dataset into jsonl.\n","\n","  Parameters\n","  ----------\n","  dataset : list\n","      List of dicts containing datapoint information.\n","  filepath: str\n","      File path to save to.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  with open(file_path,\"w\") as file:\n","    for data in dataset:\n","      json_line = json.dumps(data)\n","      file.write(json_line + '\\n')"],"metadata":{"id":"vmiwD7ihV4XE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### $\\color{red}{To-File}$\n"],"metadata":{"id":"RNxJ4RlJXi4E"}},{"cell_type":"code","source":["train_dataset = format_data(df_train, \"train\")\n","dev_dataset = format_data(df_dev, \"dev\")\n","test_dataset = format_data(df_test, \"test\")\n"],"metadata":{"id":"WReTa-Ec-Dv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-dmS4Bu2GOGb","executionInfo":{"status":"ok","timestamp":1742481779616,"user_tz":-60,"elapsed":15,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"d55ec712-5d09-4acb-e8d3-558b7491f4ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20474"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["save_to_jsonl(train_dataset, \"class/datasets/train_augmented_openai_ner_inf.jsonl\")\n","save_to_jsonl(dev_dataset, \"class/datasets/dev_augmented_openai_ner_inf.jsonl\")\n","save_to_jsonl(test_dataset, \"class/datasets/test_augmented_openai_ner_inf.jsonl\")"],"metadata":{"id":"Iv6p1oZdFY2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s67E2vm99HfX","executionInfo":{"status":"ok","timestamp":1742481818432,"user_tz":-60,"elapsed":7,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9bac2214-6277-4f96-8408-63dbd9e999ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'custom_id': 'train4',\n"," 'method': 'POST',\n"," 'url': '/v1/chat/completions',\n"," 'body': {'model': 'ft:gpt-4o-mini-2024-07-18:personal::AbTiRIUJ',\n","  'messages': [{'role': 'system', 'content': 'You are an excellent linguist.'},\n","   {'role': 'user',\n","    'content': \"The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\\nThe output should be identicle to the input with the exception of the Person and Location tags if required.\\n\\n###Examples\\nInput: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”\\nOutput: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”\\n\\nInput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\nOutput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\n\\nInput: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning.\\nOutput: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning.\\n\\n**DON'T LABEL PRONOUNS AS PERSON**\\n\\n###Text\\nInput: He peered sideways up and gave a long slow whistle of call, then paused awhile in rapt attention, his even white teeth glistening here and there with gold points. Chrysostomos. Two strong shrill whistles answered through the calm.   —Thanks, old chap, he cried briskly. That will do nicely. Switch off the current, will you?\\nOutput:\"}]}}"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# $\\color{blue}{Check - Datasets}$"],"metadata":{"id":"QEQFS7qmZM7z"}},{"cell_type":"code","source":["# Get example\n","def message_check(file_path, ind):\n","  \"\"\"\n","  Check message from jsonl file.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to jsonl file.\n","  ind: int\n","      Required ind for checking.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  # Load the dataset\n","  with open(file_path, 'r', encoding='utf-8') as f:\n","      dataset = [json.loads(line) for line in f]\n","\n","  # Initial dataset stats\n","  print(\"Num examples:\", len(dataset))\n","  print(\"First example:\")\n","  for message in dataset[ind]['body'][\"messages\"]:\n","      print(message)"],"metadata":{"id":"fzKUNPiQZLxC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["message_check(\"class/datasets/train_augmented_openai_ner_inf.jsonl\",5050)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQA417Kbckyd","executionInfo":{"status":"ok","timestamp":1742481845151,"user_tz":-60,"elapsed":847,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"a497dba6-e5dd-4ef4-ef0b-562f8da542b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples: 20474\n","First example:\n","{'role': 'system', 'content': 'You are an excellent linguist.'}\n","{'role': 'user', 'content': \"The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\\nThe output should be identicle to the input with the exception of the Person and Location tags if required.\\n\\n###Examples\\nInput: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”\\nOutput: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”\\n\\nInput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\nOutput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\n\\nInput: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning.\\nOutput: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning.\\n\\n**DON'T LABEL PRONOUNS AS PERSON**\\n\\n###Text\\nInput: it brought its bad luck with it like an opal or pearl still it must have been pure 18 car\\nOutput:\"}\n"]}]},{"cell_type":"code","source":["# Format error checks\n","def check_errors(file_path):\n","  \"\"\"\n","  Check if there are any errors in file that will cause OpenAI training process to fail.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to the json file.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  with open(file_path, 'r', encoding='utf-8') as f:\n","    dataset = [json.loads(line) for line in f]\n","\n","  format_errors = defaultdict(int)\n","\n","  for ex in dataset:\n","      if not isinstance(ex, dict):\n","          format_errors[\"data_type\"] += 1\n","          continue\n","      ex_body = ex.get(\"body\", None)\n","      messages = ex_body.get(\"messages\", None)\n","      if not messages:\n","          format_errors[\"missing_messages_list\"] += 1\n","          continue\n","\n","      for message in messages:\n","          if \"role\" not in message or \"content\" not in message:\n","              format_errors[\"message_missing_key\"] += 1\n","\n","          if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n","              format_errors[\"message_unrecognized_key\"] += 1\n","\n","          if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n","              format_errors[\"unrecognized_role\"] += 1\n","\n","          content = message.get(\"content\", None)\n","          function_call = message.get(\"function_call\", None)\n","\n","          if (not content and not function_call) or not isinstance(content, str):\n","              format_errors[\"missing_content\"] += 1\n","\n","\n","  if format_errors:\n","      print(\"Found errors:\")\n","      for k, v in format_errors.items():\n","          print(f\"{k}: {v}\")\n","  else:\n","      print(\"No errors found\")"],"metadata":{"id":"LN_dq6WmRkyx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["check_errors(\"class/datasets/train_augmented_openai_ner_inf.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCfXe7RwRtlP","executionInfo":{"status":"ok","timestamp":1742481888655,"user_tz":-60,"elapsed":621,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"7120bdd5-c16e-4edc-8cc6-eeaa7417b014"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No errors found\n"]}]},{"cell_type":"markdown","source":["# $\\color{blue}{Create-Batch-Job}$"],"metadata":{"id":"1N5bQtFd_xJp"}},{"cell_type":"markdown","source":["##### $\\color{red}{Load-File}$"],"metadata":{"id":"RWYOa1_TLBLF"}},{"cell_type":"code","source":["endpoint = \"https://api.openai.com/v1/files\" # endpoint for files\n","\n","key = userdata.get('OPENAI_API_KEY')\n","\n","headers = {'Authorization': f\"Bearer {key}\"}\n","\n","def upload_file(file_path, endpoint, headers):\n","  \"\"\"\n","  Upload a file to the OpenAI file system.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to the json file.\n","  endpoint : str\n","      Use 'https://api.openai.com/v1/files'.\n","  headers : dict\n","      Use {'Authorization': f\"Bearer {key}\"}.\n","\n","  Returns\n","  -------\n","  response : json\n","      Response from OpenAI confirming details of the upload.\n","  \"\"\"\n","  with open(file_path,'rb') as f:\n","    response = requests.post(endpoint, headers=headers, files={'file': f}, data={'purpose': 'batch'})\n","  return response.json()"],"metadata":{"id":"B9ejjx6HEkoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file_response = upload_file(\"class/datasets/train_augmented_openai_ner_inf.jsonl\", endpoint, headers)\n","dev_file_response = upload_file(\"class/datasets/dev_augmented_openai_ner_inf.jsonl\", endpoint, headers)\n","test_file_response = upload_file(\"class/datasets/test_augmented_openai_ner_inf.jsonl\", endpoint, headers)"],"metadata":{"id":"xACBUiufEkuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ie-dQl7jHgLr","executionInfo":{"status":"ok","timestamp":1742482194907,"user_tz":-60,"elapsed":18,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"cbaf93d6-d23d-4138-b7f9-615c7b9723a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'file',\n"," 'id': 'file-8q4ANgJKt7bfyoo5XqGgby',\n"," 'purpose': 'batch',\n"," 'filename': 'train_augmented_openai_ner_inf.jsonl',\n"," 'bytes': 44377016,\n"," 'created_at': 1742482189,\n"," 'expires_at': None,\n"," 'status': 'processed',\n"," 'status_details': None}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["dev_file_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MqcnSGOQJsa3","executionInfo":{"status":"ok","timestamp":1742482198057,"user_tz":-60,"elapsed":24,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"a38ddd79-ef28-472a-b7b1-118c24683fc9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'file',\n"," 'id': 'file-MNQD39tDEDjDVaMjNBW8wi',\n"," 'purpose': 'batch',\n"," 'filename': 'dev_augmented_openai_ner_inf.jsonl',\n"," 'bytes': 1616290,\n"," 'created_at': 1742482190,\n"," 'expires_at': None,\n"," 'status': 'processed',\n"," 'status_details': None}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["test_file_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TPXXqgTJvuN","executionInfo":{"status":"ok","timestamp":1742482200436,"user_tz":-60,"elapsed":16,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"0347a9ce-298a-4a7f-d8dd-c7c6f8eb86f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'file',\n"," 'id': 'file-DLe5iMf1HJAJBPSPNeEK1x',\n"," 'purpose': 'batch',\n"," 'filename': 'test_augmented_openai_ner_inf.jsonl',\n"," 'bytes': 1087735,\n"," 'created_at': 1742482191,\n"," 'expires_at': None,\n"," 'status': 'processed',\n"," 'status_details': None}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["train_file_response = {'id':'file-8q4ANgJKt7bfyoo5XqGgby'}\n","dev_file_response = {'id': 'file-MNQD39tDEDjDVaMjNBW8wi'}\n","test_file_response = {'id':'file-DLe5iMf1HJAJBPSPNeEK1x'}"],"metadata":{"id":"i9tRrz3dSWnK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### $\\color{red}{Create-Jobs}$"],"metadata":{"id":"N9C0ZLIfLR1x"}},{"cell_type":"code","source":["from openai import OpenAI\n","client = OpenAI(api_key= userdata.get('OPENAI_API_KEY'))\n","\n","train_batch_object = client.batches.create(\n","    input_file_id=train_file_response['id'],\n","    endpoint=\"/v1/chat/completions\",\n","    completion_window=\"24h\",\n","    metadata={\n","      \"description\": \"train_augmented_ner_responses\"\n","    }\n",")\n","\n","dev_batch_object = client.batches.create(\n","    input_file_id=dev_file_response['id'],\n","    endpoint=\"/v1/chat/completions\",\n","    completion_window=\"24h\",\n","    metadata={\n","      \"description\": \"dev_augmented_ner_responses\"\n","    }\n",")\n","\n","test_batch_object = client.batches.create(\n","    input_file_id=test_file_response['id'],\n","    endpoint=\"/v1/chat/completions\",\n","    completion_window=\"24h\",\n","    metadata={\n","      \"description\": \"test_augmented_ner_responses\"\n","    }\n",")"],"metadata":{"id":"3z_-3gsjKsX4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["get meta"],"metadata":{"id":"xVJ8cX85OBwP"}},{"cell_type":"code","source":["train_batch_object"],"metadata":{"id":"vZEsItQSNm2u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742482322169,"user_tz":-60,"elapsed":14,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9d440ec8-eb18-4fba-ac8b-72cb7ce50e2b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Batch(id='batch_67dc2b890a4c8190bd4156bb4240aeca', completion_window='24h', created_at=1742482313, endpoint='/v1/chat/completions', input_file_id='file-8q4ANgJKt7bfyoo5XqGgby', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742568713, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'train_augmented_ner_responses'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["dev_batch_object"],"metadata":{"id":"4icuj2hONq1o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742482325273,"user_tz":-60,"elapsed":18,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"37570bff-4f4a-44d2-ff54-f179c230b72d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Batch(id='batch_67dc2b8929fc819097fdab12ca753efc', completion_window='24h', created_at=1742482313, endpoint='/v1/chat/completions', input_file_id='file-MNQD39tDEDjDVaMjNBW8wi', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742568713, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'dev_augmented_ner_responses'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["test_batch_object"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfn7Rn9jNtek","executionInfo":{"status":"ok","timestamp":1742482327977,"user_tz":-60,"elapsed":17,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"5c29815a-235a-41a6-e4db-ee90d6496451"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Batch(id='batch_67dc2b89670c8190bbebaada409fb945', completion_window='24h', created_at=1742482313, endpoint='/v1/chat/completions', input_file_id='file-DLe5iMf1HJAJBPSPNeEK1x', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742568713, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'test_augmented_ner_responses'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["collect ids"],"metadata":{"id":"b8IEsM46ODWl"}},{"cell_type":"code","source":["train_batch_id = train_batch_object.id\n","train_batch_output_file = train_batch_object.output_file_id\n","dev_batch_id = dev_batch_object.id\n","dev_batch_output_file = dev_batch_object.output_file_id\n","test_batch_id = test_batch_object.id\n","test_batch_output_file = test_batch_object.output_file_id\n"],"metadata":{"id":"dty2lUFMNwRy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["retrieve status"],"metadata":{"id":"g6CIdqufOFAL"}},{"cell_type":"code","source":["client.batches.retrieve(train_batch_id)"],"metadata":{"id":"VHpU_wdcN_22","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742482350821,"user_tz":-60,"elapsed":251,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"997ca18c-c7ec-4559-84e4-5cedf91ef4ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Batch(id='batch_67dc2b890a4c8190bd4156bb4240aeca', completion_window='24h', created_at=1742482313, endpoint='/v1/chat/completions', input_file_id='file-8q4ANgJKt7bfyoo5XqGgby', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742568713, failed_at=None, finalizing_at=None, in_progress_at=1742482317, metadata={'description': 'train_augmented_ner_responses'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=20474))"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["client.batches.retrieve(dev_batch_id)"],"metadata":{"id":"u_DqczcSOeID","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742482359736,"user_tz":-60,"elapsed":171,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"9b21c337-dd09-4e7b-beb7-8f1f933e51a5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Batch(id='batch_67dc2b8929fc819097fdab12ca753efc', completion_window='24h', created_at=1742482313, endpoint='/v1/chat/completions', input_file_id='file-MNQD39tDEDjDVaMjNBW8wi', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742568713, failed_at=None, finalizing_at=None, in_progress_at=1742482314, metadata={'description': 'dev_augmented_ner_responses'}, output_file_id=None, request_counts=BatchRequestCounts(completed=131, failed=0, total=746))"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["client.batches.retrieve(test_batch_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbi4dN2MOhd8","executionInfo":{"status":"ok","timestamp":1742482363070,"user_tz":-60,"elapsed":118,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f8d9f689-3f1b-4ee2-f5db-76ab77a0f703"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Batch(id='batch_67dc2b89670c8190bbebaada409fb945', completion_window='24h', created_at=1742482313, endpoint='/v1/chat/completions', input_file_id='file-DLe5iMf1HJAJBPSPNeEK1x', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742568713, failed_at=None, finalizing_at=None, in_progress_at=1742482314, metadata={'description': 'test_augmented_ner_responses'}, output_file_id=None, request_counts=BatchRequestCounts(completed=161, failed=0, total=500))"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["Load the files as below in the misc folder when OpenAI is complete\n","get_files JSON"],"metadata":{"id":"HbCpQSzJOlqX"}},{"cell_type":"code","source":["path = \"class/misc/\"\n","def get_jsonl(path):\n","  with open(path, 'r', encoding='utf-8') as f:\n","      return [json.loads(line) for line in f]\n","\n","train_output = get_jsonl(path + \"batch_train_augmented_output.jsonl\")\n","dev_output = get_jsonl(path + \"batch_dev_augmented_output.jsonl\")\n","test_output = get_jsonl(path + \"batch_test_augmented_output.jsonl\")"],"metadata":{"id":"_M3FYMGnad6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_output[0]"],"metadata":{"id":"btt3GkbHOnyl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742491006537,"user_tz":-60,"elapsed":10,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f826008d-65d4-4c39-8959-3f1ffe5a1ca1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': 'batch_req_67dc378716208190a708417982fcd5a4',\n"," 'custom_id': 'train0',\n"," 'response': {'status_code': 200,\n","  'request_id': '3b47872434d61b1011aa49b682c45dfc',\n","  'body': {'id': 'chatcmpl-BDBXq8K2NVNAK0jbA42xcU4zuxlkw',\n","   'object': 'chat.completion',\n","   'created': 1742482342,\n","   'model': 'ft:gpt-4o-mini-2024-07-18:personal::AbTiRIUJ',\n","   'choices': [{'index': 0,\n","     'message': {'role': 'assistant',\n","      'content': 'Halted, he peered down the dark winding stairs and called out coarsely:   —Come up, @@Kinch##Person ! Come up, you fearful jesuit!   Solemnly he came forward and mounted the round gunrest. He faced about and blessed gravely thrice the tower, the surrounding land and the awaking mountains.',\n","      'refusal': None,\n","      'annotations': []},\n","     'logprobs': None,\n","     'finish_reason': 'stop'}],\n","   'usage': {'prompt_tokens': 453,\n","    'completion_tokens': 73,\n","    'total_tokens': 526,\n","    'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n","    'completion_tokens_details': {'reasoning_tokens': 0,\n","     'audio_tokens': 0,\n","     'accepted_prediction_tokens': 0,\n","     'rejected_prediction_tokens': 0}},\n","   'service_tier': 'default',\n","   'system_fingerprint': 'fp_6f625379d6'}},\n"," 'error': None}"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["train_responses = [obj['response']['body']['choices'][0]['message'][\"content\"] for obj in train_output]\n","dev_responses = [obj['response']['body']['choices'][0]['message'][\"content\"] for obj in dev_output]\n","test_responses = [obj['response']['body']['choices'][0]['message'][\"content\"] for obj in test_output]"],"metadata":{"id":"B8qX9c1DdjZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train['ner_responses'] = train_responses\n","df_dev['ner_responses'] = dev_responses\n","df_test['ner_responses'] = test_responses"],"metadata":{"id":"oRDBsgMGfFQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = 'class/datasets/'\n","df_train.to_pickle(path + 'df_train_augmentation_ft')\n","df_dev.to_pickle(path + 'df_dev_augmentation_ft')\n","df_test.to_pickle(path + 'df_test_augmentation_ft')"],"metadata":{"id":"H4ZBEn27fqBE"},"execution_count":null,"outputs":[]}]}