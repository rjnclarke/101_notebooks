{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["3maoAgIoJwsk","dSwoWZc1MPB5","jUmDO8qOQRH0","sgEnQqynTZS7","bBUehdKDaSK2"],"authorship_tag":"ABX9TyOk2olRGNQqIY5qMHZdiAgL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text Classification - NER Tagging (Off the shelf)\n","\n"],"metadata":{"id":"Zoh4bKaeJwk_"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","* Admin\n","* Datasets - Make a developement and test dataset\n","* Prompt\n","* Inference - Get results from LLM\n","* Metrics"],"metadata":{"id":"i0yKt0_VJwn7"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","In this notebook we test how well GPT-4o-mini can annotate our dataset with labels. We will subsequently finetune it and make a comparisson.\n","\n","The most appropriate model will be used to annotate our entire dataset, and these annotation will be used with downstream LLM and GNN tasks."],"metadata":{"id":"d07ExmUPJwqh"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin:}$\n"],"metadata":{"id":"3maoAgIoJwsk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsDdVpAIJjhx","executionInfo":{"status":"ok","timestamp":1733500045841,"user_tz":-60,"elapsed":2022,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"00107e86-f4e4-476c-b93b-a89727791433"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive\n"]}],"source":["from google.colab import drive\n","from google.colab import userdata\n","\n","drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive/'"]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"zeWXQ5PBL6Ua"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's run the LLM through Langchain this time"],"metadata":{"id":"NRQcpwy7MDBy"}},{"cell_type":"code","source":["%%capture\n","!pip install -U -q langchain langchain_openai"],"metadata":{"id":"TEDoxxMLL7xI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Datasets:}$\n"],"metadata":{"id":"dSwoWZc1MPB5"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('class/datasets/df_ner_annotated')\n","df = df[['id', 'content', 'annotated_content']]\n","df_train = df[:100]\n","df_dev = df[100:]"],"metadata":{"id":"Ur3ZFx_PMMOr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["save..."],"metadata":{"id":"Goxu-nibM-RJ"}},{"cell_type":"markdown","source":["reload data"],"metadata":{"id":"eWeI6mucPiIx"}},{"cell_type":"code","source":["import pandas as pd\n","path = 'class/datasets/ner_annotated'\n","df_train = pd.read_pickle(path + 'train')\n","df_dev = pd.read_pickle(path + 'dev')\n","df_example = pd.read_pickle(path + 'example')"],"metadata":{"id":"qJiELqKNNvew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df_train.shape, df_dev.shape, df_example.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pK2KymgNNxQN","executionInfo":{"status":"ok","timestamp":1733500060859,"user_tz":-60,"elapsed":19,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"06176cfc-604e-4ee5-9e69-706f13f4a62e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(97, 3) (100, 4) (3, 3)\n"]}]},{"cell_type":"code","source":["for el in df_example['content']:\n","  print(el)\n","  print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GaNSeAvRRqri","executionInfo":{"status":"ok","timestamp":1733500060859,"user_tz":-60,"elapsed":14,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"13587bc9-96e9-414c-ade2-645b813c8f5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["“Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”   “John of Tuam,” repeated Mr Cunningham, “was the man.”   He drank and the other gentlemen followed his lead.\n","\n","\n","sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","\n","\n","Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","\n","\n"]}]},{"cell_type":"code","source":["for el in df_example['annotated_content']:\n","  print(el)\n","  print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWKJqb4GRVGr","executionInfo":{"status":"ok","timestamp":1733500060859,"user_tz":-60,"elapsed":9,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"0a8c30f1-6681-4d8a-a910-8cfcc1609d72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["“Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”   “@@John of Tuam##Person,” repeated @@Mr Cunningham##Person, “was the man.”   He drank and the other gentlemen followed his lead.\n","\n","\n","sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","\n","\n","Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","\n","\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Prompt:}$\n"],"metadata":{"id":"jUmDO8qOQRH0"}},{"cell_type":"markdown","source":["The tagging formatting is learnt with a single example, but here we use all labels and a null sentence to fully inform the LLM."],"metadata":{"id":"KKJ7bHjwSdFQ"}},{"cell_type":"code","source":["template = \"\"\"The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\n","The output should be identicle to the input with the exception of the Person and Location tags if required.\n","\n","###Examples\n","Input: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”   “John of Tuam,” repeated Mr Cunningham, “was the man.”   He drank and the other gentlemen followed his lead.\n","Output: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”   “@@John of Tuam##Person,” repeated @@Mr Cunningham##Person, “was the man.”   He drank and the other gentlemen followed his lead.\n","\n","Input: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","Output: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","\n","Input: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","Output: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","\n","**DON'T LABEL PRONOUNS AS PERSON**\n","\n","###Text\n","Input: {}\n","Output:\"\"\""],"metadata":{"id":"GoNHKhf3QdEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_in = 'Dog'\n","print(template.format(prompt_in))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCg4XntDS2ob","executionInfo":{"status":"ok","timestamp":1733500975648,"user_tz":-60,"elapsed":250,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"980e4860-ad7b-4afe-8b30-df9b01b53748"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\n","The output should be identicle to the input with the exception of the Person and Location tags if required.\n","\n","###Examples\n","Input: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”   “John of Tuam,” repeated Mr Cunningham, “was the man.”   He drank and the other gentlemen followed his lead.\n","Output: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”   “@@John of Tuam##Person,” repeated @@Mr Cunningham##Person, “was the man.”   He drank and the other gentlemen followed his lead.\n","\n","Input: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","Output: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","\n","Input: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","Output: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","\n","**DON'T LABEL PRONOUNS AS PERSON**\n","\n","###Text\n","Input: Dog\n","Output:\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Inference:}$\n"],"metadata":{"id":"sgEnQqynTZS7"}},{"cell_type":"code","source":["import requests\n","URL = \"https://api.openai.com/v1/chat/completions\" # endpoint\n","\n","system_message = \"You are an excellent linguist\"\n","\n","key = userdata.get('OPENAI_API_KEY')\n","model = \"gpt-4o-mini\"\n","payload = {\n","\"model\": model,\n","\"messages\": [{\"role\": \"system\", \"content\": system_message}],\n","\"temperature\" : 0, # creativity of the model\n","\"top_p\":1.0, # percentile probability sampling\n","\"n\" : 1, # number of responses to generate\n","\"stream\": False,\n","\"presence_penalty\":0, # penalize/ incentivize given tokens\n","\"frequency_penalty\":0, # penalize/ incentivize given tokens\n","}\n","\n","headers = {\n","  \"Content-Type\": \"application/json\",\n","  \"Authorization\": f\"Bearer {key}\"\n","}"],"metadata":{"id":"666GQNlZTZk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","# parse the response json\n","def get_predicted(response):\n","  \"\"\"Get content of the response from OpenAI\"\"\"\n","  out = response.content\n","  out_dict = json.loads(out)\n","  return out_dict['choices'][0]['message']['content']"],"metadata":{"id":"IMJX8EHPtn2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["responses = [\"\"] * df_dev.shape[0]\n","count = 0\n","n = df_dev.shape[0]\n","for i in range(n):\n","  if count % 20 == 0:\n","    print(count)\n","  payload['messages'] = [{\"role\": \"system\", \"content\": system_message}] # reset payload\n","  new_prompt = template.format(df_dev.loc[i][\"content\"]) # make prompt\n","  payload['messages'].append({'role':'user', 'content': new_prompt}) # add prompt to payload\n","  try:\n","    response = requests.post(URL, headers=headers, json=payload, stream=False, timeout=80) # send request\n","    responses[i] = get_predicted(response) # extract content\n","  except:\n","    responses[i] = \"fail\"\n","    print(f\"fail\")\n","  count += 1"],"metadata":{"id":"tJHSXBpIT9pv","executionInfo":{"status":"ok","timestamp":1733501132509,"user_tz":-60,"elapsed":82177,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2de2e25e-ce69-4164-ab46-cf5607dd742e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","20\n","40\n","60\n","80\n"]}]},{"cell_type":"code","source":["fail = 0\n","failed = []\n","for i in range(len(responses)):\n","  if len(responses[i]) == 0:\n","    fail += 1\n","    failed.append(i)\n","print(fail)"],"metadata":{"id":"WnKs0QJLUM5Z","executionInfo":{"status":"ok","timestamp":1733501142544,"user_tz":-60,"elapsed":220,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"17cc262a-6396-471b-b490-a37b024922fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","source":["df_dev['predictions'] = responses\n","df_dev['predictions']"],"metadata":{"id":"cyHu2mcQVAiq","executionInfo":{"status":"ok","timestamp":1733501145895,"user_tz":-60,"elapsed":224,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"colab":{"base_uri":"https://localhost:8080/","height":479},"outputId":"fe7b8c6a-4c74-4316-cd23-f962296358ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     And yet, my dear, let me whisper, I felt a thr...\n","1     I did not know what to do, the less as the how...\n","2     Looks full up of bad gas. Must be an infernal ...\n","3     Why, clearly, he said, then he and his boon co...\n","4     Secondly, I will show that all men who practis...\n","                            ...                        \n","95    an idea he utterly repudiated. Quite apart fro...\n","96    —My dear @@Myles##Person, he said, flinging hi...\n","97    a reward which a man might fairly expect who n...\n","98    and is ready to compete with him in word or de...\n","99    the latter embedded to the extent of one foot ...\n","Name: predictions, Length: 100, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>And yet, my dear, let me whisper, I felt a thr...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I did not know what to do, the less as the how...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Looks full up of bad gas. Must be an infernal ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Why, clearly, he said, then he and his boon co...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Secondly, I will show that all men who practis...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>an idea he utterly repudiated. Quite apart fro...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>—My dear @@Myles##Person, he said, flinging hi...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>a reward which a man might fairly expect who n...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>and is ready to compete with him in word or de...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>the latter embedded to the extent of one foot ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import re\n","pattern = r\"@@([^#]*)##(\\w+\\b)\\S*\"\n","all_entities = [re.findall(pattern, text) for text in df_dev['predictions']]\n","\n","count_zeros = 0\n","count_people = 0\n","count_places = 0\n","people_list = []\n","place_list = []\n","for entity in all_entities:\n","  if len(entity) < 1:\n","    count_zeros += 1\n","  for tup in entity:\n","    if tup[1] == \"Person\":\n","      count_people += 1\n","      people_list.append(tup[0])\n","    elif tup[1] == \"Location\":\n","      count_places += 1\n","      place_list.append(tup[0])\n","\n","\n","print(f'Proportion of texts with entities = {(len(all_entities) - count_zeros) / len(all_entities)}.')\n","print(f'\\nThere are {count_people} Person entities.')\n","print(f'\\nThere are {count_places} Location entities.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PkKDA0EZvCO","executionInfo":{"status":"ok","timestamp":1733501167427,"user_tz":-60,"elapsed":422,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"6c346e33-b6bc-40fd-a737-a021e9f23688"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Proportion of texts with entities = 0.7.\n","\n","There are 129 Person entities.\n","\n","There are 43 Location entities.\n"]}]},{"cell_type":"markdown","source":["## $\\color{blue}{Metrics:}$\n"],"metadata":{"id":"bBUehdKDaSK2"}},{"cell_type":"code","source":["def get_labels(true, predicted):\n","  pattern = r\"@@([^#]*)##(\\w+\\b)\\S*\"\n","  true_labels = re.findall(pattern, true)\n","  predicted_labels = re.findall(pattern, predicted)\n","\n","  #clean labels for string type checking\n","  true_people = []\n","  true_locations = []\n","  predicted_people = []\n","  predicted_locations = []\n","\n","  if len(true_labels) > 0:\n","    for el in true_labels:\n","      if (el[1] == 'Person') or (el[1] == 'person'):\n","        true_people.append(el[0].lower().strip())\n","      elif (el[1] == 'Location') or (el[1] == 'location'):\n","        true_locations.append(el[0].lower().strip())\n","\n","  if len(predicted_labels) > 0:\n","    for el in predicted_labels:\n","      if (el[1] == 'Person') or (el[1] == 'person'):\n","        predicted_people.append(el[0].lower().strip())\n","      elif (el[1] == 'Location') or (el[1] == 'location'):\n","        predicted_locations.append(el[0].lower().strip())\n","\n","  return true_people, true_locations, predicted_people, predicted_locations\n","\n","\n","\n"],"metadata":{"id":"ADDCwMSZaak-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from copy import deepcopy\n","from collections import namedtuple\n","\n","Stats = namedtuple(\"stats\", ['TP','FP', 'FN'])\n","\n","def count_metrics(real, predicted):\n","  real = deepcopy(real)\n","  predicted = deepcopy(predicted)\n","  # Count Metrics\n","  TP = 0\n","  FP = 0\n","  FN = 0\n","\n","  for item in real:\n","    if item in predicted:\n","      TP += 1\n","      predicted.remove(item)\n","    else:\n","      FN += 1\n","\n","  for item in predicted:\n","    FP += 1\n","\n","  return Stats(TP, FP, FN)\n"],"metadata":{"id":"0iWwho0EeNc8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["true = list(df_dev['annotated_content'])\n","predicted = list(df_dev['predictions'])\n","\n","people = []\n","locations = []\n","\n","for i in range(len(true)):\n","  true_people, true_locations, predicted_people, predicted_locations = get_labels(true[i], predicted[i])\n","  people.append(count_metrics(true_people, predicted_people))\n","  locations.append(count_metrics(true_locations, predicted_locations))\n"],"metadata":{"id":"nUBhq3jNhEyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def report_stats(lstr):\n","  TP = 0\n","  FP = 0\n","  FN = 0\n","  for item in lstr:\n","    TP += item.TP\n","    FP += item.FP\n","    FN += item.FN\n","\n","  precision = TP / (TP + FP)\n","  recall = TP / (TP + FN)\n","  f1 = 2 * ((precision * recall)/ (precision + recall))\n","  print('F1: ', f1)\n","  print('Precision: ', precision)\n","  print('Recall: ', recall)"],"metadata":{"id":"dgLWo_kVjwiL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('-' * 10)\n","print(\"PEOPLE STATS\")\n","report_stats(people)\n","print('\\n')\n","print('-' * 10)\n","print(\"LOCATION STATS\")\n","report_stats(locations)\n","print('\\n')\n","print('-' * 10)\n","print(\"OVERALL STATS\")\n","report_stats(people + locations)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUrG3MOhlKXA","executionInfo":{"status":"ok","timestamp":1733501195475,"user_tz":-60,"elapsed":323,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"e3230de3-d5f0-49f4-869a-0e3617724e5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------\n","PEOPLE STATS\n","F1:  0.7603305785123968\n","Precision:  0.7131782945736435\n","Recall:  0.8141592920353983\n","\n","\n","----------\n","LOCATION STATS\n","F1:  0.5079365079365079\n","Precision:  0.37209302325581395\n","Recall:  0.8\n","\n","\n","----------\n","OVERALL STATS\n","F1:  0.7081967213114754\n","Precision:  0.627906976744186\n","Recall:  0.8120300751879699\n"]}]},{"cell_type":"code","source":["df_dev.to_pickle(path + \"dev\")"],"metadata":{"id":"GCr2rWLFT7l8"},"execution_count":null,"outputs":[]}]}