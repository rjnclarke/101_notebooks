{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pSGOLwphVDHmnXtS3Fsnh1yDpjwAybN4","timestamp":1733494356620},{"file_id":"1BAf6BnJwsIxUPyUzR9LZzRnDDCIR6clS","timestamp":1732272000064},{"file_id":"1Gr7WHUidodr44VZvvAqCXa-t7ZaKv2UR","timestamp":1717746596069}],"collapsed_sections":["lcifqi4flhn3","CaaxjILYlpe-","D8wzTZyPSeud","QEQFS7qmZM7z","1N5bQtFd_xJp","RWYOa1_TLBLF","N9C0ZLIfLR1x"],"authorship_tag":"ABX9TyN92MhetqLfW3XU2TZAkfqV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text Classification - Finetune GPT-4o-mini for NER\n","\n","\n","---\n","\n","---"],"metadata":{"id":"4ZNd27xZQpCv"}},{"cell_type":"markdown","source":["## $\\color{blue}{Sections:}$\n","\n","* Preamble\n","1.   Admin\n","2.   Data\n","4.   Prompt\n","5.   JSONL\n","6.   Check Datasets\n","7. Create OpenAI Finetuned Model"],"metadata":{"id":"BKrinVbAQ0gg"}},{"cell_type":"markdown","source":["## $\\color{blue}{Preamble:}$\n","\n","Uploading dataset to OpenAI Finetuning GPT-4o-mini on NER data. Subsequently launching the finetuning."],"metadata":{"id":"GmhwWOTBmgou"}},{"cell_type":"markdown","source":["## $\\color{blue}{Admin}$\n","* Install relevant Libraries\n","* Import relevant Libraries"],"metadata":{"id":"lcifqi4flhn3"}},{"cell_type":"code","source":["%%capture\n","!pip install tiktoken openai cohere"],"metadata":{"id":"PBXp0BKqh7qy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install dill"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXymZzeur8Uv","executionInfo":{"status":"ok","timestamp":1733494482278,"user_tz":-60,"elapsed":6169,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"68fa988e-48f2-440e-bf2f-b74d971a9601"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dill\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/119.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.9\n"]}]},{"cell_type":"code","source":["import openai\n","import re\n","import pandas as pd\n","import requests\n","import json\n","from google.colab import drive\n","from google.colab import userdata\n","from collections import defaultdict\n","import os\n","import dill"],"metadata":{"id":"0WYqYZRiQ3bv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## $\\color{blue}{Data}$\n","\n","* Connect to Drive\n","* Load the data to a string"],"metadata":{"id":"CaaxjILYlpe-"}},{"cell_type":"code","source":["drive.mount(\"/content/drive\")\n","%cd '/content/drive/MyDrive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haNmVkgUQ6d9","executionInfo":{"status":"ok","timestamp":1733494532543,"user_tz":-60,"elapsed":20728,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"f32bf256-9d3d-4995-8c97-57b117fbdb26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","path = 'class/datasets/ner_annotated'\n","df_train = pd.read_pickle(path + 'train')\n","df_dev = pd.read_pickle(path + 'dev')\n","df_example = pd.read_pickle(path + 'example')"],"metadata":{"id":"-2d-jro_txhv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_dev.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhJZZNFiVe9u","executionInfo":{"status":"ok","timestamp":1733494704074,"user_tz":-60,"elapsed":279,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"147663ef-3299-4ce8-a940-442de2e886c8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'content', 'annotated_content'], dtype='object')"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# $\\color{blue}{JSONL}$\n","\n","----\n","\n","The API requires data to be uploaded in this format.\n","The payload requires a system message (definition of LLM role), a user message (input prompt), and an assistant messages (expected output)."],"metadata":{"id":"D8wzTZyPSeud"}},{"cell_type":"code","source":["prompt = \"\"\"The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\n","The output should be identicle to the input with the exception of the Person and Location tags if required.\n","\n","###Examples\n","Input: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”   “John of Tuam,” repeated Mr Cunningham, “was the man.”   He drank and the other gentlemen followed his lead.\n","Output: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”   “@@John of Tuam##Person,” repeated @@Mr Cunningham##Person, “was the man.”   He drank and the other gentlemen followed his lead.\n","\n","Input: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","Output: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\n","\n","Input: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","Output: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\n","\n","**DON'T LABEL PRONOUNS AS PERSON**\n","\n","###Text\n","Input: {}\n","Output:\"\"\"\n","\n","\n","system_message = \"\"\"You are an excellent linguist.\"\"\"\n"],"metadata":{"id":"XWEHhA0Agd3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_data(df):\n","  dataset = []\n","  for i in range(df.shape[0]):\n","    point = {\"messages\" : [{\"role\": \"system\" , \"content\" : system_message}]}\n","    point[\"messages\"].append({\"role\": \"user\", \"content\": prompt.format(df.loc[i]['content'])})\n","    point[\"messages\"].append({\"role\": \"assistant\", \"content\": df.loc[i]['annotated_content']})\n","    dataset.append(point)\n","  return dataset\n","\n","def save_to_jsonl(dataset, file_path):\n","  \"\"\"\n","  Convert dataset into jsonl.\n","\n","  Parameters\n","  ----------\n","  dataset : list\n","      List of dicts containing datapoint information.\n","  filepath: str\n","      File path to save to.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  with open(file_path,\"w\") as file:\n","    for data in dataset:\n","      json_line = json.dumps(data)\n","      file.write(json_line + '\\n')"],"metadata":{"id":"vmiwD7ihV4XE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### $\\color{red}{To-File}$\n"],"metadata":{"id":"RNxJ4RlJXi4E"}},{"cell_type":"code","source":["train_dataset = format_data(df_train)\n","save_to_jsonl(train_dataset, \"class/datasets/train_openai_ner_ft.jsonl\")"],"metadata":{"id":"WReTa-Ec-Dv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s67E2vm99HfX","executionInfo":{"status":"ok","timestamp":1733495093510,"user_tz":-60,"elapsed":242,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"e128cf46-1739-400e-e602-4eff6ebe2c93"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'messages': [{'role': 'system', 'content': 'You are an excellent linguist.'},\n","  {'role': 'user',\n","   'content': \"The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\\nThe output should be identicle to the input with the exception of the Person and Location tags if required.\\n\\n###Examples\\nInput: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”   “John of Tuam,” repeated Mr Cunningham, “was the man.”   He drank and the other gentlemen followed his lead.\\nOutput: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”   “@@John of Tuam##Person,” repeated @@Mr Cunningham##Person, “was the man.”   He drank and the other gentlemen followed his lead.\\n\\nInput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\nOutput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\n\\nInput: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\\nOutput: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\\n\\n**DON'T LABEL PRONOUNS AS PERSON**\\n\\n###Text\\nInput: Stephen, who was trying his dead best to yawn if he could, suffering from lassitude generally, replied:   —To fill the ear of a cow elephant. They were haggling over money.   —Is that so? Mr Bloom asked.\\nOutput:\"},\n","  {'role': 'assistant',\n","   'content': '@@Stephen##Person , who was trying his dead best to yawn if he could, suffering from lassitude generally, replied:   —To fill the ear of a cow elephant. They were haggling over money.   —Is that so? @@Mr Bloom##Person asked.'}]}"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# $\\color{blue}{Check - Datasets}$"],"metadata":{"id":"QEQFS7qmZM7z"}},{"cell_type":"code","source":["# Get example\n","def message_check(file_path, ind):\n","  \"\"\"\n","  Check message from jsonl file.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to jsonl file.\n","  ind: int\n","      Required ind for checking.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  # Load the dataset\n","  with open(file_path, 'r', encoding='utf-8') as f:\n","      dataset = [json.loads(line) for line in f]\n","\n","  # Initial dataset stats\n","  print(\"Num examples:\", len(dataset))\n","  print(\"First example:\")\n","  for message in dataset[ind][\"messages\"]:\n","      print(message)"],"metadata":{"id":"fzKUNPiQZLxC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Format error checks\n","def check_errors(file_path):\n","  \"\"\"\n","  Check if there are any errors in file that will cause OpenAI training process to fail.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to the json file.\n","\n","  Returns\n","  -------\n","  None\n","  \"\"\"\n","  with open(file_path, 'r', encoding='utf-8') as f:\n","    dataset = [json.loads(line) for line in f]\n","\n","  format_errors = defaultdict(int)\n","\n","  for ex in dataset:\n","      if not isinstance(ex, dict):\n","          format_errors[\"data_type\"] += 1\n","          continue\n","\n","      messages = ex.get(\"messages\", None)\n","      if not messages:\n","          format_errors[\"missing_messages_list\"] += 1\n","          continue\n","\n","      for message in messages:\n","          if \"role\" not in message or \"content\" not in message:\n","              format_errors[\"message_missing_key\"] += 1\n","\n","          if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n","              format_errors[\"message_unrecognized_key\"] += 1\n","\n","          if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n","              format_errors[\"unrecognized_role\"] += 1\n","\n","          content = message.get(\"content\", None)\n","          function_call = message.get(\"function_call\", None)\n","\n","          if (not content and not function_call) or not isinstance(content, str):\n","              format_errors[\"missing_content\"] += 1\n","\n","      if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","          format_errors[\"example_missing_assistant_message\"] += 1\n","\n","  if format_errors:\n","      print(\"Found errors:\")\n","      for k, v in format_errors.items():\n","          print(f\"{k}: {v}\")\n","  else:\n","      print(\"No errors found\")"],"metadata":{"id":"CMu7hKUKbZbZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["message_check(\"class/datasets/train_openai_ner_ft.jsonl\",10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQA417Kbckyd","executionInfo":{"status":"ok","timestamp":1733495131167,"user_tz":-60,"elapsed":287,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"cdc7d271-795e-4ab8-98c9-5223d44ff076"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples: 97\n","First example:\n","{'role': 'system', 'content': 'You are an excellent linguist.'}\n","{'role': 'user', 'content': \"The task is to label the Location and Person entities in the given ###Text section, Following the format in the ###Examples section.\\nThe output should be identicle to the input with the exception of the Person and Location tags if required.\\n\\n###Examples\\nInput: “Is it John of Tuam?”   “Are you sure of that now?” asked Mr Fogarty dubiously. “I thought it was some Italian or American.”   “John of Tuam,” repeated Mr Cunningham, “was the man.”   He drank and the other gentlemen followed his lead.\\nOutput: “Is it @@John of Tuam##Person ?”   “Are you sure of that now?” asked @@Mr Fogarty##Person dubiously. “I thought it was some Italian or American.”   “@@John of Tuam##Person,” repeated @@Mr Cunningham##Person, “was the man.”   He drank and the other gentlemen followed his lead.\\n\\nInput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\nOutput: sibly there were several others. He personally, being of a sceptical bias, believed and didn’t make the smallest bones about saying so either that man or men in the plural were always hanging around on the waiting list about a lady,\\n\\nInput: Now to the historical, for as Madam Mina write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the Borgo Pass just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\\nOutput: Now to the historical, for as @@Madam Mina##Person write not in her stenography, I must, in my cumbrous old fashion, that so each day of us may not go unrecorded. We got to the @@Borgo Pass##Location  just after sunrise yesterday morning. When I saw the signs of the dawn I got ready for the hypnotism.\\n\\n**DON'T LABEL PRONOUNS AS PERSON**\\n\\n###Text\\nInput: He heard more faintly that that they heard, each for herself alone, then each for other, hearing the plash of waves, loudly, a silent roar.   Bronze by a weary gold, anear, afar, they listened.   Her ear too is a shell, the peeping lobe there. Been to the seaside. Lovely seaside girls.\\nOutput:\"}\n","{'role': 'assistant', 'content': 'He heard more faintly that that they heard, each for herself alone, then each for other, hearing the plash of waves, loudly, a silent roar.   Bronze by a weary gold, anear, afar, they listened.   Her ear too is a shell, the peeping lobe there. Been to the @@seaside##Location . Lovely seaside girls.'}\n"]}]},{"cell_type":"code","source":["check_errors(\"class/datasets/train_openai_book_ft.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LN_dq6WmRkyx","executionInfo":{"status":"ok","timestamp":1733495135702,"user_tz":-60,"elapsed":1377,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"3a84308c-126f-4342-b8ae-9c357d7636c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No errors found\n"]}]},{"cell_type":"code","source":["check_errors(\"class/datasets/dev_openai_book_ft.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCfXe7RwRtlP","executionInfo":{"status":"ok","timestamp":1733495138362,"user_tz":-60,"elapsed":508,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"ec4779c1-17f3-4aa4-cf1b-6bc94d911d41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No errors found\n"]}]},{"cell_type":"markdown","source":["# $\\color{blue}{Create-OpenAi-Finetuned-Model}$"],"metadata":{"id":"1N5bQtFd_xJp"}},{"cell_type":"markdown","source":["##### $\\color{red}{Load-File}$"],"metadata":{"id":"RWYOa1_TLBLF"}},{"cell_type":"code","source":["endpoint = \"https://api.openai.com/v1/files\" # endpoint for files\n","\n","key = userdata.get('OPENAI_API_KEY')\n","\n","headers = {'Authorization': f\"Bearer {key}\"}\n","\n","def upload_file(file_path, endpoint, headers):\n","  \"\"\"\n","  Upload a file to the OpenAI file system.\n","\n","  Parameters\n","  ----------\n","  filepath : str\n","      Path to the json file.\n","  endpoint : str\n","      Use 'https://api.openai.com/v1/files'.\n","  headers : dict\n","      Use {'Authorization': f\"Bearer {key}\"}.\n","\n","  Returns\n","  -------\n","  response : json\n","      Response from OpenAI confirming details of the upload.\n","  \"\"\"\n","  with open(file_path,'rb') as f:\n","    response = requests.post(endpoint, headers=headers, files={'file': f}, data={'purpose': 'fine-tune'})\n","  return response.json()"],"metadata":{"id":"B9ejjx6HEkoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file_response = upload_file(\"class/datasets/train_openai_ner_ft.jsonl\", endpoint, headers)"],"metadata":{"id":"xACBUiufEkuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ie-dQl7jHgLr","executionInfo":{"status":"ok","timestamp":1733495176771,"user_tz":-60,"elapsed":324,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"489fe4e9-625c-4ddd-c79d-08e0bfe70568"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'file',\n"," 'id': 'file-1PW8zfdZxtagXNURr8kKQb',\n"," 'purpose': 'fine-tune',\n"," 'filename': 'train_openai_ner_ft.jsonl',\n"," 'bytes': 262876,\n"," 'created_at': 1733495172,\n"," 'status': 'processed',\n"," 'status_details': None}"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["##### $\\color{red}{Create-Models}$"],"metadata":{"id":"N9C0ZLIfLR1x"}},{"cell_type":"code","source":["URL = \"https://api.openai.com/v1/fine_tuning/jobs\" # endpoint\n","\n","\n","headers = {\n","  \"Content-Type\": \"application/json\",\n","  \"Authorization\": f\"Bearer {key}\"\n","}"],"metadata":{"id":"bOK5fV4BCt4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["payload = {\n","  \"training_file\": train_file_response['id'],\n","  \"model\": \"gpt-4o-mini-2024-07-18\"\n","}\n","finetune_response = requests.post(URL, json=payload, headers=headers)\n","finetune_meta = json.loads(finetune_response.content)"],"metadata":{"id":"cd6PIWfmSZzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["finetune_meta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJ4saBldUE2r","executionInfo":{"status":"ok","timestamp":1733495222843,"user_tz":-60,"elapsed":217,"user":{"displayName":"Clarke Ricahrd","userId":"13372369852905387831"}},"outputId":"fb44d419-a957-4c33-9ab4-48144c8e23d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'object': 'fine_tuning.job',\n"," 'id': 'ftjob-Kn1UUueyuQsTGNm36sw1P4i7',\n"," 'model': 'gpt-4o-mini-2024-07-18',\n"," 'created_at': 1733495217,\n"," 'finished_at': None,\n"," 'fine_tuned_model': None,\n"," 'organization_id': 'org-4bBdSgsciB8iKzeJ61GgVdXt',\n"," 'result_files': [],\n"," 'status': 'validating_files',\n"," 'validation_file': None,\n"," 'training_file': 'file-1PW8zfdZxtagXNURr8kKQb',\n"," 'hyperparameters': {'n_epochs': 'auto',\n","  'batch_size': 'auto',\n","  'learning_rate_multiplier': 'auto'},\n"," 'trained_tokens': None,\n"," 'error': {},\n"," 'user_provided_suffix': None,\n"," 'seed': 230197262,\n"," 'estimated_finish': None,\n"," 'integrations': []}"]},"metadata":{},"execution_count":27}]}]}